{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Vissim_env_class import environment\n",
    "from MasterDQN_Agent import MasterDQN_Agent\n",
    "\n",
    "# General Libraries\n",
    "import numpy as np \n",
    "import pylab as plt\n",
    "import os\n",
    "import csv\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Single_Cross_Triple 8 actions DQN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name  = 'Single_Cross_Triple'\n",
    "#vissim_working_directory =  'C:\\\\Users\\\\Rzhang\\\\Desktop\\\\MLforFlowOptimisationOrigine\\\\Vissim\\\\'\n",
    "vissim_working_directory = 'C:\\\\Users\\\\acabrejasegea\\\\Desktop\\\\15_Timescales_utc\\\\gamma_code'\n",
    "\n",
    "sim_length = 3601\n",
    "timesteps_per_second = 1\n",
    "learning_iterations = 10\n",
    "actions_set = \"all_actions\"\n",
    "\n",
    "agent_type = \"DuelingDDQN\"\n",
    "Session_ID = \"SCT_8act_DuelingDDQN_acf_memorytest\"\n",
    "\n",
    "# all controller actions\n",
    "Single_Cross_Triple_dictionary8 =\\\n",
    "{\\\n",
    "    # Controller Number 0 \n",
    "   'junctions' : {0 : {'default_actions' :  {    0 : [1,1,1,0,0,0,0,0,0,0,0,0],\n",
    "                                             1 : [0,0,0,1,1,1,0,0,0,0,0,0],\n",
    "                                             2 : [0,0,0,0,0,0,1,1,1,0,0,0],\n",
    "                                             3 : [0,0,0,0,0,0,0,0,0,1,1,1],\n",
    "                                             4 : [1,0,0,0,0,0,1,0,0,0,0,0],\n",
    "                                             5 : [0,0,0,1,0,0,0,0,0,1,0,0],\n",
    "                                             6 : [0,1,1,0,0,0,0,1,1,0,0,0],\n",
    "                                             7 : [0,0,0,0,1,1,0,0,0,0,1,1]},\n",
    "         \n",
    "         'all_actions' :        {            0 : [1,1,1,0,0,0,0,0,0,0,0,0],\n",
    "                                             1 : [0,0,0,1,1,1,0,0,0,0,0,0],\n",
    "                                             2 : [0,0,0,0,0,0,1,1,1,0,0,0],\n",
    "                                             3 : [0,0,0,0,0,0,0,0,0,1,1,1],\n",
    "                                             4 : [1,0,0,0,0,0,1,0,0,0,0,0],\n",
    "                                             5 : [0,0,0,1,0,0,0,0,0,1,0,0],\n",
    "                                             6 : [0,1,1,0,0,0,0,1,1,0,0,0],\n",
    "                                             7 : [0,0,0,0,1,1,0,0,0,0,1,1]},\n",
    " \n",
    "         'link' : [1, 3, 5, 7],\n",
    "         'lane' : ['1-1', '1-2', '1-3', '3-1', '3-2', '3-3', '5-1', '5-2', '5-3', '7-1', '7-2', '7-3'],\n",
    "         \n",
    "         'controled_by_com' : True,\n",
    "         'agent_type' : agent_type,\n",
    "         'green_time' : 6,\n",
    "         'redamber_time' : 0,\n",
    "         'amber_time' : 3, \n",
    "         'red_time' : 0,\n",
    "         'state_size' : [13],\n",
    "         'state_type' : 'QueuesSig',\n",
    "         'reward_type' : 'Queues' ,\n",
    "         'queues_counter_ID' : [1,2,3,4,5,6,7,8,9,10,11,12]             \n",
    "         }\n",
    "    },\n",
    "   'demand' : { 'default' : [400, 400, 400, 400],\n",
    "             \n",
    "             0 : [300,300,300,300],\n",
    "             1 : [600,600,600,600],\n",
    "             2 : [1350,750,1350,750],\n",
    "             3 : [1500,750,1500,750],\n",
    "             4 : [1050,750,1050,750],\n",
    "             5 : [750,1050,750,1050],\n",
    "             6 : [750,1500,750,1500],\n",
    "             7 : [750,1350,750,1350],\n",
    "             8 : [600,600,600,600],\n",
    "             9 : [300,300,300,300]\n",
    "            }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## DQN Hyperaramenters\n",
    "episodes = 5 \n",
    "copy_weights_frequency = 20 # On a successfull run I copied the weight every 50\n",
    "\n",
    "PER_activated = True\n",
    "memory_size = 1000\n",
    "batch_size = 128\n",
    "\n",
    "gamma = 0.95\n",
    "alpha = 0.005"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x324 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Exploration Schedule (\"linear\" or \"geometric\")\n",
    "exploration_schedule = \"geometric\"\n",
    "epsilon_start = 1\n",
    "epsilon_end   = 0.001\n",
    "\n",
    "Random_Seed = 100\n",
    "\n",
    "def choose_schedule(exploration_schedule, espilon_start, epsilon_end, episodes):\n",
    "    if exploration_schedule == \"linear\":\n",
    "        epsilon_decay = 1.2*(epsilon_end - epsilon_start)/(episodes-1)\n",
    "        epsilon_sequence = [1 + epsilon_decay * entry for entry in range(episodes+1)]\n",
    "        epsilon_sequence = [0 if entry < 0 else entry for entry in epsilon_sequence]\n",
    "    elif exploration_schedule == \"geometric\":\n",
    "        epsilon_decay = np.power(epsilon_end/epsilon_start, 1./(episodes-1)) # Geometric decay\n",
    "        epsilon_sequence = [epsilon_start * epsilon_decay ** entry for entry in range(episodes+1)]\n",
    "    elif exploration_schedule == \"entropy\":\n",
    "        pass\n",
    "    else:\n",
    "        print(\"ERROR: Unrecognized choice of exploration schedule.\")\n",
    "        \n",
    "    # Plotting exploration schedule\n",
    "    plt.figure(figsize=(8,4.5))\n",
    "    x_series = np.array(range(1,episodes+1))\n",
    "    y_series = epsilon_sequence[0:episodes]\n",
    "    plt.plot(x_series, y_series, '-b')\n",
    "    plt.xlabel('Episodes')\n",
    "    plt.ylabel('Ratio of random exploration')\n",
    "    plt.title('Exploration schedule')\n",
    "    plt.show()\n",
    "    return(epsilon_sequence)\n",
    "\n",
    "epsilon_sequence = choose_schedule(exploration_schedule, epsilon_start, epsilon_end, episodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INTERSECTION 0: SETTING UP AGENT\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 13)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 24)           336         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 24)           600         dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 24)           600         dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 24)           600         dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 1)            25          dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 8)            200         dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "policy (Lambda)                 (None, 8)            0           dense_5[0][0]                    \n",
      "                                                                 dense_3[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 2,361\n",
      "Trainable params: 2,361\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Deployed instance of Dueling Double Deep Q Learning Agent(s) at Intersection 0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Single_Cross_Triple8_MultiDQN_Agents = MasterDQN_Agent(model_name, vissim_working_directory,\\\n",
    "                                                       sim_length, Single_Cross_Triple_dictionary8,\\\n",
    "                                                       actions_set, gamma, alpha, agent_type,\\\n",
    "                                                       memory_size, PER_activated, batch_size,\\\n",
    "                                                       learning_iterations, copy_weights_frequency,\\\n",
    "                                                       epsilon_sequence,Random_Seed,\\\n",
    "                                                       timesteps_per_second, Session_ID,\\\n",
    "                                                       verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous Experience: Found. Loading into agents\n",
      "Previous Experience: Successfully loaded file from:\n",
      "C:\\Users\\acabrejasegea\\Desktop\\15_Timescales_utc\\gamma_code\\Single_Cross_Triple\\Agents_Results\\DuelingDDQN\\SCT_8act_DuelingDDQN_acf_memorytest\\Agent0_PERPre_1000.p\n"
     ]
    }
   ],
   "source": [
    "Single_Cross_Triple8_MultiDQN_Agents.prepopulate_memory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working Directory set to: C:\\Users\\acabrejasegea\\Desktop\\15_Timescales_utc\\gamma_code\n",
      "Generating Cache...\n",
      "Cache generated.\n",
      "\n",
      "****************************\n",
      "*   COM Server dispatched  *\n",
      "****************************\n",
      "\n",
      "Attempting to load Model File: Single_Cross_Triple.inpx ...\n",
      "Model File load process successful.\n",
      "Simulation length set to 3601 seconds.\n",
      "Results from Previous Simulations: Deleted. Fresh Start Available.\n",
      "Fetched and containerized Network Object \n",
      "\n",
      "*******************************************************\n",
      "*                                                     *\n",
      "*                COM SETUP COMPLETE                   *\n",
      "*                                                     *\n",
      "*******************************************************\n",
      "\n",
      "Random seed set in simulator. Random Seed = 100\n",
      "Deploying Network Parser...\n",
      "Successful Network Crawl: Identified SignalControllers, Links, Lanes and Vehicle Inputs.\n",
      "\n",
      "Setting Simulation mode to: training\n",
      "Starting Deployments of Signal Control Units...\n",
      "SCUs successfully deployed. Elapsed time 0.15 seconds.\n",
      "\n",
      "start\n",
      "Random Seed Set to 101\n",
      "Episode 1: Finished running.\n",
      "Agent 0, Average Reward: -118.11\n",
      "Saving architecture, weights, optimizer state for best agent-0\n",
      "1/1 - 0s - loss: 1527.2222\n",
      "1/1 - 0s - loss: 1468.7021\n",
      "1/1 - 0s - loss: 1124.6420\n",
      "1/1 - 0s - loss: 929.4767\n",
      "1/1 - 0s - loss: 702.4374\n",
      "1/1 - 0s - loss: 530.8009\n",
      "1/1 - 0s - loss: 340.1701\n",
      "1/1 - 0s - loss: 205.9768\n",
      "1/1 - 0s - loss: 124.0591\n",
      "1/1 - 0s - loss: 120.3285\n",
      "Reducing exploration for all agents to 0.1778\n",
      "\n",
      "Episode 2: Starting computation.\n",
      "Random Seed Set to 102\n",
      "Episode 2: Finished running.\n",
      "Agent 0, Average Reward: -557.84\n",
      "1/1 - 0s - loss: 569.2526\n",
      "1/1 - 0s - loss: 639.7220\n",
      "1/1 - 0s - loss: 782.2302\n",
      "1/1 - 0s - loss: 684.3627\n",
      "1/1 - 0s - loss: 404.3340\n",
      "1/1 - 0s - loss: 440.5598\n",
      "1/1 - 0s - loss: 525.0416\n",
      "1/1 - 0s - loss: 504.9879\n",
      "1/1 - 0s - loss: 227.2545\n",
      "1/1 - 0s - loss: 165.3661\n",
      "Reducing exploration for all agents to 0.0316\n",
      "\n",
      "Episode 3: Starting computation.\n",
      "Random Seed Set to 103\n",
      "Episode 3: Finished running.\n",
      "Agent 0, Average Reward: -1506.1\n",
      "1/1 - 0s - loss: 23667.2246\n",
      "1/1 - 0s - loss: 17247.7891\n",
      "1/1 - 0s - loss: 6737.1406\n",
      "1/1 - 0s - loss: 2335.4585\n",
      "1/1 - 0s - loss: 6028.6401\n",
      "1/1 - 0s - loss: 11291.0908\n",
      "1/1 - 0s - loss: 9649.6660\n",
      "1/1 - 0s - loss: 3411.3713\n",
      "1/1 - 0s - loss: 702.6214\n",
      "1/1 - 0s - loss: 958.9478\n",
      "Reducing exploration for all agents to 0.0056\n",
      "\n",
      "Episode 4: Starting computation.\n",
      "Random Seed Set to 104\n",
      "Episode 4: Finished running.\n",
      "Agent 0, Average Reward: -3105.85\n",
      "1/1 - 0s - loss: 17327.0840\n",
      "1/1 - 0s - loss: 12476.5918\n",
      "1/1 - 0s - loss: 1349.2428\n",
      "1/1 - 0s - loss: 18466.1074\n",
      "1/1 - 0s - loss: 14582.4238\n",
      "1/1 - 0s - loss: 2579.1050\n",
      "1/1 - 0s - loss: 4071.6797\n",
      "1/1 - 0s - loss: 11826.6367\n",
      "1/1 - 0s - loss: 10699.8643\n",
      "1/1 - 0s - loss: 3589.3550\n",
      "Reducing exploration for all agents to 0.001\n",
      "\n",
      "Episode 5: Starting computation.\n",
      "Random Seed Set to 105\n",
      "Episode 5: Finished running.\n",
      "Agent 0, Average Reward: -229.92\n",
      "1/1 - 0s - loss: 520.3835\n",
      "1/1 - 0s - loss: 5121.9287\n",
      "1/1 - 0s - loss: 6902.5889\n",
      "1/1 - 0s - loss: 4004.3484\n",
      "1/1 - 0s - loss: 1093.9506\n",
      "1/1 - 0s - loss: 872.5118\n",
      "1/1 - 0s - loss: 4367.2988\n",
      "1/1 - 0s - loss: 5299.6924\n",
      "1/1 - 0s - loss: 2796.6606\n",
      "1/1 - 0s - loss: 474.1832\n",
      "Reducing exploration for all agents to 0.0002\n",
      "\n",
      "Episode 6: Starting computation.\n"
     ]
    }
   ],
   "source": [
    "Single_Cross_Triple8_MultiDQN_Agents.train(episodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Single_Cross_Triple8_MultiDQN_Agents.save(401)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Single_Cross_Triple8_MultiDQN_Agents.load(400,best = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working Directory set to: C:\\Users\\acabrejasegea\\Desktop\\15_Timescales_utc\\gamma_code\n",
      "Generating Cache...\n",
      "Cache generated.\n",
      "\n",
      "****************************\n",
      "*   COM Server dispatched  *\n",
      "****************************\n",
      "\n",
      "Attempting to load Model File: Single_Cross_Triple.inpx ...\n",
      "Model File load process successful.\n",
      "Simulation length set to 3601 seconds.\n",
      "Results from Previous Simulations: Deleted. Fresh Start Available.\n",
      "Fetched and containerized Network Object \n",
      "\n",
      "*******************************************************\n",
      "*                                                     *\n",
      "*                COM SETUP COMPLETE                   *\n",
      "*                                                     *\n",
      "*******************************************************\n",
      "\n",
      "Random seed set in simulator. Random Seed = 105\n",
      "Deploying Network Parser...\n",
      "Successful Network Crawl: Identified SignalControllers, Links, Lanes and Vehicle Inputs.\n",
      "\n",
      "Setting Simulation mode to: test\n",
      "Starting Deployments of Signal Control Units...\n",
      "SCUs successfully deployed. Elapsed time 0.14 seconds.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Episode_Queues, Cumulative_Episode_Delays,Cumulative_Episode_stop_Delays, Cumulative_Totale_network_delay,Cumulative_Totale_network_stop_delay  = Single_Cross_Triple8_MultiDQN_Agents.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "time = [t for t in range(len(Cumulative_Totale_network_stop_delay))]\n",
    "\n",
    "# Queues ovzer time for each junction\n",
    "for idx, queues in Episode_Queues.items():\n",
    "    queues = np.array(queues)\n",
    "    queues = queues.T\n",
    "    \n",
    "    plt.figure('1'+str(idx),figsize=(16, 9))\n",
    "    \n",
    "    Queuesdf = pd.DataFrame()\n",
    "    \n",
    "    Queuesdf['Time'] = time\n",
    "    Queues_legend = []\n",
    "    \n",
    "    for i, queue in enumerate(queues):\n",
    "        plt.plot(queue, label = \"Queue\"+str(i))\n",
    "        Queuesdf[str(i)] = queue\n",
    "        Queues_legend.append(\"Queue\"+str(i))\n",
    "        \n",
    "    plt.xlabel('Time [s]',fontsize=18)\n",
    "    plt.ylabel('Queue Length',fontsize=18)\n",
    "    plt.title('Junction {} Queue length'.format(idx),fontsize=18)\n",
    "    #plt.gca().legend(Queues_legend)\n",
    "    \n",
    "    Path = os.path.join(vissim_working_directory, model_name, \"Agents_Results\", Session_ID,\\\n",
    "                        \"Junction{}_Queues.png\".format(idx))               \n",
    "    plt.savefig(Path)\n",
    "    \n",
    "    csv_Path = os.path.join(vissim_working_directory, model_name, \"Agents_Results\", Session_ID,\\\n",
    "                        \"Junction{}_Queues.csv\".format(idx))        \n",
    "   \n",
    "    Queuesdf.to_csv(csv_Path,index=False)\n",
    "    plt.legend()\n",
    "        \n",
    "        \n",
    "# Accumulated delay over time for each junction\n",
    "for idx, delay in Cumulative_Episode_Delays.items():\n",
    "    \n",
    "    plt.figure('2'+str(idx),figsize=(16, 9))\n",
    "    \n",
    "    delaydf = pd.DataFrame()   \n",
    "    delaydf['Time'] = time\n",
    "    delaydf['Junction {} delay'.format(idx)] = delay\n",
    "    \n",
    "    plt.plot(delay)\n",
    "    plt.xlabel('Time [s]',fontsize=18)\n",
    "    plt.ylabel('Accumulated Delay',fontsize=18)\n",
    "    plt.title('Junction {} Delay'.format(idx),fontsize=18)\n",
    "    plt.gca().legend('Junction accumulated delay')\n",
    "    \n",
    "    Path = os.path.join(vissim_working_directory, model_name, \"Agents_Results\", Session_ID,\\\n",
    "                            \"Junction{}_Cumulative_Delay.png\".format(idx))\n",
    "    csv_Path = os.path.join(vissim_working_directory, model_name, \"Agents_Results\", Session_ID,\\\n",
    "                        \"Junction{}_Cumulative_Delay.csv\".format(idx))   \n",
    "    plt.savefig(Path)\n",
    "\n",
    "    delaydf.to_csv(csv_Path,index=False)\n",
    "    \n",
    "    \n",
    "# Accumulated stop delay over time for each junction\n",
    "for idx, stop_delay in Cumulative_Episode_stop_Delays.items():\n",
    "    \n",
    "    plt.figure('3'+str(idx),figsize=(16, 9))\n",
    "    \n",
    "    stop_delaydf = pd.DataFrame()   \n",
    "    stop_delaydf['Time'] = time\n",
    "    stop_delaydf['Junction {} stop delay'.format(idx)] = stop_delay\n",
    "\n",
    "    plt.plot(stop_delay)\n",
    "    plt.xlabel('Time [s]',fontsize=18)\n",
    "    plt.ylabel('Accumulated Stop Delay',fontsize=18)\n",
    "    plt.title('Junction {} Stop Delay'.format(idx),fontsize=18)\n",
    "    plt.gca().legend('Junction accumulated Stop delay')\n",
    "    \n",
    "    Path = os.path.join(vissim_working_directory, model_name, \"Agents_Results\", Session_ID,\\\n",
    "                            \"Junction{}_Cumulative_stop_Delay.png\".format(idx))\n",
    "    csv_Path = os.path.join(vissim_working_directory, model_name, \"Agents_Results\", Session_ID,\\\n",
    "                        \"Junction{}_Cumulative_stop_Delay.csv\".format(idx))\n",
    "    plt.savefig(Path)\n",
    "    stop_delaydf.to_csv(csv_Path,index=False)\n",
    "    \n",
    "# Global Accumulated delay over time\n",
    "plt.figure('4',figsize=(16,9))\n",
    "\n",
    "\n",
    "Global_delaydf = pd.DataFrame()   \n",
    "Global_delaydf['Time'] = time\n",
    "Global_delaydf['Global accumulated Delay'] = Cumulative_Totale_network_delay\n",
    "\n",
    "plt.plot(Cumulative_Totale_network_delay)\n",
    "plt.xlabel('Time [s]',fontsize=18)\n",
    "plt.ylabel('Global accumulated Delay',fontsize=18)\n",
    "plt.title('Global accumulated Delay',fontsize=18)\n",
    "plt.gca().legend('Global accumulated delay')\n",
    "\n",
    "Path = os.path.join(vissim_working_directory, model_name, \"Agents_Results\", Session_ID,\\\n",
    "                        \"Total_Cumulative_Delay.png\")\n",
    "csv_Path = os.path.join(vissim_working_directory, model_name, \"Agents_Results\", Session_ID,\\\n",
    "                        \"Total_Cumulative_Delay.csv\")\n",
    "plt.savefig(Path)\n",
    "Global_delaydf.to_csv(csv_Path,index=False)\n",
    "\n",
    "# Global Accumulated stop delay over time\n",
    "plt.figure('5'+str(idx),figsize=(16, 9))\n",
    "\n",
    "Global_stop_delaydf = pd.DataFrame()   \n",
    "Global_stop_delaydf['Time'] = time\n",
    "Global_stop_delaydf['Global accumulated stop Delay'] = Cumulative_Totale_network_stop_delay\n",
    "\n",
    "plt.plot(Cumulative_Totale_network_stop_delay)\n",
    "plt.xlabel('Time [s]',fontsize=18)\n",
    "plt.ylabel('Global accumulated stop Delay',fontsize=18)\n",
    "plt.title('Global accumulated stop Delay',fontsize=18)\n",
    "plt.gca().legend('Global accumulated stop Delay')\n",
    "\n",
    "Path = os.path.join(vissim_working_directory, model_name, \"Agents_Results\", Session_ID,\\\n",
    "                        \"Total_Cumulative_stop_Delay.png\")\n",
    "csv_Path = os.path.join(vissim_working_directory, model_name, \"Agents_Results\", Session_ID,\\\n",
    "                        \"Total_Cumulative_stop_Delay.csv\")\n",
    "plt.savefig(Path)\n",
    "Global_stop_delaydf.to_csv(csv_Path,index=False)\n",
    "\n",
    "\n",
    "# For the agent training\n",
    "\n",
    "for idx , agent in Single_Cross_Triple8_MultiDQN_Agents.Agents.items():  \n",
    "    plt.figure('6'+str(idx),figsize=(16, 9))\n",
    "    \n",
    "    Loss_rewarddf = pd.DataFrame()   \n",
    "    \n",
    "    plt.plot(agent.loss)\n",
    "    plt.xlabel('Episode',fontsize=18)\n",
    "    plt.ylabel('Loss',fontsize=18)\n",
    "    plt.title('Agent{} Loss over training'.format(idx),fontsize=18)\n",
    "    plt.gca().legend('Agent Loss over training')\n",
    "    \n",
    "    Path  = os.path.join(vissim_working_directory, model_name, \"Agents_Results\", Session_ID,\\\n",
    "                        \"Agent{}_Loss.png\".format(idx)) \n",
    "    plt.savefig(Path)\n",
    "    \n",
    "    csv_Path = os.path.join(vissim_working_directory, model_name, \"Agents_Results\", Session_ID,\\\n",
    "                           \"Agent{}_Loss_average_reward.csv\".format(idx)) \n",
    "    \n",
    "    \n",
    "    plt.figure('7'+str(idx),figsize=(16, 9))\n",
    "    plt.plot(agent.reward_storage)\n",
    "    plt.xlabel('Episode',fontsize=18)\n",
    "    plt.ylabel('Average reward',fontsize=18)\n",
    "    plt.title('Agent{} average reward over training'.format(idx),fontsize=18)\n",
    "    plt.gca().legend('Agent reward over training')\n",
    "    \n",
    "    Path  = os.path.join(vissim_working_directory, model_name, \"Agents_Results\", Session_ID,\\\n",
    "                        \"Agent{}_average_reward.png\".format(idx)) \n",
    "    plt.savefig(Path)\n",
    "    \n",
    "    \n",
    "    episode = [i for i in range(len(agent.reward_storage))]\n",
    "    \n",
    "    Loss_rewarddf['episode'] = episode \n",
    "    Loss_rewarddf['Agent{} loss'.format(idx)] = agent.loss\n",
    "    Loss_rewarddf['Agent{} Average_Reward'.format(idx)] = agent.reward_storage\n",
    "    \n",
    "    Loss_rewarddf.to_csv(csv_Path,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Single_Cross_Triple8_MultiDQN_Agents.demo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Five intersection DQN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "model_name  = 'Five_intersection'\n",
    "#vissim_working_directory =  'C:\\\\Users\\\\Rzhang\\\\Desktop\\\\MLforFlowOptimisationOrigine\\\\Vissim\\\\'\n",
    "vissim_working_directory = 'C:\\\\Users\\\\acabrejasegea\\\\OneDrive - The Alan Turing Institute\\\\Desktop\\\\ATI\\\\0_TMF\\\\MLforFlowOptimisation\\\\Vissim\\\\'\n",
    "\n",
    "sim_length = 3601\n",
    "\n",
    "agent_type = \"DuelingDDQN\"\n",
    "Session_ID = \"Five5transfert\"\n",
    "\n",
    "# all controller actions\n",
    "Five_intersection_dictionary =\\\n",
    "{\\\n",
    "    # Controller Number 0 \n",
    "   'junctions' : {0 : {'default_actions' :  {    0 : [1,1,1,0,0,0,0,0,0,0,0,0],\n",
    "                                             1 : [0,0,0,1,1,1,0,0,0,0,0,0],\n",
    "                                             2 : [0,0,0,0,0,0,1,1,1,0,0,0],\n",
    "                                             3 : [0,0,0,0,0,0,0,0,0,1,1,1],\n",
    "                                             4 : [1,0,0,0,0,0,1,0,0,0,0,0],\n",
    "                                             5 : [0,0,0,1,0,0,0,0,0,1,0,0],\n",
    "                                             6 : [0,1,1,0,0,0,0,1,1,0,0,0],\n",
    "                                             7 : [0,0,0,0,1,1,0,0,0,0,1,1]},\n",
    "         \n",
    "         'all_actions' :        {            0 : [1,1,1,0,0,0,0,0,0,0,0,0],\n",
    "                                             1 : [0,0,0,1,1,1,0,0,0,0,0,0],\n",
    "                                             2 : [0,0,0,0,0,0,1,1,1,0,0,0],\n",
    "                                             3 : [0,0,0,0,0,0,0,0,0,1,1,1],\n",
    "                                             4 : [1,0,0,0,0,0,1,0,0,0,0,0],\n",
    "                                             5 : [0,0,0,1,0,0,0,0,0,1,0,0],\n",
    "                                             6 : [0,1,1,0,0,0,0,1,1,0,0,0],\n",
    "                                             7 : [0,0,0,0,1,1,0,0,0,0,1,1]},\n",
    " \n",
    "         'link' : [],\n",
    "         'lane' : ['11-1', '11-2', '11-3', '12-1', '12-2', '12-3', '13-1', '13-2', '13-3', '14-1', '14-2', '14-3'],\n",
    "         \n",
    "         'controled_by_com' : True,\n",
    "         'agent_type' : agent_type,\n",
    "         'green_time' : 6,\n",
    "         'redamber_time' : 0,\n",
    "         'amber_time' : 3, \n",
    "         'red_time' : 0,\n",
    "         'state_size' : [13],\n",
    "         'state_type' : 'QueuesSig',\n",
    "         'reward_type' : 'Queues',\n",
    "         'queues_counter_ID' : [1,2,3,4,5,6,7,8,9,10,11,12]\n",
    "         },\n",
    "                  1 : {'default_actions' :  {    0 : [1,1,1,0,0,0,0,0,0,0,0,0],\n",
    "                                             1 : [0,0,0,1,1,1,0,0,0,0,0,0],\n",
    "                                             2 : [0,0,0,0,0,0,1,1,1,0,0,0],\n",
    "                                             3 : [0,0,0,0,0,0,0,0,0,1,1,1],\n",
    "                                             4 : [1,0,0,0,0,0,1,0,0,0,0,0],\n",
    "                                             5 : [0,0,0,1,0,0,0,0,0,1,0,0],\n",
    "                                             6 : [0,1,1,0,0,0,0,1,1,0,0,0],\n",
    "                                             7 : [0,0,0,0,1,1,0,0,0,0,1,1]},\n",
    "         \n",
    "         'all_actions' :        {            0 : [1,1,1,0,0,0,0,0,0,0,0,0],\n",
    "                                             1 : [0,0,0,1,1,1,0,0,0,0,0,0],\n",
    "                                             2 : [0,0,0,0,0,0,1,1,1,0,0,0],\n",
    "                                             3 : [0,0,0,0,0,0,0,0,0,1,1,1],\n",
    "                                             4 : [1,0,0,0,0,0,1,0,0,0,0,0],\n",
    "                                             5 : [0,0,0,1,0,0,0,0,0,1,0,0],\n",
    "                                             6 : [0,1,1,0,0,0,0,1,1,0,0,0],\n",
    "                                             7 : [0,0,0,0,1,1,0,0,0,0,1,1]},\n",
    " \n",
    "         'link' : [],\n",
    "         'lane' : ['21-1', '21-2', '21-3', '22-1', '22-2', '22-3', '23-1', '23-2', '23-3', '24-1', '24-2', '24-3'],\n",
    "         \n",
    "         'controled_by_com' : True,\n",
    "         'agent_type' : agent_type,\n",
    "         'green_time' : 6,\n",
    "         'redamber_time' : 0,\n",
    "         'amber_time' : 3, \n",
    "         'red_time' : 0,\n",
    "         'state_size' : [13],\n",
    "         'state_type' : 'QueuesSig',\n",
    "         'reward_type' : 'Queues' ,\n",
    "        'queues_counter_ID' : [13,14,15,16,17,18,19,20,21,22,23,24]\n",
    "         },\n",
    "                  2 : {'default_actions' :  {    0 : [1,1,1,0,0,0,0,0,0,0,0,0],\n",
    "                                             1 : [0,0,0,1,1,1,0,0,0,0,0,0],\n",
    "                                             2 : [0,0,0,0,0,0,1,1,1,0,0,0],\n",
    "                                             3 : [0,0,0,0,0,0,0,0,0,1,1,1],\n",
    "                                             4 : [1,0,0,0,0,0,1,0,0,0,0,0],\n",
    "                                             5 : [0,0,0,1,0,0,0,0,0,1,0,0],\n",
    "                                             6 : [0,1,1,0,0,0,0,1,1,0,0,0],\n",
    "                                             7 : [0,0,0,0,1,1,0,0,0,0,1,1]},\n",
    "         \n",
    "         'all_actions' :        {            0 : [1,1,1,0,0,0,0,0,0,0,0,0],\n",
    "                                             1 : [0,0,0,1,1,1,0,0,0,0,0,0],\n",
    "                                             2 : [0,0,0,0,0,0,1,1,1,0,0,0],\n",
    "                                             3 : [0,0,0,0,0,0,0,0,0,1,1,1],\n",
    "                                             4 : [1,0,0,0,0,0,1,0,0,0,0,0],\n",
    "                                             5 : [0,0,0,1,0,0,0,0,0,1,0,0],\n",
    "                                             6 : [0,1,1,0,0,0,0,1,1,0,0,0],\n",
    "                                             7 : [0,0,0,0,1,1,0,0,0,0,1,1]},\n",
    " \n",
    "         'link' : [],\n",
    "         'lane' : ['31-1', '31-2', '31-3', '32-1', '32-2', '32-3', '33-1', '33-2', '33-3', '34-1', '34-2', '34-3'],\n",
    "         \n",
    "         'controled_by_com' : True,\n",
    "         'agent_type' : agent_type,\n",
    "         'green_time' : 6,\n",
    "         'redamber_time' : 0,\n",
    "         'amber_time' : 3, \n",
    "         'red_time' : 0,\n",
    "         'state_size' : [13],\n",
    "         'state_type' : 'QueuesSig',\n",
    "         'reward_type' : 'Queues' ,\n",
    "         'queues_counter_ID' : [25,26,27,28,29,30,31,32,33,34,35,36]\n",
    "         },\n",
    "                  3 : {'default_actions' :  {    0 : [1,1,1,0,0,0,0,0,0,0,0,0],\n",
    "                                             1 : [0,0,0,1,1,1,0,0,0,0,0,0],\n",
    "                                             2 : [0,0,0,0,0,0,1,1,1,0,0,0],\n",
    "                                             3 : [0,0,0,0,0,0,0,0,0,1,1,1],\n",
    "                                             4 : [1,0,0,0,0,0,1,0,0,0,0,0],\n",
    "                                             5 : [0,0,0,1,0,0,0,0,0,1,0,0],\n",
    "                                             6 : [0,1,1,0,0,0,0,1,1,0,0,0],\n",
    "                                             7 : [0,0,0,0,1,1,0,0,0,0,1,1]},\n",
    "         \n",
    "         'all_actions' :        {            0 : [1,1,1,0,0,0,0,0,0,0,0,0],\n",
    "                                             1 : [0,0,0,1,1,1,0,0,0,0,0,0],\n",
    "                                             2 : [0,0,0,0,0,0,1,1,1,0,0,0],\n",
    "                                             3 : [0,0,0,0,0,0,0,0,0,1,1,1],\n",
    "                                             4 : [1,0,0,0,0,0,1,0,0,0,0,0],\n",
    "                                             5 : [0,0,0,1,0,0,0,0,0,1,0,0],\n",
    "                                             6 : [0,1,1,0,0,0,0,1,1,0,0,0],\n",
    "                                             7 : [0,0,0,0,1,1,0,0,0,0,1,1]},\n",
    " \n",
    "         'link' : [],\n",
    "         'lane' : ['41-1', '41-2', '41-3', '42-1', '42-2', '42-3', '43-1', '43-2', '43-3', '44-1', '44-2', '44-3'],\n",
    "         \n",
    "         'controled_by_com' : True,\n",
    "         'agent_type' : agent_type,\n",
    "         'green_time' : 6,\n",
    "         'redamber_time' : 0,\n",
    "         'amber_time' : 3, \n",
    "         'red_time' : 0,\n",
    "         'state_size' : [13],\n",
    "         'state_type' : 'QueuesSig',\n",
    "         'reward_type' : 'Queues' ,\n",
    "          'queues_counter_ID' : [37,38,39,40,41,42,43,44,45,46,47,48]\n",
    "         },\n",
    "                  4 : {'default_actions' :  {    0 : [1,1,1,0,0,0,0,0,0,0,0,0],\n",
    "                                             1 : [0,0,0,1,1,1,0,0,0,0,0,0],\n",
    "                                             2 : [0,0,0,0,0,0,1,1,1,0,0,0],\n",
    "                                             3 : [0,0,0,0,0,0,0,0,0,1,1,1],\n",
    "                                             4 : [1,0,0,0,0,0,1,0,0,0,0,0],\n",
    "                                             5 : [0,0,0,1,0,0,0,0,0,1,0,0],\n",
    "                                             6 : [0,1,1,0,0,0,0,1,1,0,0,0],\n",
    "                                             7 : [0,0,0,0,1,1,0,0,0,0,1,1]},\n",
    "         \n",
    "         'all_actions' :        {            0 : [1,1,1,0,0,0,0,0,0,0,0,0],\n",
    "                                             1 : [0,0,0,1,1,1,0,0,0,0,0,0],\n",
    "                                             2 : [0,0,0,0,0,0,1,1,1,0,0,0],\n",
    "                                             3 : [0,0,0,0,0,0,0,0,0,1,1,1],\n",
    "                                             4 : [1,0,0,0,0,0,1,0,0,0,0,0],\n",
    "                                             5 : [0,0,0,1,0,0,0,0,0,1,0,0],\n",
    "                                             6 : [0,1,1,0,0,0,0,1,1,0,0,0],\n",
    "                                             7 : [0,0,0,0,1,1,0,0,0,0,1,1]},\n",
    " \n",
    "         'link' : [],\n",
    "         'lane' : ['51-1', '51-2', '51-3', '52-1', '52-2', '52-3', '53-1', '53-2', '53-3', '54-1', '54-2', '54-3'],\n",
    "         \n",
    "         'controled_by_com' : True,\n",
    "         'agent_type' : agent_type,\n",
    "         'green_time' : 6,\n",
    "         'redamber_time' : 0,\n",
    "         'amber_time' : 3, \n",
    "         'red_time' : 0,\n",
    "         'state_size' : [13],\n",
    "         'state_type' : 'QueuesSig',\n",
    "         'reward_type' : 'Queues' ,\n",
    "         'queues_counter_ID' : [49,50,51,52,53,54,55,56,57,58,59,60]\n",
    "         }\n",
    "    },\n",
    "   'demand' : { 'default' : [400,400,400,400,400,400,400,400,400,400,400,400],\n",
    "             \n",
    "             0 : [200,200,200,200,200,200,200,200,200,200,200,200],\n",
    "             1 : [400,400,400,400,400,400,400,400,400,400,400,400],\n",
    "             2 : [500,900,500,500,900,500,500,900,500,500,900,500],\n",
    "             3 : [500,1000,500,500,1000,500,500,1000,500,500,1000,500],\n",
    "             4 : [500,700,500,500,700,500,500,700,500,500,700,500],\n",
    "             5 : [500,700,500,500,700,500,500,700,500,500,700,500],\n",
    "             6 : [500,1000,500,500,1000,500,500,1000,500,500,1000,500],\n",
    "             7 : [500,900,500,500,900,500,500,900,500,500,900,500],\n",
    "             8 : [400,400,400,400,400,400,400,400,400,400,400,400],\n",
    "             9 : [200,200,200,200,200,200,200,200,200,200,200,200]\n",
    "            }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "## DQN Hyperaramenters\n",
    "episodes = 400\n",
    "copy_weights_frequency = 20 # On a successfull run I copied the weight every 50\n",
    "\n",
    "PER_activated = True\n",
    "memory_size = 1000\n",
    "batch_size = 128\n",
    "\n",
    "gamma = 0.95\n",
    "alpha = 0.005"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Exploration Schedule (\"linear\" or \"geometric\")\n",
    "exploration_schedule = \"geometric\"\n",
    "epsilon_start = 1\n",
    "epsilon_end   = 0.001\n",
    "\n",
    "Random_Seed = 100\n",
    "\n",
    "def choose_schedule(exploration_schedule, espilon_start, epsilon_end, episodes):\n",
    "    if exploration_schedule == \"linear\":\n",
    "        epsilon_decay = 1.2*(epsilon_end - epsilon_start)/(episodes-1)\n",
    "        epsilon_sequence = [1 + epsilon_decay * entry for entry in range(episodes+1)]\n",
    "        epsilon_sequence = [0 if entry < 0 else entry for entry in epsilon_sequence]\n",
    "    elif exploration_schedule == \"geometric\":\n",
    "        epsilon_decay = np.power(epsilon_end/epsilon_start, 1./(episodes-1)) # Geometric decay\n",
    "        epsilon_sequence = [epsilon_start * epsilon_decay ** entry for entry in range(episodes+1)]\n",
    "    elif exploration_schedule == \"entropy\":\n",
    "        pass\n",
    "    else:\n",
    "        print(\"ERROR: Unrecognized choice of exploration schedule.\")\n",
    "        \n",
    "    # Plotting exploration schedule\n",
    "    plt.figure(figsize=(8,4.5))\n",
    "    x_series = np.array(range(1,episodes+1))\n",
    "    y_series = epsilon_sequence[0:episodes]\n",
    "    plt.plot(x_series, y_series, '-b')\n",
    "    plt.xlabel('Episodes')\n",
    "    plt.ylabel('Ratio of random exploration')\n",
    "    plt.title('Exploration schedule')\n",
    "    plt.show()\n",
    "    return(epsilon_sequence)\n",
    "\n",
    "epsilon_sequence = choose_schedule(exploration_schedule, epsilon_start, epsilon_end, episodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "Five_intersection_MultiDQN_Agents = MasterDQN_Agent(model_name, vissim_working_directory, sim_length, Five_intersection_dictionary,\\\n",
    "                gamma, alpha, agent_type, memory_size, PER_activated, batch_size, copy_weights_frequency, epsilon_sequence,\\\n",
    "                Random_Seed = Random_Seed, timesteps_per_second = 1, Session_ID = Session_ID, verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "Five_intersection_MultiDQN_Agents.prepopulate_memory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "Five_intersection_MultiDQN_Agents.train(episodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "Five_intersection_MultiDQN_Agents.save(401)\n",
    "Five_intersection_MultiDQN_Agents.load(400,best = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "Five_intersection_MultiDQN_Agents.Agents[0].load_agent(vissim_working_directory, 'Single_Cross_Triple', 'Single_Cross_Triple8_actions',400 , best = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "Episode_Queues, Cumulative_Episode_Delays,Cumulative_Episode_stop_Delays, Cumulative_Totale_network_delay,Cumulative_Totale_network_stop_delay = Five_intersection_MultiDQN_Agents.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "time = [t for t in range(len(Cumulative_Totale_network_stop_delay))]\n",
    "\n",
    "\n",
    "# Queues ovzer time for each junction\n",
    "for idx, queues in Episode_Queues.items():\n",
    "    queues = np.array(queues)\n",
    "    queues = queues.T\n",
    "    \n",
    "    plt.figure('1'+str(idx),figsize=(16, 9))\n",
    "    \n",
    "    Queuesdf = pd.DataFrame()\n",
    "    \n",
    "    Queuesdf['Time'] = time\n",
    "    \n",
    "    for i, queue in enumerate(queues):\n",
    "        plt.plot(queue)\n",
    "        Queuesdf[str(i)] = queue\n",
    "        \n",
    "    plt.xlabel('Time [s]')\n",
    "    plt.ylabel('Queue Length')\n",
    "    plt.title('Junction {} Queue length'.format(idx))\n",
    "    plt.gca().legend(('West Queue','South Queue', 'East Queue', 'North Queue'))\n",
    "    \n",
    "    Path = os.path.join(vissim_working_directory, model_name, \"Agents_Results\", Session_ID,\\\n",
    "                        \"Junction{}_Queues.png\".format(idx))               \n",
    "    plt.savefig(Path)\n",
    "    \n",
    "    csv_Path = os.path.join(vissim_working_directory, model_name, \"Agents_Results\", Session_ID,\\\n",
    "                        \"Junction{}_Queues.csv\".format(idx))        \n",
    "   \n",
    "    Queuesdf.to_csv(csv_Path,index=False)\n",
    "        \n",
    "        \n",
    "# Accumulated delay over time for each junction\n",
    "for idx, delay in Cumulative_Episode_Delays.items():\n",
    "    \n",
    "    plt.figure('2'+str(idx),figsize=(16, 9))\n",
    "    \n",
    "    delaydf = pd.DataFrame()   \n",
    "    delaydf['Time'] = time\n",
    "    delaydf['Junction {} delay'.format(idx)] = delay\n",
    "    \n",
    "    plt.plot(delay)\n",
    "    plt.xlabel('Time [s]')\n",
    "    plt.ylabel('Accumulated Delay')\n",
    "    plt.title('Junction {} Delay'.format(idx))\n",
    "    plt.gca().legend('Junction accumulated delay')\n",
    "    \n",
    "    Path = os.path.join(vissim_working_directory, model_name, \"Agents_Results\", Session_ID,\\\n",
    "                            \"Junction{}_Cumulative_Delay.png\".format(idx))\n",
    "    csv_Path = os.path.join(vissim_working_directory, model_name, \"Agents_Results\", Session_ID,\\\n",
    "                        \"Junction{}_Cumulative_Delay.csv\".format(idx))   \n",
    "    plt.savefig(Path)\n",
    "\n",
    "    delaydf.to_csv(csv_Path,index=False)\n",
    "    \n",
    "    \n",
    "# Accumulated stop delay over time for each junction\n",
    "for idx, stop_delay in Cumulative_Episode_stop_Delays.items():\n",
    "    \n",
    "    plt.figure('3'+str(idx),figsize=(16, 9))\n",
    "    \n",
    "    stop_delaydf = pd.DataFrame()   \n",
    "    stop_delaydf['Time'] = time\n",
    "    stop_delaydf['Junction {} stop delay'.format(idx)] = stop_delay\n",
    "\n",
    "    plt.plot(stop_delay)\n",
    "    plt.xlabel('Time [s]')\n",
    "    plt.ylabel('Accumulated Stop Delay')\n",
    "    plt.title('Junction {} Stop Delay'.format(idx))\n",
    "    plt.gca().legend('Junction accumulated Stop delay')\n",
    "    \n",
    "    Path = os.path.join(vissim_working_directory, model_name, \"Agents_Results\", Session_ID,\\\n",
    "                            \"Junction{}_Cumulative_stop_Delay.png\".format(idx))\n",
    "    csv_Path = os.path.join(vissim_working_directory, model_name, \"Agents_Results\", Session_ID,\\\n",
    "                        \"Junction{}_Cumulative_stop_Delay.csv\".format(idx))\n",
    "    plt.savefig(Path)\n",
    "    stop_delaydf.to_csv(csv_Path,index=False)\n",
    "    \n",
    "# Global Accumulated delay over time\n",
    "plt.figure('4',figsize=(16,9))\n",
    "\n",
    "\n",
    "Global_delaydf = pd.DataFrame()   \n",
    "Global_delaydf['Time'] = time\n",
    "Global_delaydf['Global accumulated Delay'] = Cumulative_Totale_network_delay\n",
    "\n",
    "plt.plot(Cumulative_Totale_network_delay)\n",
    "plt.xlabel('Time [s]')\n",
    "plt.ylabel('Global accumulated Delay')\n",
    "plt.title('Global accumulated Delay')\n",
    "plt.gca().legend('Global accumulated delay')\n",
    "\n",
    "Path = os.path.join(vissim_working_directory, model_name, \"Agents_Results\", Session_ID,\\\n",
    "                        \"Total_Cumulative_Delay.png\")\n",
    "csv_Path = os.path.join(vissim_working_directory, model_name, \"Agents_Results\", Session_ID,\\\n",
    "                        \"Total_Cumulative_Delay.csv\")\n",
    "plt.savefig(Path)\n",
    "Global_delaydf.to_csv(csv_Path,index=False)\n",
    "\n",
    "# Global Accumulated stop delay over time\n",
    "plt.figure('5'+str(idx),figsize=(16, 9))\n",
    "\n",
    "Global_stop_delaydf = pd.DataFrame()   \n",
    "Global_stop_delaydf['Time'] = time\n",
    "Global_stop_delaydf['Global accumulated stop Delay'] = Cumulative_Totale_network_stop_delay\n",
    "\n",
    "plt.plot(Cumulative_Totale_network_stop_delay)\n",
    "plt.xlabel('Time [s]')\n",
    "plt.ylabel('Global accumulated stop Delay')\n",
    "plt.title('Global accumulated stop Delay')\n",
    "plt.gca().legend('Global accumulated stop Delay')\n",
    "\n",
    "Path = os.path.join(vissim_working_directory, model_name, \"Agents_Results\", Session_ID,\\\n",
    "                        \"Total_Cumulative_stop_Delay.png\")\n",
    "csv_Path = os.path.join(vissim_working_directory, model_name, \"Agents_Results\", Session_ID,\\\n",
    "                        \"Total_Cumulative_stop_Delay.csv\")\n",
    "plt.savefig(Path)\n",
    "Global_stop_delaydf.to_csv(csv_Path,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "Five_intersection_MultiDQN_Agents.Agents[2] = Five_intersection_MultiDQN_Agents.Agents[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "Five_intersection_MultiDQN_Agents.demo()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
