{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "from Vissim_env_class import environment\n",
    "from MasterDQN_Agent import MasterDQN_Agent\n",
    "\n",
    "# General Libraries\n",
    "import numpy as np \n",
    "import pylab as plt\n",
    "import os\n",
    "import csv\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Single_Cross_Triple 8 actions DQN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name  = 'Single_Cross_Triple'\n",
    "#vissim_working_directory =  'C:\\\\Users\\\\Rzhang\\\\Desktop\\\\MLforFlowOptimisationOrigine\\\\Vissim\\\\'\n",
    "vissim_working_directory = \"C:\\\\Users\\\\acabrejasegea\\\\Desktop\\\\15_Timescales_utc\\\\Timescales_and_Discount_Factor_in_UTC\"\n",
    "\n",
    "sim_length = 3601\n",
    "timesteps_per_second = 1\n",
    "learning_iterations = 10\n",
    "actions_set = \"all_actions\"\n",
    "\n",
    "agent_type = \"DuelingDDQN\"\n",
    "Session_ID = \"SCT_8act_DuelingDDQN_common_memory_generation_2\"\n",
    "\n",
    "# all controller actions\n",
    "Single_Cross_Triple_dictionary8 =\\\n",
    "{\\\n",
    "    # Controller Number 0 \n",
    "   'junctions' : {0 : {'default_actions' :  {    0 : [1,1,1,0,0,0,0,0,0,0,0,0],\n",
    "                                             1 : [0,0,0,1,1,1,0,0,0,0,0,0],\n",
    "                                             2 : [0,0,0,0,0,0,1,1,1,0,0,0],\n",
    "                                             3 : [0,0,0,0,0,0,0,0,0,1,1,1],\n",
    "                                             4 : [1,0,0,0,0,0,1,0,0,0,0,0],\n",
    "                                             5 : [0,0,0,1,0,0,0,0,0,1,0,0],\n",
    "                                             6 : [0,1,1,0,0,0,0,1,1,0,0,0],\n",
    "                                             7 : [0,0,0,0,1,1,0,0,0,0,1,1]},\n",
    "         \n",
    "         'all_actions' :        {            0 : [1,1,1,0,0,0,0,0,0,0,0,0],\n",
    "                                             1 : [0,0,0,1,1,1,0,0,0,0,0,0],\n",
    "                                             2 : [0,0,0,0,0,0,1,1,1,0,0,0],\n",
    "                                             3 : [0,0,0,0,0,0,0,0,0,1,1,1],\n",
    "                                             4 : [1,0,0,0,0,0,1,0,0,0,0,0],\n",
    "                                             5 : [0,0,0,1,0,0,0,0,0,1,0,0],\n",
    "                                             6 : [0,1,1,0,0,0,0,1,1,0,0,0],\n",
    "                                             7 : [0,0,0,0,1,1,0,0,0,0,1,1]},\n",
    " \n",
    "         'link' : [1, 3, 5, 7],\n",
    "         'lane' : ['1-1', '1-2', '1-3', '3-1', '3-2', '3-3', '5-1', '5-2', '5-3', '7-1', '7-2', '7-3'],\n",
    "         \n",
    "         'controled_by_com' : True,\n",
    "         'agent_type' : agent_type,\n",
    "         'green_time' : 6,\n",
    "         'redamber_time' : 0,\n",
    "         'amber_time' : 3, \n",
    "         'red_time' : 0,\n",
    "         'state_size' : [13],\n",
    "         'state_type' : 'QueuesSig',\n",
    "         'reward_type' : 'Queues' ,\n",
    "         'queues_counter_ID' : [1,2,3,4,5,6,7,8,9,10,11,12]             \n",
    "         }\n",
    "    },\n",
    "   'demand' : { 'default' : [400, 400, 400, 400],\n",
    "             \n",
    "             0 : [300,300,300,300],\n",
    "             1 : [600,600,600,600],\n",
    "             2 : [1350,750,1350,750],\n",
    "             3 : [1500,750,1500,750],\n",
    "             4 : [1050,750,1050,750],\n",
    "             5 : [750,1050,750,1050],\n",
    "             6 : [750,1500,750,1500],\n",
    "             7 : [750,1350,750,1350],\n",
    "             8 : [600,600,600,600],\n",
    "             9 : [300,300,300,300]\n",
    "            }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "## DQN Hyperaramenters\n",
    "episodes = 400 \n",
    "copy_weights_frequency = 20 # On a successfull run I copied the weight every 50\n",
    "\n",
    "PER_activated = True\n",
    "memory_size = 5000\n",
    "batch_size = 128\n",
    "\n",
    "gamma = 0.9\n",
    "alpha = 0.005"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x324 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Exploration Schedule (\"linear\" or \"geometric\")\n",
    "exploration_schedule = \"linear\"\n",
    "epsilon_start = 1\n",
    "epsilon_end   = 0.001\n",
    "\n",
    "Random_Seed = 100\n",
    "\n",
    "def choose_schedule(exploration_schedule, espilon_start, epsilon_end, episodes):\n",
    "    if exploration_schedule == \"linear\":\n",
    "        epsilon_decay = 1.2*(epsilon_end - epsilon_start)/(episodes-1)\n",
    "        epsilon_sequence = [1 + epsilon_decay * entry for entry in range(episodes+1)]\n",
    "        epsilon_sequence = [0 if entry < 0 else entry for entry in epsilon_sequence]\n",
    "    elif exploration_schedule == \"geometric\":\n",
    "        epsilon_decay = np.power(epsilon_end/epsilon_start, 1./(episodes-1)) # Geometric decay\n",
    "        epsilon_sequence = [epsilon_start * epsilon_decay ** entry for entry in range(episodes+1)]\n",
    "    elif exploration_schedule == \"entropy\":\n",
    "        pass\n",
    "    else:\n",
    "        print(\"ERROR: Unrecognized choice of exploration schedule.\")\n",
    "        \n",
    "    # Plotting exploration schedule\n",
    "    plt.figure(figsize=(8,4.5))\n",
    "    x_series = np.array(range(1,episodes+1))\n",
    "    y_series = epsilon_sequence[0:episodes]\n",
    "    plt.plot(x_series, y_series, '-b')\n",
    "    plt.xlabel('Episodes')\n",
    "    plt.ylabel('Ratio of random exploration')\n",
    "    plt.title('Exploration schedule')\n",
    "    plt.show()\n",
    "    return(epsilon_sequence)\n",
    "\n",
    "epsilon_sequence = choose_schedule(exploration_schedule, epsilon_start, epsilon_end, episodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INTERSECTION 0: SETTING UP AGENT\n",
      "Model: \"model_10\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_11 (InputLayer)           [(None, 13)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_60 (Dense)                (None, 24)           336         input_11[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_61 (Dense)                (None, 24)           600         dense_60[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_64 (Dense)                (None, 24)           600         dense_61[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_62 (Dense)                (None, 24)           600         dense_61[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_65 (Dense)                (None, 1)            25          dense_64[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_63 (Dense)                (None, 8)            200         dense_62[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "policy (Lambda)                 (None, 8)            0           dense_65[0][0]                   \n",
      "                                                                 dense_63[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 2,361\n",
      "Trainable params: 2,361\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Deployed instance of Dueling Double Deep Q Learning Agent(s) at Intersection 0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Single_Cross_Triple8_MultiDQN_Agents = MasterDQN_Agent(model_name, vissim_working_directory,\\\n",
    "                                                       sim_length, Single_Cross_Triple_dictionary8,\\\n",
    "                                                       actions_set, gamma, alpha, agent_type,\\\n",
    "                                                       memory_size, PER_activated, batch_size,\\\n",
    "                                                       learning_iterations, copy_weights_frequency,\\\n",
    "                                                       epsilon_sequence,Random_Seed,\\\n",
    "                                                       timesteps_per_second, Session_ID,\\\n",
    "                                                       verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experience file not found. Generating now...\n",
      "Working Directory set to: C:\\Users\\acabrejasegea\\Desktop\\15_Timescales_utc\\Timescales_and_Discount_Factor_in_UTC\n",
      "Generating Cache...\n",
      "Cache generated.\n",
      "\n",
      "****************************\n",
      "*   COM Server dispatched  *\n",
      "****************************\n",
      "\n",
      "Attempting to load Model File: Single_Cross_Triple.inpx ...\n",
      "Failed load attempt 1/5. Re-attempting.\n",
      "Working Directory set to: C:\\Users\\acabrejasegea\\Desktop\\15_Timescales_utc\\Timescales_and_Discount_Factor_in_UTC\n",
      "Generating Cache...\n",
      "Cache generated.\n",
      "\n",
      "****************************\n",
      "*   COM Server dispatched  *\n",
      "****************************\n",
      "\n",
      "Attempting to load Model File: Single_Cross_Triple.inpx ...\n",
      "Model File load process successful.\n",
      "Simulation length set to 3601 seconds.\n",
      "Results from Previous Simulations: Deleted. Fresh Start Available.\n",
      "Fetched and containerized Network Object \n",
      "\n",
      "*******************************************************\n",
      "*                                                     *\n",
      "*                COM SETUP COMPLETE                   *\n",
      "*                                                     *\n",
      "*******************************************************\n",
      "\n",
      "Random seed set in simulator. Random Seed = 100\n",
      "Deploying Network Parser...\n",
      "Successful Network Crawl: Identified SignalControllers, Links, Lanes and Vehicle Inputs.\n",
      "\n",
      "Setting Simulation mode to: training\n",
      "Starting Deployments of Signal Control Units...\n",
      "SCUs successfully deployed. Elapsed time 0.27 seconds.\n",
      "\n",
      "After 0 actions taken by the Agents,  Agent 0 memory is 0.0 percent full\n",
      "Random Seed Set to 101\n",
      "Random Seed Set to 102\n",
      "After 1000 actions taken by the Agents,  Agent 0 memory is 20.0 percent full\n",
      "Random Seed Set to 103\n",
      "Random Seed Set to 104\n",
      "Random Seed Set to 105\n",
      "After 2000 actions taken by the Agents,  Agent 0 memory is 40.0 percent full\n",
      "Random Seed Set to 106\n",
      "Random Seed Set to 107\n",
      "Random Seed Set to 108\n",
      "After 3000 actions taken by the Agents,  Agent 0 memory is 60.0 percent full\n",
      "Random Seed Set to 109\n",
      "Random Seed Set to 110\n",
      "After 4000 actions taken by the Agents,  Agent 0 memory is 80.0 percent full\n",
      "Random Seed Set to 111\n",
      "Random Seed Set to 112\n",
      "Random Seed Set to 113\n",
      "Memory filled. Saving as:C:\\Users\\acabrejasegea\\Desktop\\15_Timescales_utc\\Timescales_and_Discount_Factor_in_UTC\\Single_Cross_Triple\\Agents_Results\\DuelingDDQN\\SCT_8act_DuelingDDQN_common_memory_generation_2\\Agent0_PERPre_5000.p\n"
     ]
    }
   ],
   "source": [
    "Single_Cross_Triple8_MultiDQN_Agents.prepopulate_memory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working Directory set to: C:\\Users\\acabrejasegea\\Desktop\\15_Timescales_utc\\Timescales_and_Discount_Factor_in_UTC\n",
      "Generating Cache...\n",
      "Cache generated.\n",
      "\n",
      "****************************\n",
      "*   COM Server dispatched  *\n",
      "****************************\n",
      "\n",
      "Attempting to load Model File: Single_Cross_Triple.inpx ...\n",
      "Model File load process successful.\n",
      "Simulation length set to 3601 seconds.\n",
      "Results from Previous Simulations: Deleted. Fresh Start Available.\n",
      "Fetched and containerized Network Object \n",
      "\n",
      "*******************************************************\n",
      "*                                                     *\n",
      "*                COM SETUP COMPLETE                   *\n",
      "*                                                     *\n",
      "*******************************************************\n",
      "\n",
      "Random seed set in simulator. Random Seed = 100\n",
      "Deploying Network Parser...\n",
      "Successful Network Crawl: Identified SignalControllers, Links, Lanes and Vehicle Inputs.\n",
      "\n",
      "Setting Simulation mode to: training\n",
      "Starting Deployments of Signal Control Units...\n",
      "SCUs successfully deployed. Elapsed time 0.24 seconds.\n",
      "\n",
      "start\n",
      "Random Seed Set to 101\n",
      "Episode 1: Finished running.\n",
      "Agent 0, Average Reward: -1210.7\n",
      "Saving architecture, weights, optimizer state for best agent-0\n",
      "1/1 - 0s - loss: 201842.8438\n",
      "1/1 - 0s - loss: 184469.7656\n",
      "1/1 - 0s - loss: 177702.1094\n",
      "1/1 - 0s - loss: 152080.7344\n",
      "1/1 - 0s - loss: 132584.3594\n",
      "1/1 - 0s - loss: 130675.6875\n",
      "1/1 - 0s - loss: 112732.7266\n",
      "1/1 - 0s - loss: 92017.1484\n",
      "1/1 - 0s - loss: 75569.3906\n",
      "1/1 - 0s - loss: 52431.7773\n",
      "Reducing exploration for all agents to 0.997\n",
      "\n",
      "Episode 2: Starting computation.\n",
      "Random Seed Set to 102\n",
      "Episode 2: Finished running.\n",
      "Agent 0, Average Reward: -1248.77\n",
      "1/1 - 0s - loss: 33075.4297\n",
      "1/1 - 0s - loss: 19583.7383\n",
      "1/1 - 0s - loss: 10792.5137\n",
      "1/1 - 0s - loss: 4189.5962\n",
      "1/1 - 0s - loss: 8658.7471\n",
      "1/1 - 0s - loss: 14275.3213\n",
      "1/1 - 0s - loss: 27188.8984\n",
      "1/1 - 0s - loss: 29960.8633\n",
      "1/1 - 0s - loss: 30055.8633\n",
      "1/1 - 0s - loss: 19799.6758\n",
      "Reducing exploration for all agents to 0.994\n",
      "\n",
      "Episode 3: Starting computation.\n",
      "Random Seed Set to 103\n",
      "Episode 3: Finished running.\n",
      "Agent 0, Average Reward: -1155.97\n",
      "Saving architecture, weights, optimizer state for best agent-0\n",
      "1/1 - 0s - loss: 12768.4482\n",
      "1/1 - 0s - loss: 7773.2568\n",
      "1/1 - 0s - loss: 3399.6560\n",
      "1/1 - 0s - loss: 2615.3054\n",
      "1/1 - 0s - loss: 2471.8572\n",
      "1/1 - 0s - loss: 2917.0681\n",
      "1/1 - 0s - loss: 5308.7866\n",
      "1/1 - 0s - loss: 7396.0322\n",
      "1/1 - 0s - loss: 7418.4141\n",
      "1/1 - 0s - loss: 7087.4629\n",
      "Reducing exploration for all agents to 0.991\n",
      "\n",
      "Episode 4: Starting computation.\n",
      "Random Seed Set to 104\n",
      "Episode 4: Finished running.\n",
      "Agent 0, Average Reward: -1291.8\n",
      "1/1 - 0s - loss: 6213.7549\n",
      "1/1 - 0s - loss: 5917.2480\n",
      "1/1 - 0s - loss: 4767.1416\n",
      "1/1 - 0s - loss: 3517.5911\n",
      "1/1 - 0s - loss: 3105.1189\n",
      "1/1 - 0s - loss: 2514.0408\n",
      "1/1 - 0s - loss: 1650.4233\n",
      "1/1 - 0s - loss: 1619.4602\n",
      "1/1 - 0s - loss: 1424.6843\n",
      "1/1 - 0s - loss: 1603.2266\n",
      "Reducing exploration for all agents to 0.988\n",
      "\n",
      "Episode 5: Starting computation.\n",
      "Random Seed Set to 105\n",
      "Episode 5: Finished running.\n",
      "Agent 0, Average Reward: -1261.46\n",
      "1/1 - 0s - loss: 1846.9751\n",
      "1/1 - 0s - loss: 1941.0952\n",
      "1/1 - 0s - loss: 2013.7107\n",
      "1/1 - 0s - loss: 1862.8882\n",
      "1/1 - 0s - loss: 1891.7444\n",
      "1/1 - 0s - loss: 1954.3000\n",
      "1/1 - 0s - loss: 1434.3251\n",
      "1/1 - 0s - loss: 1700.3198\n",
      "1/1 - 0s - loss: 1120.0647\n",
      "1/1 - 0s - loss: 1257.6903\n",
      "Reducing exploration for all agents to 0.985\n",
      "\n",
      "Episode 6: Starting computation.\n",
      "Random Seed Set to 106\n",
      "Episode 6: Finished running.\n",
      "Agent 0, Average Reward: -1001.79\n",
      "Saving architecture, weights, optimizer state for best agent-0\n",
      "1/1 - 0s - loss: 1120.7678\n",
      "1/1 - 0s - loss: 1269.2140\n",
      "1/1 - 0s - loss: 1139.1793\n",
      "1/1 - 0s - loss: 1517.8159\n",
      "1/1 - 0s - loss: 1234.4130\n",
      "1/1 - 0s - loss: 1317.2926\n",
      "1/1 - 0s - loss: 1243.0129\n",
      "1/1 - 0s - loss: 1039.4531\n",
      "1/1 - 0s - loss: 971.5368\n",
      "1/1 - 0s - loss: 1065.1420\n",
      "Reducing exploration for all agents to 0.982\n",
      "\n",
      "Episode 7: Starting computation.\n",
      "Random Seed Set to 107\n",
      "Episode 7: Finished running.\n",
      "Agent 0, Average Reward: -1364.11\n",
      "1/1 - 0s - loss: 932.1096\n",
      "1/1 - 0s - loss: 916.4292\n",
      "1/1 - 0s - loss: 1184.6323\n",
      "1/1 - 0s - loss: 1022.7252\n",
      "1/1 - 0s - loss: 695.8286\n",
      "1/1 - 0s - loss: 618.5837\n",
      "1/1 - 0s - loss: 998.8595\n",
      "1/1 - 0s - loss: 797.2472\n",
      "1/1 - 0s - loss: 870.9485\n",
      "1/1 - 0s - loss: 977.7456\n",
      "Reducing exploration for all agents to 0.979\n",
      "\n",
      "Episode 8: Starting computation.\n",
      "Random Seed Set to 108\n",
      "Episode 8: Finished running.\n",
      "Agent 0, Average Reward: -1264.64\n",
      "1/1 - 0s - loss: 708.2650\n",
      "1/1 - 0s - loss: 634.8649\n",
      "1/1 - 0s - loss: 782.5078\n",
      "1/1 - 0s - loss: 672.7833\n",
      "1/1 - 0s - loss: 718.7062\n",
      "1/1 - 0s - loss: 881.0756\n",
      "1/1 - 0s - loss: 835.3198\n",
      "1/1 - 0s - loss: 570.8104\n",
      "1/1 - 0s - loss: 727.4845\n",
      "1/1 - 0s - loss: 783.3309\n",
      "Reducing exploration for all agents to 0.976\n",
      "\n",
      "Episode 9: Starting computation.\n",
      "Random Seed Set to 109\n",
      "Episode 9: Finished running.\n",
      "Agent 0, Average Reward: -973.63\n",
      "Saving architecture, weights, optimizer state for best agent-0\n",
      "1/1 - 0s - loss: 590.4905\n",
      "1/1 - 0s - loss: 561.3820\n",
      "1/1 - 0s - loss: 680.9023\n",
      "1/1 - 0s - loss: 835.5531\n",
      "1/1 - 0s - loss: 676.8414\n",
      "1/1 - 0s - loss: 932.8896\n",
      "1/1 - 0s - loss: 894.3078\n",
      "1/1 - 0s - loss: 846.4171\n",
      "1/1 - 0s - loss: 739.9821\n",
      "1/1 - 0s - loss: 905.5538\n",
      "Reducing exploration for all agents to 0.973\n",
      "\n",
      "Episode 10: Starting computation.\n",
      "Random Seed Set to 110\n",
      "Episode 10: Finished running.\n",
      "Agent 0, Average Reward: -1152.89\n",
      "1/1 - 0s - loss: 747.7325\n",
      "1/1 - 0s - loss: 805.6768\n",
      "1/1 - 0s - loss: 517.9868\n",
      "1/1 - 0s - loss: 700.2683\n",
      "1/1 - 0s - loss: 613.3250\n",
      "1/1 - 0s - loss: 534.2632\n",
      "1/1 - 0s - loss: 760.7106\n",
      "1/1 - 0s - loss: 502.8783\n",
      "1/1 - 0s - loss: 675.5043\n",
      "1/1 - 0s - loss: 527.2861\n",
      "Reducing exploration for all agents to 0.97\n",
      "\n",
      "Episode 11: Starting computation.\n",
      "Random Seed Set to 111\n",
      "Episode 11: Finished running.\n",
      "Agent 0, Average Reward: -1216.17\n",
      "1/1 - 0s - loss: 597.8776\n",
      "1/1 - 0s - loss: 752.3298\n",
      "1/1 - 0s - loss: 520.1783\n",
      "1/1 - 0s - loss: 733.9111\n",
      "1/1 - 0s - loss: 681.1164\n",
      "1/1 - 0s - loss: 748.1447\n",
      "1/1 - 0s - loss: 671.1683\n",
      "1/1 - 0s - loss: 703.9949\n",
      "1/1 - 0s - loss: 597.5880\n",
      "1/1 - 0s - loss: 654.3484\n",
      "Reducing exploration for all agents to 0.967\n",
      "\n",
      "Episode 12: Starting computation.\n",
      "Random Seed Set to 112\n",
      "Episode 12: Finished running.\n",
      "Agent 0, Average Reward: -1198.58\n",
      "1/1 - 0s - loss: 663.3325\n",
      "1/1 - 0s - loss: 446.5219\n",
      "1/1 - 0s - loss: 595.5192\n",
      "1/1 - 0s - loss: 657.5853\n",
      "1/1 - 0s - loss: 712.9989\n",
      "1/1 - 0s - loss: 670.7820\n",
      "1/1 - 0s - loss: 649.8561\n",
      "1/1 - 0s - loss: 710.5230\n",
      "1/1 - 0s - loss: 757.2924\n",
      "1/1 - 0s - loss: 586.1509\n",
      "Reducing exploration for all agents to 0.9639\n",
      "\n",
      "Episode 13: Starting computation.\n",
      "Random Seed Set to 113\n",
      "Episode 13: Finished running.\n",
      "Agent 0, Average Reward: -1249.69\n",
      "1/1 - 0s - loss: 629.1175\n",
      "1/1 - 0s - loss: 680.5810\n",
      "1/1 - 0s - loss: 570.5344\n",
      "1/1 - 0s - loss: 584.1619\n",
      "1/1 - 0s - loss: 703.1508\n",
      "1/1 - 0s - loss: 450.4380\n",
      "1/1 - 0s - loss: 541.2829\n",
      "1/1 - 0s - loss: 474.6393\n",
      "1/1 - 0s - loss: 533.3083\n",
      "1/1 - 0s - loss: 421.0385\n",
      "Reducing exploration for all agents to 0.9609\n",
      "\n",
      "Episode 14: Starting computation.\n",
      "Random Seed Set to 114\n",
      "Episode 14: Finished running.\n",
      "Agent 0, Average Reward: -1315.66\n",
      "1/1 - 0s - loss: 435.7007\n",
      "1/1 - 0s - loss: 579.1985\n",
      "1/1 - 0s - loss: 565.3234\n",
      "1/1 - 0s - loss: 509.2587\n",
      "1/1 - 0s - loss: 609.9363\n",
      "1/1 - 0s - loss: 434.9198\n",
      "1/1 - 0s - loss: 527.6575\n",
      "1/1 - 0s - loss: 455.2298\n",
      "1/1 - 0s - loss: 551.8583\n",
      "1/1 - 0s - loss: 651.7231\n",
      "Reducing exploration for all agents to 0.9579\n",
      "\n",
      "Episode 15: Starting computation.\n",
      "Random Seed Set to 115\n",
      "Episode 15: Finished running.\n",
      "Agent 0, Average Reward: -1340.57\n",
      "1/1 - 0s - loss: 414.4526\n",
      "1/1 - 0s - loss: 377.8076\n",
      "1/1 - 0s - loss: 477.1571\n",
      "1/1 - 0s - loss: 357.2486\n",
      "1/1 - 0s - loss: 409.8569\n",
      "1/1 - 0s - loss: 612.4137\n",
      "1/1 - 0s - loss: 553.6359\n",
      "1/1 - 0s - loss: 320.4342\n",
      "1/1 - 0s - loss: 353.3479\n",
      "1/1 - 0s - loss: 426.0608\n",
      "Reducing exploration for all agents to 0.9549\n",
      "\n",
      "Episode 16: Starting computation.\n",
      "Random Seed Set to 116\n",
      "Episode 16: Finished running.\n",
      "Agent 0, Average Reward: -1057.31\n",
      "1/1 - 0s - loss: 536.1471\n",
      "1/1 - 0s - loss: 508.8869\n",
      "1/1 - 0s - loss: 454.4894\n",
      "1/1 - 0s - loss: 449.4738\n",
      "1/1 - 0s - loss: 491.8411\n",
      "1/1 - 0s - loss: 629.2599\n",
      "1/1 - 0s - loss: 461.3199\n",
      "1/1 - 0s - loss: 438.4697\n",
      "1/1 - 0s - loss: 511.0642\n",
      "1/1 - 0s - loss: 518.8544\n",
      "Reducing exploration for all agents to 0.9519\n",
      "\n",
      "Episode 17: Starting computation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Seed Set to 117\n",
      "Episode 17: Finished running.\n",
      "Agent 0, Average Reward: -1167.04\n",
      "1/1 - 0s - loss: 403.5495\n",
      "1/1 - 0s - loss: 642.1719\n",
      "1/1 - 0s - loss: 516.0325\n",
      "1/1 - 0s - loss: 512.4126\n",
      "1/1 - 0s - loss: 385.9888\n",
      "1/1 - 0s - loss: 663.8277\n",
      "1/1 - 0s - loss: 426.3775\n",
      "1/1 - 0s - loss: 610.2044\n",
      "1/1 - 0s - loss: 504.2627\n",
      "1/1 - 0s - loss: 473.7882\n",
      "Reducing exploration for all agents to 0.9489\n",
      "\n",
      "Episode 18: Starting computation.\n",
      "Random Seed Set to 118\n",
      "Episode 18: Finished running.\n",
      "Agent 0, Average Reward: -999.34\n",
      "1/1 - 0s - loss: 591.7959\n",
      "1/1 - 0s - loss: 562.7068\n",
      "1/1 - 0s - loss: 464.1369\n",
      "1/1 - 0s - loss: 402.8173\n",
      "1/1 - 0s - loss: 370.2311\n",
      "1/1 - 0s - loss: 520.5810\n",
      "1/1 - 0s - loss: 513.0887\n",
      "1/1 - 0s - loss: 408.3979\n",
      "1/1 - 0s - loss: 391.9613\n",
      "1/1 - 0s - loss: 362.6369\n",
      "Reducing exploration for all agents to 0.9459\n",
      "\n",
      "Episode 19: Starting computation.\n",
      "Random Seed Set to 119\n",
      "Episode 19: Finished running.\n",
      "Agent 0, Average Reward: -875.24\n",
      "Saving architecture, weights, optimizer state for best agent-0\n",
      "1/1 - 0s - loss: 464.1721\n",
      "1/1 - 0s - loss: 458.6238\n",
      "1/1 - 0s - loss: 669.6456\n",
      "1/1 - 0s - loss: 436.4094\n",
      "1/1 - 0s - loss: 601.5625\n",
      "1/1 - 0s - loss: 616.5984\n",
      "1/1 - 0s - loss: 641.4616\n",
      "1/1 - 0s - loss: 477.9862\n",
      "1/1 - 0s - loss: 474.5807\n",
      "1/1 - 0s - loss: 538.3273\n",
      "Reducing exploration for all agents to 0.9429\n",
      "\n",
      "Episode 20: Starting computation.\n",
      "Random Seed Set to 120\n",
      "Episode 20: Finished running.\n",
      "Agent 0, Average Reward: -743.2\n",
      "Saving architecture, weights, optimizer state for best agent-0\n",
      "1/1 - 0s - loss: 680.8909\n",
      "1/1 - 0s - loss: 703.8967\n",
      "1/1 - 0s - loss: 663.0231\n",
      "1/1 - 0s - loss: 595.7928\n",
      "1/1 - 0s - loss: 721.5400\n",
      "1/1 - 0s - loss: 721.1392\n",
      "1/1 - 0s - loss: 764.4344\n",
      "1/1 - 0s - loss: 683.8162\n",
      "1/1 - 0s - loss: 576.0041\n",
      "1/1 - 0s - loss: 697.7587\n",
      "Weights succesfully copied to Target model for Agent 0.\n",
      "Saving architecture, weights and optimizer state for agent-0\n",
      "Dumping agent-0 memory into pickle file\n",
      "Dumping Training Results into pickle file.\n",
      "Dumping Loss Results into pickle file.\n",
      "Reducing exploration for all agents to 0.9399\n",
      "\n",
      "Episode 21: Starting computation.\n",
      "Random Seed Set to 121\n",
      "Episode 21: Finished running.\n",
      "Agent 0, Average Reward: -808.04\n",
      "1/1 - 0s - loss: 162124.3281\n",
      "1/1 - 0s - loss: 119664.6328\n",
      "1/1 - 0s - loss: 72047.9609\n",
      "1/1 - 0s - loss: 22635.5020\n",
      "1/1 - 0s - loss: 2396.4536\n",
      "1/1 - 0s - loss: 32760.3535\n",
      "1/1 - 0s - loss: 74840.5859\n",
      "1/1 - 0s - loss: 65728.1953\n",
      "1/1 - 0s - loss: 31259.5430\n",
      "1/1 - 0s - loss: 8162.5645\n",
      "Reducing exploration for all agents to 0.9369\n",
      "\n",
      "Episode 22: Starting computation.\n",
      "Random Seed Set to 122\n",
      "Episode 22: Finished running.\n",
      "Agent 0, Average Reward: -808.79\n",
      "1/1 - 0s - loss: 2969.3357\n",
      "1/1 - 0s - loss: 12484.8281\n",
      "1/1 - 0s - loss: 27756.2910\n",
      "1/1 - 0s - loss: 32575.3770\n",
      "1/1 - 0s - loss: 33603.7070\n",
      "1/1 - 0s - loss: 26804.4043\n",
      "1/1 - 0s - loss: 16615.8535\n",
      "1/1 - 0s - loss: 7045.2036\n",
      "1/1 - 0s - loss: 2393.1572\n",
      "1/1 - 0s - loss: 2533.7542\n",
      "Reducing exploration for all agents to 0.9339\n",
      "\n",
      "Episode 23: Starting computation.\n",
      "Random Seed Set to 123\n",
      "Episode 23: Finished running.\n",
      "Agent 0, Average Reward: -950.96\n",
      "1/1 - 0s - loss: 9513.6338\n",
      "1/1 - 0s - loss: 14991.4814\n",
      "1/1 - 0s - loss: 14056.8145\n",
      "1/1 - 0s - loss: 9448.6602\n",
      "1/1 - 0s - loss: 5859.2124\n",
      "1/1 - 0s - loss: 2116.4016\n",
      "1/1 - 0s - loss: 1102.4237\n",
      "1/1 - 0s - loss: 2779.3362\n",
      "1/1 - 0s - loss: 5100.4497\n",
      "1/1 - 0s - loss: 7754.4150\n",
      "Reducing exploration for all agents to 0.9309\n",
      "\n",
      "Episode 24: Starting computation.\n",
      "Random Seed Set to 124\n",
      "Episode 24: Finished running.\n",
      "Agent 0, Average Reward: -1424.25\n",
      "1/1 - 0s - loss: 6905.5483\n",
      "1/1 - 0s - loss: 5872.9590\n",
      "1/1 - 0s - loss: 3564.7573\n",
      "1/1 - 0s - loss: 2084.2041\n",
      "1/1 - 0s - loss: 865.6817\n",
      "1/1 - 0s - loss: 1373.4491\n",
      "1/1 - 0s - loss: 2944.1433\n",
      "1/1 - 0s - loss: 3637.5945\n",
      "1/1 - 0s - loss: 4618.7500\n",
      "1/1 - 0s - loss: 3088.9141\n",
      "Reducing exploration for all agents to 0.9279\n",
      "\n",
      "Episode 25: Starting computation.\n",
      "Random Seed Set to 125\n",
      "Episode 25: Finished running.\n",
      "Agent 0, Average Reward: -1404.3\n",
      "1/1 - 0s - loss: 1373.4138\n",
      "1/1 - 0s - loss: 904.1819\n",
      "1/1 - 0s - loss: 1340.5856\n",
      "1/1 - 0s - loss: 1554.4451\n",
      "1/1 - 0s - loss: 1871.8381\n",
      "1/1 - 0s - loss: 2556.6829\n",
      "1/1 - 0s - loss: 2105.3845\n",
      "1/1 - 0s - loss: 2095.3752\n",
      "1/1 - 0s - loss: 1254.2656\n",
      "1/1 - 0s - loss: 1226.8573\n",
      "Reducing exploration for all agents to 0.9249\n",
      "\n",
      "Episode 26: Starting computation.\n",
      "Random Seed Set to 126\n",
      "Episode 26: Finished running.\n",
      "Agent 0, Average Reward: -1217.39\n",
      "1/1 - 0s - loss: 1051.2108\n",
      "1/1 - 0s - loss: 1766.9337\n",
      "1/1 - 0s - loss: 1465.7329\n",
      "1/1 - 0s - loss: 1573.9607\n",
      "1/1 - 0s - loss: 2118.3438\n",
      "1/1 - 0s - loss: 1508.8625\n",
      "1/1 - 0s - loss: 844.7887\n",
      "1/1 - 0s - loss: 862.3461\n",
      "1/1 - 0s - loss: 1452.5441\n",
      "1/1 - 0s - loss: 1215.8623\n",
      "Reducing exploration for all agents to 0.9219\n",
      "\n",
      "Episode 27: Starting computation.\n",
      "Random Seed Set to 127\n",
      "Episode 27: Finished running.\n",
      "Agent 0, Average Reward: -915.92\n",
      "1/1 - 0s - loss: 1716.7386\n",
      "1/1 - 0s - loss: 1532.2325\n",
      "1/1 - 0s - loss: 1231.1597\n",
      "1/1 - 0s - loss: 1426.3105\n",
      "1/1 - 0s - loss: 1257.8159\n",
      "1/1 - 0s - loss: 1182.2607\n",
      "1/1 - 0s - loss: 704.8560\n",
      "1/1 - 0s - loss: 1374.4850\n",
      "1/1 - 0s - loss: 1076.4166\n",
      "1/1 - 0s - loss: 1032.5477\n",
      "Reducing exploration for all agents to 0.9189\n",
      "\n",
      "Episode 28: Starting computation.\n",
      "Random Seed Set to 128\n",
      "Episode 28: Finished running.\n",
      "Agent 0, Average Reward: -1396.27\n",
      "1/1 - 0s - loss: 948.3344\n",
      "1/1 - 0s - loss: 723.2252\n",
      "1/1 - 0s - loss: 1332.3220\n",
      "1/1 - 0s - loss: 1131.4852\n",
      "1/1 - 0s - loss: 805.5240\n",
      "1/1 - 0s - loss: 1062.7821\n",
      "1/1 - 0s - loss: 914.1534\n",
      "1/1 - 0s - loss: 1100.5587\n",
      "1/1 - 0s - loss: 1213.7914\n",
      "1/1 - 0s - loss: 750.7697\n",
      "Reducing exploration for all agents to 0.9159\n",
      "\n",
      "Episode 29: Starting computation.\n",
      "Random Seed Set to 129\n",
      "Episode 29: Finished running.\n",
      "Agent 0, Average Reward: -1361.31\n",
      "1/1 - 0s - loss: 675.3323\n",
      "1/1 - 0s - loss: 940.9304\n",
      "1/1 - 0s - loss: 831.2967\n",
      "1/1 - 0s - loss: 707.0489\n",
      "1/1 - 0s - loss: 858.4235\n",
      "1/1 - 0s - loss: 961.7681\n",
      "1/1 - 0s - loss: 1231.2290\n",
      "1/1 - 0s - loss: 889.5854\n",
      "1/1 - 0s - loss: 725.0573\n",
      "1/1 - 0s - loss: 1026.2363\n",
      "Reducing exploration for all agents to 0.9129\n",
      "\n",
      "Episode 30: Starting computation.\n",
      "Random Seed Set to 130\n",
      "Episode 30: Finished running.\n",
      "Agent 0, Average Reward: -1188.94\n",
      "1/1 - 0s - loss: 842.8304\n",
      "1/1 - 0s - loss: 1080.2450\n",
      "1/1 - 0s - loss: 973.0582\n",
      "1/1 - 0s - loss: 1146.7926\n",
      "1/1 - 0s - loss: 866.2402\n",
      "1/1 - 0s - loss: 2112.9949\n",
      "1/1 - 0s - loss: 892.4815\n",
      "1/1 - 0s - loss: 764.5842\n",
      "1/1 - 0s - loss: 1145.7308\n",
      "1/1 - 0s - loss: 1040.5847\n",
      "Reducing exploration for all agents to 0.9099\n",
      "\n",
      "Episode 31: Starting computation.\n",
      "Random Seed Set to 131\n",
      "Episode 31: Finished running.\n",
      "Agent 0, Average Reward: -1392.3\n",
      "1/1 - 0s - loss: 956.4424\n",
      "1/1 - 0s - loss: 1215.7043\n",
      "1/1 - 0s - loss: 902.7976\n",
      "1/1 - 0s - loss: 903.5508\n",
      "1/1 - 0s - loss: 1065.8835\n",
      "1/1 - 0s - loss: 696.2164\n",
      "1/1 - 0s - loss: 814.7845\n",
      "1/1 - 0s - loss: 905.5472\n",
      "1/1 - 0s - loss: 1142.2836\n",
      "1/1 - 0s - loss: 841.1369\n",
      "Reducing exploration for all agents to 0.9069\n",
      "\n",
      "Episode 32: Starting computation.\n",
      "Random Seed Set to 132\n",
      "Episode 32: Finished running.\n",
      "Agent 0, Average Reward: -1358.02\n",
      "1/1 - 0s - loss: 1461.6393\n",
      "1/1 - 0s - loss: 707.6290\n",
      "1/1 - 0s - loss: 1089.9614\n",
      "1/1 - 0s - loss: 698.2741\n",
      "1/1 - 0s - loss: 872.0529\n",
      "1/1 - 0s - loss: 1371.5328\n",
      "1/1 - 0s - loss: 775.5355\n",
      "1/1 - 0s - loss: 786.6785\n",
      "1/1 - 0s - loss: 740.7562\n",
      "1/1 - 0s - loss: 688.5895\n",
      "Reducing exploration for all agents to 0.9039\n",
      "\n",
      "Episode 33: Starting computation.\n",
      "Random Seed Set to 133\n",
      "Episode 33: Finished running.\n",
      "Agent 0, Average Reward: -1332.11\n",
      "1/1 - 0s - loss: 967.2221\n",
      "1/1 - 0s - loss: 560.4813\n",
      "1/1 - 0s - loss: 821.4313\n",
      "1/1 - 0s - loss: 910.5096\n",
      "1/1 - 0s - loss: 829.7447\n",
      "1/1 - 0s - loss: 622.1155\n",
      "1/1 - 0s - loss: 588.1141\n",
      "1/1 - 0s - loss: 1260.4110\n",
      "1/1 - 0s - loss: 676.9711\n",
      "1/1 - 0s - loss: 822.9744\n",
      "Reducing exploration for all agents to 0.9009\n",
      "\n",
      "Episode 34: Starting computation.\n",
      "Random Seed Set to 134\n",
      "Episode 34: Finished running.\n",
      "Agent 0, Average Reward: -1321.3\n",
      "1/1 - 0s - loss: 531.4218\n",
      "1/1 - 0s - loss: 930.3019\n",
      "1/1 - 0s - loss: 688.3871\n",
      "1/1 - 0s - loss: 562.5414\n",
      "1/1 - 0s - loss: 749.3732\n",
      "1/1 - 0s - loss: 765.0164\n",
      "1/1 - 0s - loss: 778.5092\n",
      "1/1 - 0s - loss: 805.1028\n",
      "1/1 - 0s - loss: 1316.8149\n",
      "1/1 - 0s - loss: 642.6024\n",
      "Reducing exploration for all agents to 0.8978\n",
      "\n",
      "Episode 35: Starting computation.\n",
      "Random Seed Set to 135\n",
      "Episode 35: Finished running.\n",
      "Agent 0, Average Reward: -1263.97\n",
      "1/1 - 0s - loss: 725.9843\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 - 0s - loss: 884.0272\n",
      "1/1 - 0s - loss: 772.5463\n",
      "1/1 - 0s - loss: 949.6962\n",
      "1/1 - 0s - loss: 1252.6549\n",
      "1/1 - 0s - loss: 1152.5448\n",
      "1/1 - 0s - loss: 1046.2303\n",
      "1/1 - 0s - loss: 1082.5089\n",
      "1/1 - 0s - loss: 978.3016\n",
      "1/1 - 0s - loss: 655.2192\n",
      "Reducing exploration for all agents to 0.8948\n",
      "\n",
      "Episode 36: Starting computation.\n",
      "Random Seed Set to 136\n",
      "Episode 36: Finished running.\n",
      "Agent 0, Average Reward: -1087.85\n",
      "1/1 - 0s - loss: 833.5324\n",
      "1/1 - 0s - loss: 893.3594\n",
      "1/1 - 0s - loss: 667.1432\n",
      "1/1 - 0s - loss: 668.9224\n",
      "1/1 - 0s - loss: 679.3233\n",
      "1/1 - 0s - loss: 578.8237\n",
      "1/1 - 0s - loss: 874.6443\n",
      "1/1 - 0s - loss: 548.2042\n",
      "1/1 - 0s - loss: 692.7748\n",
      "1/1 - 0s - loss: 693.7940\n",
      "Reducing exploration for all agents to 0.8918\n",
      "\n",
      "Episode 37: Starting computation.\n",
      "Random Seed Set to 137\n",
      "Episode 37: Finished running.\n",
      "Agent 0, Average Reward: -1157.67\n",
      "1/1 - 0s - loss: 763.3217\n",
      "1/1 - 0s - loss: 809.4360\n",
      "1/1 - 0s - loss: 681.6513\n",
      "1/1 - 0s - loss: 808.8076\n",
      "1/1 - 0s - loss: 1183.1942\n",
      "1/1 - 0s - loss: 714.5792\n",
      "1/1 - 0s - loss: 1169.9208\n",
      "1/1 - 0s - loss: 626.3665\n",
      "1/1 - 0s - loss: 656.7651\n",
      "1/1 - 0s - loss: 758.5283\n",
      "Reducing exploration for all agents to 0.8888\n",
      "\n",
      "Episode 38: Starting computation.\n",
      "Random Seed Set to 138\n",
      "Episode 38: Finished running.\n",
      "Agent 0, Average Reward: -1073.38\n",
      "1/1 - 0s - loss: 1162.7145\n",
      "1/1 - 0s - loss: 722.6035\n",
      "1/1 - 0s - loss: 790.5208\n",
      "1/1 - 0s - loss: 658.9245\n",
      "1/1 - 0s - loss: 1340.2986\n",
      "1/1 - 0s - loss: 637.0419\n",
      "1/1 - 0s - loss: 825.1788\n",
      "1/1 - 0s - loss: 1152.7690\n",
      "1/1 - 0s - loss: 1552.3325\n",
      "1/1 - 0s - loss: 899.1341\n",
      "Reducing exploration for all agents to 0.8858\n",
      "\n",
      "Episode 39: Starting computation.\n",
      "Random Seed Set to 139\n",
      "Episode 39: Finished running.\n",
      "Agent 0, Average Reward: -998.44\n",
      "1/1 - 0s - loss: 665.3636\n",
      "1/1 - 0s - loss: 770.2553\n",
      "1/1 - 0s - loss: 801.0176\n",
      "1/1 - 0s - loss: 946.0429\n",
      "1/1 - 0s - loss: 703.9944\n",
      "1/1 - 0s - loss: 719.2560\n",
      "1/1 - 0s - loss: 653.9192\n",
      "1/1 - 0s - loss: 814.2675\n",
      "1/1 - 0s - loss: 975.6357\n",
      "1/1 - 0s - loss: 700.3521\n",
      "Reducing exploration for all agents to 0.8828\n",
      "\n",
      "Episode 40: Starting computation.\n",
      "Random Seed Set to 140\n",
      "Episode 40: Finished running.\n",
      "Agent 0, Average Reward: -831.05\n",
      "1/1 - 0s - loss: 751.6459\n",
      "1/1 - 0s - loss: 852.8443\n",
      "1/1 - 0s - loss: 615.3268\n",
      "1/1 - 0s - loss: 864.5916\n",
      "1/1 - 0s - loss: 755.7935\n",
      "1/1 - 0s - loss: 1075.4736\n",
      "1/1 - 0s - loss: 999.1378\n",
      "1/1 - 0s - loss: 852.3735\n",
      "1/1 - 0s - loss: 679.8717\n",
      "1/1 - 0s - loss: 781.6901\n",
      "Weights succesfully copied to Target model for Agent 0.\n",
      "Saving architecture, weights and optimizer state for agent-0\n",
      "Dumping agent-0 memory into pickle file\n",
      "Dumping Training Results into pickle file.\n",
      "Dumping Loss Results into pickle file.\n",
      "Reducing exploration for all agents to 0.8798\n",
      "\n",
      "Episode 41: Starting computation.\n",
      "Random Seed Set to 141\n",
      "Episode 41: Finished running.\n",
      "Agent 0, Average Reward: -1136.2\n",
      "1/1 - 0s - loss: 143012.6875\n",
      "1/1 - 0s - loss: 93770.7656\n",
      "1/1 - 0s - loss: 23739.7988\n",
      "1/1 - 0s - loss: 5219.5269\n",
      "1/1 - 0s - loss: 64540.2109\n",
      "1/1 - 0s - loss: 78630.2422\n",
      "1/1 - 0s - loss: 52803.7344\n",
      "1/1 - 0s - loss: 8936.4189\n",
      "1/1 - 0s - loss: 3738.3049\n",
      "1/1 - 0s - loss: 20988.2676\n",
      "Reducing exploration for all agents to 0.8768\n",
      "\n",
      "Episode 42: Starting computation.\n",
      "Random Seed Set to 142\n",
      "Episode 42: Finished running.\n",
      "Agent 0, Average Reward: -1203.36\n",
      "1/1 - 0s - loss: 41813.0312\n",
      "1/1 - 0s - loss: 44043.4219\n",
      "1/1 - 0s - loss: 34335.4492\n",
      "1/1 - 0s - loss: 13945.2715\n",
      "1/1 - 0s - loss: 2763.5718\n",
      "1/1 - 0s - loss: 5848.2710\n",
      "1/1 - 0s - loss: 19299.2637\n",
      "1/1 - 0s - loss: 25864.3203\n",
      "1/1 - 0s - loss: 19549.7168\n",
      "1/1 - 0s - loss: 8988.7197\n",
      "Reducing exploration for all agents to 0.8738\n",
      "\n",
      "Episode 43: Starting computation.\n",
      "Random Seed Set to 143\n",
      "Episode 43: Finished running.\n",
      "Agent 0, Average Reward: -1631.35\n",
      "1/1 - 0s - loss: 2094.5581\n",
      "1/1 - 0s - loss: 5601.7988\n",
      "1/1 - 0s - loss: 11201.2139\n",
      "1/1 - 0s - loss: 16596.0957\n",
      "1/1 - 0s - loss: 12576.2881\n",
      "1/1 - 0s - loss: 7020.2217\n",
      "1/1 - 0s - loss: 2953.6716\n",
      "1/1 - 0s - loss: 3457.2446\n",
      "1/1 - 0s - loss: 6180.0176\n",
      "1/1 - 0s - loss: 7915.3135\n",
      "Reducing exploration for all agents to 0.8708\n",
      "\n",
      "Episode 44: Starting computation.\n",
      "Random Seed Set to 144\n",
      "Episode 44: Finished running.\n",
      "Agent 0, Average Reward: -1333.45\n",
      "1/1 - 0s - loss: 6319.1680\n",
      "1/1 - 0s - loss: 3160.5706\n",
      "1/1 - 0s - loss: 2319.6555\n",
      "1/1 - 0s - loss: 2981.2056\n",
      "1/1 - 0s - loss: 3407.7798\n",
      "1/1 - 0s - loss: 5263.4663\n",
      "1/1 - 0s - loss: 4128.5259\n",
      "1/1 - 0s - loss: 3251.1064\n",
      "1/1 - 0s - loss: 2445.6443\n",
      "1/1 - 0s - loss: 2261.1768\n",
      "Reducing exploration for all agents to 0.8678\n",
      "\n",
      "Episode 45: Starting computation.\n",
      "Random Seed Set to 145\n",
      "Episode 45: Finished running.\n",
      "Agent 0, Average Reward: -1489.07\n",
      "1/1 - 0s - loss: 3554.9888\n",
      "1/1 - 0s - loss: 4483.6973\n",
      "1/1 - 0s - loss: 2659.4102\n",
      "1/1 - 0s - loss: 1784.1810\n",
      "1/1 - 0s - loss: 2015.0563\n",
      "1/1 - 0s - loss: 1628.7133\n",
      "1/1 - 0s - loss: 2722.0542\n",
      "1/1 - 0s - loss: 2474.8601\n",
      "1/1 - 0s - loss: 2754.0203\n",
      "1/1 - 0s - loss: 3056.9038\n",
      "Reducing exploration for all agents to 0.8648\n",
      "\n",
      "Episode 46: Starting computation.\n",
      "Random Seed Set to 146\n",
      "Episode 46: Finished running.\n",
      "Agent 0, Average Reward: -886.79\n",
      "1/1 - 0s - loss: 1787.0312\n",
      "1/1 - 0s - loss: 2023.6917\n",
      "1/1 - 0s - loss: 1775.4679\n",
      "1/1 - 0s - loss: 1863.2136\n",
      "1/1 - 0s - loss: 2180.3521\n",
      "1/1 - 0s - loss: 1688.2924\n",
      "1/1 - 0s - loss: 1235.5670\n",
      "1/1 - 0s - loss: 1916.2875\n",
      "1/1 - 0s - loss: 2239.9233\n",
      "1/1 - 0s - loss: 2199.6794\n",
      "Reducing exploration for all agents to 0.8618\n",
      "\n",
      "Episode 47: Starting computation.\n",
      "Random Seed Set to 147\n",
      "Episode 47: Finished running.\n",
      "Agent 0, Average Reward: -1368.09\n",
      "1/1 - 0s - loss: 1606.0248\n",
      "1/1 - 0s - loss: 1853.0020\n",
      "1/1 - 0s - loss: 1255.7203\n",
      "1/1 - 0s - loss: 1632.7729\n",
      "1/1 - 0s - loss: 2019.1453\n",
      "1/1 - 0s - loss: 1879.9585\n",
      "1/1 - 0s - loss: 1943.9491\n",
      "1/1 - 0s - loss: 2531.3062\n",
      "1/1 - 0s - loss: 1499.5503\n",
      "1/1 - 0s - loss: 1257.1431\n",
      "Reducing exploration for all agents to 0.8588\n",
      "\n",
      "Episode 48: Starting computation.\n",
      "Random Seed Set to 148\n",
      "Episode 48: Finished running.\n",
      "Agent 0, Average Reward: -1261.65\n",
      "1/1 - 0s - loss: 1282.9080\n",
      "1/1 - 0s - loss: 1484.4290\n",
      "1/1 - 0s - loss: 1970.8928\n",
      "1/1 - 0s - loss: 2411.7009\n",
      "1/1 - 0s - loss: 1686.4517\n",
      "1/1 - 0s - loss: 2327.8401\n",
      "1/1 - 0s - loss: 1678.9099\n",
      "1/1 - 0s - loss: 1317.5948\n",
      "1/1 - 0s - loss: 2385.2261\n",
      "1/1 - 0s - loss: 1975.8627\n",
      "Reducing exploration for all agents to 0.8558\n",
      "\n",
      "Episode 49: Starting computation.\n",
      "Random Seed Set to 149\n",
      "Episode 49: Finished running.\n",
      "Agent 0, Average Reward: -989.45\n",
      "1/1 - 0s - loss: 2545.0637\n",
      "1/1 - 0s - loss: 1680.3275\n",
      "1/1 - 0s - loss: 1429.8292\n",
      "1/1 - 0s - loss: 1392.7711\n",
      "1/1 - 0s - loss: 1723.7218\n",
      "1/1 - 0s - loss: 1768.1050\n",
      "1/1 - 0s - loss: 1368.2294\n",
      "1/1 - 0s - loss: 1403.6490\n",
      "1/1 - 0s - loss: 1655.2732\n",
      "1/1 - 0s - loss: 1758.7726\n",
      "Reducing exploration for all agents to 0.8528\n",
      "\n",
      "Episode 50: Starting computation.\n",
      "Random Seed Set to 150\n",
      "Episode 50: Finished running.\n",
      "Agent 0, Average Reward: -1356.78\n",
      "1/1 - 0s - loss: 1720.9869\n",
      "1/1 - 0s - loss: 1290.3628\n",
      "1/1 - 0s - loss: 2198.4695\n",
      "1/1 - 0s - loss: 2181.7869\n",
      "1/1 - 0s - loss: 1480.9484\n",
      "1/1 - 0s - loss: 1406.1567\n",
      "1/1 - 0s - loss: 1272.3303\n",
      "1/1 - 0s - loss: 1393.5846\n",
      "1/1 - 0s - loss: 1975.2775\n",
      "1/1 - 0s - loss: 1414.1359\n",
      "Reducing exploration for all agents to 0.8498\n",
      "\n",
      "Episode 51: Starting computation.\n",
      "Random Seed Set to 151\n",
      "Episode 51: Finished running.\n",
      "Agent 0, Average Reward: -1038.23\n",
      "1/1 - 0s - loss: 1828.7761\n",
      "1/1 - 0s - loss: 1105.9003\n",
      "1/1 - 0s - loss: 2312.8972\n",
      "1/1 - 0s - loss: 1401.6783\n",
      "1/1 - 0s - loss: 1465.2375\n",
      "1/1 - 0s - loss: 1519.3885\n",
      "1/1 - 0s - loss: 1497.2130\n",
      "1/1 - 0s - loss: 1444.9084\n",
      "1/1 - 0s - loss: 1638.9933\n",
      "1/1 - 0s - loss: 1491.5099\n",
      "Reducing exploration for all agents to 0.8468\n",
      "\n",
      "Episode 52: Starting computation.\n",
      "Random Seed Set to 152\n",
      "Episode 52: Finished running.\n",
      "Agent 0, Average Reward: -1138.47\n",
      "1/1 - 0s - loss: 2202.6965\n",
      "1/1 - 0s - loss: 1509.3054\n",
      "1/1 - 0s - loss: 1318.2135\n",
      "1/1 - 0s - loss: 1347.4022\n",
      "1/1 - 0s - loss: 1407.3522\n",
      "1/1 - 0s - loss: 1228.3210\n",
      "1/1 - 0s - loss: 1115.3065\n",
      "1/1 - 0s - loss: 1450.0386\n",
      "1/1 - 0s - loss: 1723.0510\n",
      "1/1 - 0s - loss: 1731.9567\n",
      "Reducing exploration for all agents to 0.8438\n",
      "\n",
      "Episode 53: Starting computation.\n",
      "Random Seed Set to 153\n",
      "Episode 53: Finished running.\n",
      "Agent 0, Average Reward: -1311.8\n",
      "1/1 - 0s - loss: 2352.7756\n",
      "1/1 - 0s - loss: 1668.4193\n",
      "1/1 - 0s - loss: 1453.7893\n",
      "1/1 - 0s - loss: 1427.8809\n",
      "1/1 - 0s - loss: 1742.5978\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 - 0s - loss: 1975.4844\n",
      "1/1 - 0s - loss: 1387.6908\n",
      "1/1 - 0s - loss: 2200.3782\n",
      "1/1 - 0s - loss: 1886.0212\n",
      "1/1 - 0s - loss: 2072.3899\n",
      "Reducing exploration for all agents to 0.8408\n",
      "\n",
      "Episode 54: Starting computation.\n",
      "Random Seed Set to 154\n",
      "Episode 54: Finished running.\n",
      "Agent 0, Average Reward: -978.05\n",
      "1/1 - 0s - loss: 1481.3159\n",
      "1/1 - 0s - loss: 1312.8153\n",
      "1/1 - 0s - loss: 1512.7598\n",
      "1/1 - 0s - loss: 1336.5615\n",
      "1/1 - 0s - loss: 1488.2651\n",
      "1/1 - 0s - loss: 1908.0385\n",
      "1/1 - 0s - loss: 1763.8533\n",
      "1/1 - 0s - loss: 1117.5140\n",
      "1/1 - 0s - loss: 1401.7266\n",
      "1/1 - 0s - loss: 1384.1270\n",
      "Reducing exploration for all agents to 0.8378\n",
      "\n",
      "Episode 55: Starting computation.\n",
      "Random Seed Set to 155\n",
      "Episode 55: Finished running.\n",
      "Agent 0, Average Reward: -1150.12\n",
      "1/1 - 0s - loss: 1418.0151\n",
      "1/1 - 0s - loss: 2125.9460\n",
      "1/1 - 0s - loss: 1289.7863\n",
      "1/1 - 0s - loss: 1463.0846\n",
      "1/1 - 0s - loss: 1990.2461\n",
      "1/1 - 0s - loss: 1895.6453\n",
      "1/1 - 0s - loss: 1205.1333\n",
      "1/1 - 0s - loss: 1285.1147\n",
      "1/1 - 0s - loss: 1958.3167\n",
      "1/1 - 0s - loss: 1733.3250\n",
      "Reducing exploration for all agents to 0.8348\n",
      "\n",
      "Episode 56: Starting computation.\n",
      "Random Seed Set to 156\n",
      "Episode 56: Finished running.\n",
      "Agent 0, Average Reward: -1227.8\n",
      "1/1 - 0s - loss: 1524.7369\n",
      "1/1 - 0s - loss: 1720.2236\n",
      "1/1 - 0s - loss: 1188.1100\n",
      "1/1 - 0s - loss: 1278.0375\n",
      "1/1 - 0s - loss: 1808.8783\n",
      "1/1 - 0s - loss: 1431.8768\n",
      "1/1 - 0s - loss: 1381.6932\n",
      "1/1 - 0s - loss: 1576.8722\n",
      "1/1 - 0s - loss: 1217.0155\n",
      "1/1 - 0s - loss: 1579.1708\n",
      "Reducing exploration for all agents to 0.8317\n",
      "\n",
      "Episode 57: Starting computation.\n",
      "Random Seed Set to 157\n",
      "Episode 57: Finished running.\n",
      "Agent 0, Average Reward: -1044.13\n",
      "1/1 - 0s - loss: 1587.8257\n",
      "1/1 - 0s - loss: 1227.5013\n",
      "1/1 - 0s - loss: 1237.0885\n",
      "1/1 - 0s - loss: 2456.8250\n",
      "1/1 - 0s - loss: 1181.7476\n",
      "1/1 - 0s - loss: 2500.4751\n",
      "1/1 - 0s - loss: 1670.6882\n",
      "1/1 - 0s - loss: 2698.0525\n",
      "1/1 - 0s - loss: 1718.7872\n",
      "1/1 - 0s - loss: 1570.3618\n",
      "Reducing exploration for all agents to 0.8287\n",
      "\n",
      "Episode 58: Starting computation.\n",
      "Random Seed Set to 158\n",
      "Episode 58: Finished running.\n",
      "Agent 0, Average Reward: -1004.7\n",
      "1/1 - 0s - loss: 1985.5719\n",
      "1/1 - 0s - loss: 2062.9878\n",
      "1/1 - 0s - loss: 1685.5133\n",
      "1/1 - 0s - loss: 1466.8347\n",
      "1/1 - 0s - loss: 1438.9248\n",
      "1/1 - 0s - loss: 1813.9172\n",
      "1/1 - 0s - loss: 1953.9755\n",
      "1/1 - 0s - loss: 1402.0425\n",
      "1/1 - 0s - loss: 1495.1396\n",
      "1/1 - 0s - loss: 2237.4131\n",
      "Reducing exploration for all agents to 0.8257\n",
      "\n",
      "Episode 59: Starting computation.\n",
      "Random Seed Set to 159\n",
      "Episode 59: Finished running.\n",
      "Agent 0, Average Reward: -1447.73\n",
      "1/1 - 0s - loss: 1284.4452\n",
      "1/1 - 0s - loss: 1435.2103\n",
      "1/1 - 0s - loss: 1652.5280\n",
      "1/1 - 0s - loss: 1672.3197\n",
      "1/1 - 0s - loss: 1541.6571\n",
      "1/1 - 0s - loss: 1488.9283\n",
      "1/1 - 0s - loss: 1011.1390\n",
      "1/1 - 0s - loss: 1828.0652\n",
      "1/1 - 0s - loss: 1285.9348\n",
      "1/1 - 0s - loss: 1475.1265\n",
      "Reducing exploration for all agents to 0.8227\n",
      "\n",
      "Episode 60: Starting computation.\n",
      "Random Seed Set to 160\n",
      "Episode 60: Finished running.\n",
      "Agent 0, Average Reward: -1302.86\n",
      "1/1 - 0s - loss: 2178.0767\n",
      "1/1 - 0s - loss: 1231.3054\n",
      "1/1 - 0s - loss: 2215.1711\n",
      "1/1 - 0s - loss: 2166.5447\n",
      "1/1 - 0s - loss: 1580.2568\n",
      "1/1 - 0s - loss: 1378.5902\n",
      "1/1 - 0s - loss: 1338.8668\n",
      "1/1 - 0s - loss: 1886.3475\n",
      "1/1 - 0s - loss: 1509.1123\n",
      "1/1 - 0s - loss: 1411.6400\n",
      "Weights succesfully copied to Target model for Agent 0.\n",
      "Saving architecture, weights and optimizer state for agent-0\n",
      "Dumping agent-0 memory into pickle file\n",
      "Dumping Training Results into pickle file.\n",
      "Dumping Loss Results into pickle file.\n",
      "Reducing exploration for all agents to 0.8197\n",
      "\n",
      "Episode 61: Starting computation.\n",
      "Random Seed Set to 161\n",
      "Episode 61: Finished running.\n",
      "Agent 0, Average Reward: -1294.52\n",
      "1/1 - 0s - loss: 114136.0391\n",
      "1/1 - 0s - loss: 58998.2266\n",
      "1/1 - 0s - loss: 9729.8750\n",
      "1/1 - 0s - loss: 15886.8457\n",
      "1/1 - 0s - loss: 60852.9648\n",
      "1/1 - 0s - loss: 69346.3594\n",
      "1/1 - 0s - loss: 23280.9824\n",
      "1/1 - 0s - loss: 3729.3787\n",
      "1/1 - 0s - loss: 15702.6475\n",
      "1/1 - 0s - loss: 33749.0898\n",
      "Reducing exploration for all agents to 0.8167\n",
      "\n",
      "Episode 62: Starting computation.\n",
      "Random Seed Set to 162\n",
      "Episode 62: Finished running.\n",
      "Agent 0, Average Reward: -485.06\n",
      "Saving architecture, weights, optimizer state for best agent-0\n",
      "1/1 - 0s - loss: 40531.8438\n",
      "1/1 - 0s - loss: 26604.2598\n",
      "1/1 - 0s - loss: 7973.2905\n",
      "1/1 - 0s - loss: 2939.4644\n",
      "1/1 - 0s - loss: 9820.0400\n",
      "1/1 - 0s - loss: 22519.3809\n",
      "1/1 - 0s - loss: 21046.1562\n",
      "1/1 - 0s - loss: 10248.3818\n",
      "1/1 - 0s - loss: 4419.8955\n",
      "1/1 - 0s - loss: 4111.7749\n",
      "Reducing exploration for all agents to 0.8137\n",
      "\n",
      "Episode 63: Starting computation.\n",
      "Random Seed Set to 163\n",
      "Episode 63: Finished running.\n",
      "Agent 0, Average Reward: -1035.67\n",
      "1/1 - 0s - loss: 8641.5332\n",
      "1/1 - 0s - loss: 15045.2900\n",
      "1/1 - 0s - loss: 12957.3125\n",
      "1/1 - 0s - loss: 9713.1836\n",
      "1/1 - 0s - loss: 3147.8284\n",
      "1/1 - 0s - loss: 3665.4395\n",
      "1/1 - 0s - loss: 7398.9614\n",
      "1/1 - 0s - loss: 8911.0283\n",
      "1/1 - 0s - loss: 8329.1602\n",
      "1/1 - 0s - loss: 6936.7563\n",
      "Reducing exploration for all agents to 0.8107\n",
      "\n",
      "Episode 64: Starting computation.\n",
      "Random Seed Set to 164\n",
      "Episode 64: Finished running.\n",
      "Agent 0, Average Reward: -1071.9\n",
      "1/1 - 0s - loss: 3318.1951\n",
      "1/1 - 0s - loss: 3309.2803\n",
      "1/1 - 0s - loss: 6000.0635\n",
      "1/1 - 0s - loss: 6786.4180\n",
      "1/1 - 0s - loss: 5674.0015\n",
      "1/1 - 0s - loss: 3526.3643\n",
      "1/1 - 0s - loss: 2048.5569\n",
      "1/1 - 0s - loss: 3586.0803\n",
      "1/1 - 0s - loss: 3608.7251\n",
      "1/1 - 0s - loss: 5148.7529\n",
      "Reducing exploration for all agents to 0.8077\n",
      "\n",
      "Episode 65: Starting computation.\n",
      "Random Seed Set to 165\n",
      "Episode 65: Finished running.\n",
      "Agent 0, Average Reward: -1274.17\n",
      "1/1 - 0s - loss: 3327.2888\n",
      "1/1 - 0s - loss: 4090.5544\n",
      "1/1 - 0s - loss: 4063.8313\n",
      "1/1 - 0s - loss: 3670.0571\n",
      "1/1 - 0s - loss: 3619.8486\n",
      "1/1 - 0s - loss: 4363.0288\n",
      "1/1 - 0s - loss: 4729.5898\n",
      "1/1 - 0s - loss: 2937.3350\n",
      "1/1 - 0s - loss: 3215.8406\n",
      "1/1 - 0s - loss: 2095.2551\n",
      "Reducing exploration for all agents to 0.8047\n",
      "\n",
      "Episode 66: Starting computation.\n",
      "Random Seed Set to 166\n",
      "Episode 66: Finished running.\n",
      "Agent 0, Average Reward: -1235.51\n",
      "1/1 - 0s - loss: 2857.1501\n",
      "1/1 - 0s - loss: 4562.0718\n",
      "1/1 - 0s - loss: 2748.8242\n",
      "1/1 - 0s - loss: 3186.9128\n",
      "1/1 - 0s - loss: 2165.6995\n",
      "1/1 - 0s - loss: 2608.3098\n",
      "1/1 - 0s - loss: 3910.3977\n",
      "1/1 - 0s - loss: 3138.7517\n",
      "1/1 - 0s - loss: 3580.6060\n",
      "1/1 - 0s - loss: 2292.1692\n",
      "Reducing exploration for all agents to 0.8017\n",
      "\n",
      "Episode 67: Starting computation.\n",
      "Random Seed Set to 167\n",
      "Episode 67: Finished running.\n",
      "Agent 0, Average Reward: -1274.62\n",
      "1/1 - 0s - loss: 2071.3325\n",
      "1/1 - 0s - loss: 2671.0723\n",
      "1/1 - 0s - loss: 2650.2654\n",
      "1/1 - 0s - loss: 3578.7434\n",
      "1/1 - 0s - loss: 3902.7517\n",
      "1/1 - 0s - loss: 3749.4883\n",
      "1/1 - 0s - loss: 2357.2847\n",
      "1/1 - 0s - loss: 4022.9707\n",
      "1/1 - 0s - loss: 3060.5151\n",
      "1/1 - 0s - loss: 3161.0151\n",
      "Reducing exploration for all agents to 0.7987\n",
      "\n",
      "Episode 68: Starting computation.\n",
      "Random Seed Set to 168\n",
      "Episode 68: Finished running.\n",
      "Agent 0, Average Reward: -1026.85\n",
      "1/1 - 0s - loss: 2671.2646\n",
      "1/1 - 0s - loss: 2605.5562\n",
      "1/1 - 0s - loss: 2766.6218\n",
      "1/1 - 0s - loss: 3389.7971\n",
      "1/1 - 0s - loss: 2766.2734\n",
      "1/1 - 0s - loss: 3981.9021\n",
      "1/1 - 0s - loss: 2058.1279\n",
      "1/1 - 0s - loss: 1786.0974\n",
      "1/1 - 0s - loss: 2468.5798\n",
      "1/1 - 0s - loss: 2281.3787\n",
      "Reducing exploration for all agents to 0.7957\n",
      "\n",
      "Episode 69: Starting computation.\n",
      "Random Seed Set to 169\n",
      "Episode 69: Finished running.\n",
      "Agent 0, Average Reward: -1299.49\n",
      "1/1 - 0s - loss: 2727.3083\n",
      "1/1 - 0s - loss: 2636.6050\n",
      "1/1 - 0s - loss: 2815.2344\n",
      "1/1 - 0s - loss: 2543.5105\n",
      "1/1 - 0s - loss: 3022.0552\n",
      "1/1 - 0s - loss: 1752.5304\n",
      "1/1 - 0s - loss: 2314.4897\n",
      "1/1 - 0s - loss: 3254.4993\n",
      "1/1 - 0s - loss: 2286.2070\n",
      "1/1 - 0s - loss: 2097.7598\n",
      "Reducing exploration for all agents to 0.7927\n",
      "\n",
      "Episode 70: Starting computation.\n",
      "Random Seed Set to 170\n",
      "Episode 70: Finished running.\n",
      "Agent 0, Average Reward: -1393.05\n",
      "1/1 - 0s - loss: 2177.0562\n",
      "1/1 - 0s - loss: 3167.2063\n",
      "1/1 - 0s - loss: 2403.8909\n",
      "1/1 - 0s - loss: 2359.4863\n",
      "1/1 - 0s - loss: 2127.6780\n",
      "1/1 - 0s - loss: 1948.1382\n",
      "1/1 - 0s - loss: 1996.8827\n",
      "1/1 - 0s - loss: 2694.5667\n",
      "1/1 - 0s - loss: 1882.2070\n",
      "1/1 - 0s - loss: 2309.7490\n",
      "Reducing exploration for all agents to 0.7897\n",
      "\n",
      "Episode 71: Starting computation.\n",
      "Random Seed Set to 171\n",
      "Episode 71: Finished running.\n",
      "Agent 0, Average Reward: -1426.59\n",
      "1/1 - 0s - loss: 2462.0593\n",
      "1/1 - 0s - loss: 3769.8862\n",
      "1/1 - 0s - loss: 3075.1428\n",
      "1/1 - 0s - loss: 2347.9099\n",
      "1/1 - 0s - loss: 3289.8787\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 - 0s - loss: 2133.1934\n",
      "1/1 - 0s - loss: 1603.1205\n",
      "1/1 - 0s - loss: 2606.2874\n",
      "1/1 - 0s - loss: 2750.4282\n",
      "1/1 - 0s - loss: 4320.3979\n",
      "Reducing exploration for all agents to 0.7867\n",
      "\n",
      "Episode 72: Starting computation.\n",
      "Random Seed Set to 172\n",
      "Episode 72: Finished running.\n",
      "Agent 0, Average Reward: -1300.74\n",
      "1/1 - 0s - loss: 1545.8694\n",
      "1/1 - 0s - loss: 1654.6511\n",
      "1/1 - 0s - loss: 2110.7458\n",
      "1/1 - 0s - loss: 2010.3522\n",
      "1/1 - 0s - loss: 1567.4131\n",
      "1/1 - 0s - loss: 2171.5645\n",
      "1/1 - 0s - loss: 2157.8157\n",
      "1/1 - 0s - loss: 2222.4749\n",
      "1/1 - 0s - loss: 3137.9783\n",
      "1/1 - 0s - loss: 1817.1481\n",
      "Reducing exploration for all agents to 0.7837\n",
      "\n",
      "Episode 73: Starting computation.\n",
      "Random Seed Set to 173\n",
      "Episode 73: Finished running.\n",
      "Agent 0, Average Reward: -1539.93\n",
      "1/1 - 0s - loss: 2515.5361\n",
      "1/1 - 0s - loss: 3256.5442\n",
      "1/1 - 0s - loss: 1820.9358\n",
      "1/1 - 0s - loss: 2063.4600\n",
      "1/1 - 0s - loss: 1497.6387\n",
      "1/1 - 0s - loss: 1706.3116\n",
      "1/1 - 0s - loss: 1892.1003\n",
      "1/1 - 0s - loss: 2262.0156\n",
      "1/1 - 0s - loss: 2326.0422\n",
      "1/1 - 0s - loss: 2117.0886\n",
      "Reducing exploration for all agents to 0.7807\n",
      "\n",
      "Episode 74: Starting computation.\n",
      "Random Seed Set to 174\n",
      "Episode 74: Finished running.\n",
      "Agent 0, Average Reward: -1125.8\n",
      "1/1 - 0s - loss: 1981.4434\n",
      "1/1 - 0s - loss: 2181.0420\n",
      "1/1 - 0s - loss: 1829.9825\n",
      "1/1 - 0s - loss: 2019.3668\n",
      "1/1 - 0s - loss: 2108.5581\n",
      "1/1 - 0s - loss: 2309.9053\n",
      "1/1 - 0s - loss: 2058.2466\n",
      "1/1 - 0s - loss: 2179.2297\n",
      "1/1 - 0s - loss: 1820.4569\n",
      "1/1 - 0s - loss: 2419.5896\n",
      "Reducing exploration for all agents to 0.7777\n",
      "\n",
      "Episode 75: Starting computation.\n",
      "Random Seed Set to 175\n",
      "Episode 75: Finished running.\n",
      "Agent 0, Average Reward: -1267.57\n",
      "1/1 - 0s - loss: 2724.9807\n",
      "1/1 - 0s - loss: 1854.3844\n",
      "1/1 - 0s - loss: 1871.0040\n",
      "1/1 - 0s - loss: 2272.1653\n",
      "1/1 - 0s - loss: 2506.9580\n",
      "1/1 - 0s - loss: 2344.8945\n",
      "1/1 - 0s - loss: 2177.0781\n",
      "1/1 - 0s - loss: 3685.2236\n",
      "1/1 - 0s - loss: 3999.5359\n",
      "1/1 - 0s - loss: 2500.6995\n",
      "Reducing exploration for all agents to 0.7747\n",
      "\n",
      "Episode 76: Starting computation.\n",
      "Random Seed Set to 176\n",
      "Episode 76: Finished running.\n",
      "Agent 0, Average Reward: -1265.31\n",
      "1/1 - 0s - loss: 1307.0562\n",
      "1/1 - 0s - loss: 2033.0299\n",
      "1/1 - 0s - loss: 1530.1322\n",
      "1/1 - 0s - loss: 1981.7555\n",
      "1/1 - 0s - loss: 2016.7321\n",
      "1/1 - 0s - loss: 2589.6011\n",
      "1/1 - 0s - loss: 1845.5251\n",
      "1/1 - 0s - loss: 2366.5645\n",
      "1/1 - 0s - loss: 2453.8928\n",
      "1/1 - 0s - loss: 1956.0809\n",
      "Reducing exploration for all agents to 0.7717\n",
      "\n",
      "Episode 77: Starting computation.\n",
      "Random Seed Set to 177\n",
      "Episode 77: Finished running.\n",
      "Agent 0, Average Reward: -1284.53\n",
      "1/1 - 0s - loss: 2126.5740\n",
      "1/1 - 0s - loss: 2291.9749\n",
      "1/1 - 0s - loss: 1704.5521\n",
      "1/1 - 0s - loss: 1807.2815\n",
      "1/1 - 0s - loss: 2262.9268\n",
      "1/1 - 0s - loss: 1970.8876\n",
      "1/1 - 0s - loss: 3116.5010\n",
      "1/1 - 0s - loss: 1966.6486\n",
      "1/1 - 0s - loss: 2557.0137\n",
      "1/1 - 0s - loss: 1953.4796\n",
      "Reducing exploration for all agents to 0.7687\n",
      "\n",
      "Episode 78: Starting computation.\n",
      "Random Seed Set to 178\n",
      "Episode 78: Finished running.\n",
      "Agent 0, Average Reward: -1338.15\n",
      "1/1 - 0s - loss: 2355.0706\n",
      "1/1 - 0s - loss: 2310.8171\n",
      "1/1 - 0s - loss: 3247.3252\n",
      "1/1 - 0s - loss: 1898.8258\n",
      "1/1 - 0s - loss: 1865.3497\n",
      "1/1 - 0s - loss: 1466.5502\n",
      "1/1 - 0s - loss: 1549.2589\n",
      "1/1 - 0s - loss: 1928.2365\n",
      "1/1 - 0s - loss: 1436.3702\n",
      "1/1 - 0s - loss: 2259.6689\n",
      "Reducing exploration for all agents to 0.7656\n",
      "\n",
      "Episode 79: Starting computation.\n",
      "Random Seed Set to 179\n",
      "Episode 79: Finished running.\n",
      "Agent 0, Average Reward: -1113.66\n",
      "1/1 - 0s - loss: 2232.5544\n",
      "1/1 - 0s - loss: 2533.5569\n",
      "1/1 - 0s - loss: 2149.6582\n",
      "1/1 - 0s - loss: 2333.0940\n",
      "1/1 - 0s - loss: 2066.2959\n",
      "1/1 - 0s - loss: 2352.7671\n",
      "1/1 - 0s - loss: 2173.5044\n",
      "1/1 - 0s - loss: 1946.2892\n",
      "1/1 - 0s - loss: 1746.1715\n",
      "1/1 - 0s - loss: 1791.5454\n",
      "Reducing exploration for all agents to 0.7626\n",
      "\n",
      "Episode 80: Starting computation.\n",
      "Random Seed Set to 180\n",
      "Episode 80: Finished running.\n",
      "Agent 0, Average Reward: -1449.53\n",
      "1/1 - 0s - loss: 2332.2791\n",
      "1/1 - 0s - loss: 3467.7153\n",
      "1/1 - 0s - loss: 2387.3765\n",
      "1/1 - 0s - loss: 1992.2557\n",
      "1/1 - 0s - loss: 1957.5677\n",
      "1/1 - 0s - loss: 3532.9060\n",
      "1/1 - 0s - loss: 3013.8406\n",
      "1/1 - 0s - loss: 2121.6282\n",
      "1/1 - 0s - loss: 1852.3495\n",
      "1/1 - 0s - loss: 2740.0623\n",
      "Weights succesfully copied to Target model for Agent 0.\n",
      "Saving architecture, weights and optimizer state for agent-0\n",
      "Dumping agent-0 memory into pickle file\n",
      "Dumping Training Results into pickle file.\n",
      "Dumping Loss Results into pickle file.\n",
      "Reducing exploration for all agents to 0.7596\n",
      "\n",
      "Episode 81: Starting computation.\n",
      "Random Seed Set to 181\n",
      "Episode 81: Finished running.\n",
      "Agent 0, Average Reward: -1419.62\n",
      "1/1 - 0s - loss: 108002.1016\n",
      "1/1 - 0s - loss: 43034.8125\n",
      "1/1 - 0s - loss: 3313.0381\n",
      "1/1 - 0s - loss: 46790.4844\n",
      "1/1 - 0s - loss: 83311.2578\n",
      "1/1 - 0s - loss: 41036.7070\n",
      "1/1 - 0s - loss: 5231.5269\n",
      "1/1 - 0s - loss: 24580.5098\n",
      "1/1 - 0s - loss: 55404.5859\n",
      "1/1 - 0s - loss: 48621.8633\n",
      "Reducing exploration for all agents to 0.7566\n",
      "\n",
      "Episode 82: Starting computation.\n",
      "Random Seed Set to 182\n",
      "Episode 82: Finished running.\n",
      "Agent 0, Average Reward: -1244.26\n",
      "1/1 - 0s - loss: 18795.4902\n",
      "1/1 - 0s - loss: 3884.2935\n",
      "1/1 - 0s - loss: 20498.8398\n",
      "1/1 - 0s - loss: 35024.5586\n",
      "1/1 - 0s - loss: 19464.1758\n",
      "1/1 - 0s - loss: 4391.1294\n",
      "1/1 - 0s - loss: 8628.6982\n",
      "1/1 - 0s - loss: 17091.1816\n",
      "1/1 - 0s - loss: 21801.0137\n",
      "1/1 - 0s - loss: 21308.7773\n",
      "Reducing exploration for all agents to 0.7536\n",
      "\n",
      "Episode 83: Starting computation.\n",
      "Random Seed Set to 183\n",
      "Episode 83: Finished running.\n",
      "Agent 0, Average Reward: -1051.43\n",
      "1/1 - 0s - loss: 6076.8818\n",
      "1/1 - 0s - loss: 5655.9727\n",
      "1/1 - 0s - loss: 20548.6582\n",
      "1/1 - 0s - loss: 26314.8711\n",
      "1/1 - 0s - loss: 11777.1445\n",
      "1/1 - 0s - loss: 3025.3228\n",
      "1/1 - 0s - loss: 6092.5122\n",
      "1/1 - 0s - loss: 14529.2773\n",
      "1/1 - 0s - loss: 17602.5508\n",
      "1/1 - 0s - loss: 7528.9575\n",
      "Reducing exploration for all agents to 0.7506\n",
      "\n",
      "Episode 84: Starting computation.\n",
      "Random Seed Set to 184\n",
      "Episode 84: Finished running.\n",
      "Agent 0, Average Reward: -1201.55\n",
      "1/1 - 0s - loss: 5146.7695\n",
      "1/1 - 0s - loss: 4127.6514\n",
      "1/1 - 0s - loss: 7286.5898\n",
      "1/1 - 0s - loss: 9508.3320\n",
      "1/1 - 0s - loss: 5751.4326\n",
      "1/1 - 0s - loss: 4369.3687\n",
      "1/1 - 0s - loss: 4052.6602\n",
      "1/1 - 0s - loss: 5824.9922\n",
      "1/1 - 0s - loss: 6318.0103\n",
      "1/1 - 0s - loss: 4393.0474\n",
      "Reducing exploration for all agents to 0.7476\n",
      "\n",
      "Episode 85: Starting computation.\n",
      "Random Seed Set to 185\n",
      "Episode 85: Finished running.\n",
      "Agent 0, Average Reward: -1126.7\n",
      "1/1 - 0s - loss: 3818.6956\n",
      "1/1 - 0s - loss: 2958.9216\n",
      "1/1 - 0s - loss: 3468.9304\n",
      "1/1 - 0s - loss: 4872.2168\n",
      "1/1 - 0s - loss: 5125.2178\n",
      "1/1 - 0s - loss: 2878.3381\n",
      "1/1 - 0s - loss: 2319.5837\n",
      "1/1 - 0s - loss: 3534.8284\n",
      "1/1 - 0s - loss: 3881.6968\n",
      "1/1 - 0s - loss: 2906.4932\n",
      "Reducing exploration for all agents to 0.7446\n",
      "\n",
      "Episode 86: Starting computation.\n",
      "Random Seed Set to 186\n",
      "Episode 86: Finished running.\n",
      "Agent 0, Average Reward: -1488.4\n",
      "1/1 - 0s - loss: 3821.1577\n",
      "1/1 - 0s - loss: 2395.8821\n",
      "1/1 - 0s - loss: 3475.5723\n",
      "1/1 - 0s - loss: 4342.6528\n",
      "1/1 - 0s - loss: 3314.9573\n",
      "1/1 - 0s - loss: 3830.1562\n",
      "1/1 - 0s - loss: 2529.6675\n",
      "1/1 - 0s - loss: 3037.4211\n",
      "1/1 - 0s - loss: 3797.3098\n",
      "1/1 - 0s - loss: 4010.9197\n",
      "Reducing exploration for all agents to 0.7416\n",
      "\n",
      "Episode 87: Starting computation.\n",
      "Random Seed Set to 187\n",
      "Episode 87: Finished running.\n",
      "Agent 0, Average Reward: -1264.73\n",
      "1/1 - 0s - loss: 4944.0835\n",
      "1/1 - 0s - loss: 2859.5967\n",
      "1/1 - 0s - loss: 3497.9307\n",
      "1/1 - 0s - loss: 4243.4253\n",
      "1/1 - 0s - loss: 2485.2080\n",
      "1/1 - 0s - loss: 3692.9893\n",
      "1/1 - 0s - loss: 2942.8889\n",
      "1/1 - 0s - loss: 3445.3413\n",
      "1/1 - 0s - loss: 3334.7935\n",
      "1/1 - 0s - loss: 3384.2939\n",
      "Reducing exploration for all agents to 0.7386\n",
      "\n",
      "Episode 88: Starting computation.\n",
      "Random Seed Set to 188\n",
      "Episode 88: Finished running.\n",
      "Agent 0, Average Reward: -1372.41\n",
      "1/1 - 0s - loss: 2965.2947\n",
      "1/1 - 0s - loss: 2760.3567\n",
      "1/1 - 0s - loss: 3249.7458\n",
      "1/1 - 0s - loss: 3001.7300\n",
      "1/1 - 0s - loss: 3698.8552\n",
      "1/1 - 0s - loss: 2644.5459\n",
      "1/1 - 0s - loss: 4665.7505\n",
      "1/1 - 0s - loss: 2523.1289\n",
      "1/1 - 0s - loss: 3686.3452\n",
      "1/1 - 0s - loss: 5260.7930\n",
      "Reducing exploration for all agents to 0.7356\n",
      "\n",
      "Episode 89: Starting computation.\n",
      "Random Seed Set to 189\n",
      "Episode 89: Finished running.\n",
      "Agent 0, Average Reward: -1409.25\n",
      "1/1 - 0s - loss: 2976.6631\n",
      "1/1 - 0s - loss: 2813.4441\n",
      "1/1 - 0s - loss: 2422.0342\n",
      "1/1 - 0s - loss: 2406.1396\n",
      "1/1 - 0s - loss: 3493.7231\n",
      "1/1 - 0s - loss: 3188.4207\n",
      "1/1 - 0s - loss: 2569.0454\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 - 0s - loss: 3870.4016\n",
      "1/1 - 0s - loss: 2851.0520\n",
      "1/1 - 0s - loss: 4182.0688\n",
      "Reducing exploration for all agents to 0.7326\n",
      "\n",
      "Episode 90: Starting computation.\n",
      "Random Seed Set to 190\n",
      "Episode 90: Finished running.\n",
      "Agent 0, Average Reward: -1374.36\n",
      "1/1 - 0s - loss: 2304.7471\n",
      "1/1 - 0s - loss: 4291.3965\n",
      "1/1 - 0s - loss: 1913.0181\n",
      "1/1 - 0s - loss: 2694.1841\n",
      "1/1 - 0s - loss: 3825.2878\n",
      "1/1 - 0s - loss: 2426.3987\n",
      "1/1 - 0s - loss: 2278.5911\n",
      "1/1 - 0s - loss: 2064.3728\n",
      "1/1 - 0s - loss: 2613.5874\n",
      "1/1 - 0s - loss: 2273.7261\n",
      "Reducing exploration for all agents to 0.7296\n",
      "\n",
      "Episode 91: Starting computation.\n",
      "Random Seed Set to 191\n",
      "Episode 91: Finished running.\n",
      "Agent 0, Average Reward: -1156.34\n",
      "1/1 - 0s - loss: 2698.5586\n",
      "1/1 - 0s - loss: 2710.7063\n",
      "1/1 - 0s - loss: 2295.2615\n",
      "1/1 - 0s - loss: 2348.6096\n",
      "1/1 - 0s - loss: 2308.1130\n",
      "1/1 - 0s - loss: 2832.1321\n",
      "1/1 - 0s - loss: 2937.2654\n",
      "1/1 - 0s - loss: 2403.2307\n",
      "1/1 - 0s - loss: 2511.8660\n",
      "1/1 - 0s - loss: 2599.5183\n",
      "Reducing exploration for all agents to 0.7266\n",
      "\n",
      "Episode 92: Starting computation.\n",
      "Random Seed Set to 192\n",
      "Episode 92: Finished running.\n",
      "Agent 0, Average Reward: -1473.8\n",
      "1/1 - 0s - loss: 2067.8181\n",
      "1/1 - 0s - loss: 3230.8228\n",
      "1/1 - 0s - loss: 2842.8384\n",
      "1/1 - 0s - loss: 3208.3213\n",
      "1/1 - 0s - loss: 2807.8760\n",
      "1/1 - 0s - loss: 2353.4695\n",
      "1/1 - 0s - loss: 3244.3657\n",
      "1/1 - 0s - loss: 2476.3704\n",
      "1/1 - 0s - loss: 2013.1888\n",
      "1/1 - 0s - loss: 2741.3328\n",
      "Reducing exploration for all agents to 0.7236\n",
      "\n",
      "Episode 93: Starting computation.\n",
      "Random Seed Set to 193\n",
      "Episode 93: Finished running.\n",
      "Agent 0, Average Reward: -1456.55\n",
      "1/1 - 0s - loss: 3103.8711\n",
      "1/1 - 0s - loss: 4285.9248\n",
      "1/1 - 0s - loss: 2282.5645\n",
      "1/1 - 0s - loss: 2124.2017\n",
      "1/1 - 0s - loss: 2506.7864\n",
      "1/1 - 0s - loss: 2177.5667\n",
      "1/1 - 0s - loss: 2171.1929\n",
      "1/1 - 0s - loss: 2443.4182\n",
      "1/1 - 0s - loss: 2941.9004\n",
      "1/1 - 0s - loss: 2148.3823\n",
      "Reducing exploration for all agents to 0.7206\n",
      "\n",
      "Episode 94: Starting computation.\n",
      "Random Seed Set to 194\n",
      "Episode 94: Finished running.\n",
      "Agent 0, Average Reward: -1456.16\n",
      "1/1 - 0s - loss: 2672.3960\n",
      "1/1 - 0s - loss: 2722.3350\n",
      "1/1 - 0s - loss: 1815.1664\n",
      "1/1 - 0s - loss: 2450.3611\n",
      "1/1 - 0s - loss: 2659.6548\n",
      "1/1 - 0s - loss: 2975.2070\n",
      "1/1 - 0s - loss: 3599.9451\n",
      "1/1 - 0s - loss: 3183.4041\n",
      "1/1 - 0s - loss: 2580.1541\n",
      "1/1 - 0s - loss: 2348.5496\n",
      "Reducing exploration for all agents to 0.7176\n",
      "\n",
      "Episode 95: Starting computation.\n",
      "Random Seed Set to 195\n",
      "Episode 95: Finished running.\n",
      "Agent 0, Average Reward: -1588.57\n",
      "1/1 - 0s - loss: 2200.7739\n",
      "1/1 - 0s - loss: 3002.9871\n",
      "1/1 - 0s - loss: 2623.4492\n",
      "1/1 - 0s - loss: 2414.6885\n",
      "1/1 - 0s - loss: 4212.5391\n",
      "1/1 - 0s - loss: 3779.3574\n",
      "1/1 - 0s - loss: 2229.3499\n",
      "1/1 - 0s - loss: 2714.8574\n",
      "1/1 - 0s - loss: 3907.0823\n",
      "1/1 - 0s - loss: 2716.8655\n",
      "Reducing exploration for all agents to 0.7146\n",
      "\n",
      "Episode 96: Starting computation.\n",
      "Random Seed Set to 196\n",
      "Episode 96: Finished running.\n",
      "Agent 0, Average Reward: -1183.75\n",
      "1/1 - 0s - loss: 2710.0808\n",
      "1/1 - 0s - loss: 3620.9028\n",
      "1/1 - 0s - loss: 2331.9585\n",
      "1/1 - 0s - loss: 2516.4678\n",
      "1/1 - 0s - loss: 3083.3730\n",
      "1/1 - 0s - loss: 2276.3232\n",
      "1/1 - 0s - loss: 1754.4990\n",
      "1/1 - 0s - loss: 3529.1646\n",
      "1/1 - 0s - loss: 3146.2048\n",
      "1/1 - 0s - loss: 2529.4529\n",
      "Reducing exploration for all agents to 0.7116\n",
      "\n",
      "Episode 97: Starting computation.\n",
      "Random Seed Set to 197\n",
      "Episode 97: Finished running.\n",
      "Agent 0, Average Reward: -1435.78\n",
      "1/1 - 0s - loss: 2499.2490\n",
      "1/1 - 0s - loss: 2912.4133\n",
      "1/1 - 0s - loss: 3188.7568\n",
      "1/1 - 0s - loss: 2859.4053\n",
      "1/1 - 0s - loss: 2969.1472\n",
      "1/1 - 0s - loss: 2763.0098\n",
      "1/1 - 0s - loss: 2732.6147\n",
      "1/1 - 0s - loss: 2674.9595\n",
      "1/1 - 0s - loss: 2092.8584\n",
      "1/1 - 0s - loss: 2199.7920\n",
      "Reducing exploration for all agents to 0.7086\n",
      "\n",
      "Episode 98: Starting computation.\n",
      "Random Seed Set to 198\n",
      "Episode 98: Finished running.\n",
      "Agent 0, Average Reward: -1281.45\n",
      "1/1 - 0s - loss: 2717.7539\n",
      "1/1 - 0s - loss: 3287.8535\n",
      "1/1 - 0s - loss: 2406.6108\n",
      "1/1 - 0s - loss: 4078.9153\n",
      "1/1 - 0s - loss: 3236.1401\n",
      "1/1 - 0s - loss: 2758.8540\n",
      "1/1 - 0s - loss: 2701.1685\n",
      "1/1 - 0s - loss: 2762.2854\n",
      "1/1 - 0s - loss: 2915.8062\n",
      "1/1 - 0s - loss: 2557.6826\n",
      "Reducing exploration for all agents to 0.7056\n",
      "\n",
      "Episode 99: Starting computation.\n",
      "Random Seed Set to 199\n",
      "Episode 99: Finished running.\n",
      "Agent 0, Average Reward: -1107.14\n",
      "1/1 - 0s - loss: 2753.0933\n",
      "1/1 - 0s - loss: 2572.6875\n",
      "1/1 - 0s - loss: 2150.8699\n",
      "1/1 - 0s - loss: 2109.2583\n",
      "1/1 - 0s - loss: 2443.7798\n",
      "1/1 - 0s - loss: 2348.4812\n",
      "1/1 - 0s - loss: 2403.9253\n",
      "1/1 - 0s - loss: 3910.3992\n",
      "1/1 - 0s - loss: 2493.7004\n",
      "1/1 - 0s - loss: 1558.9757\n",
      "Reducing exploration for all agents to 0.7026\n",
      "\n",
      "Episode 100: Starting computation.\n",
      "Random Seed Set to 200\n",
      "Episode 100: Finished running.\n",
      "Agent 0, Average Reward: -1290.88\n",
      "1/1 - 0s - loss: 3513.1218\n",
      "1/1 - 0s - loss: 3263.1567\n",
      "1/1 - 0s - loss: 2540.1316\n",
      "1/1 - 0s - loss: 3468.0374\n",
      "1/1 - 0s - loss: 1723.9912\n",
      "1/1 - 0s - loss: 1905.8115\n",
      "1/1 - 0s - loss: 2700.4097\n",
      "1/1 - 0s - loss: 1993.3209\n",
      "1/1 - 0s - loss: 2628.8086\n",
      "1/1 - 0s - loss: 2658.4128\n",
      "Weights succesfully copied to Target model for Agent 0.\n",
      "Saving architecture, weights and optimizer state for agent-0\n",
      "Dumping agent-0 memory into pickle file\n",
      "Dumping Training Results into pickle file.\n",
      "Dumping Loss Results into pickle file.\n",
      "Reducing exploration for all agents to 0.6995\n",
      "\n",
      "Episode 101: Starting computation.\n",
      "Random Seed Set to 201\n",
      "Episode 101: Finished running.\n",
      "Agent 0, Average Reward: -912.52\n",
      "1/1 - 0s - loss: 89816.8594\n",
      "1/1 - 0s - loss: 29580.3066\n",
      "1/1 - 0s - loss: 4339.7847\n",
      "1/1 - 0s - loss: 50136.4023\n",
      "1/1 - 0s - loss: 60385.6602\n",
      "1/1 - 0s - loss: 18883.1055\n",
      "1/1 - 0s - loss: 3016.6792\n",
      "1/1 - 0s - loss: 23797.2363\n",
      "1/1 - 0s - loss: 40676.9961\n",
      "1/1 - 0s - loss: 25256.8242\n",
      "Reducing exploration for all agents to 0.6965\n",
      "\n",
      "Episode 102: Starting computation.\n",
      "Random Seed Set to 202\n",
      "Episode 102: Finished running.\n",
      "Agent 0, Average Reward: -1375.8\n",
      "1/1 - 0s - loss: 4941.7656\n",
      "1/1 - 0s - loss: 7579.5259\n",
      "1/1 - 0s - loss: 23167.5977\n",
      "1/1 - 0s - loss: 20541.8398\n",
      "1/1 - 0s - loss: 7076.5254\n",
      "1/1 - 0s - loss: 3602.4412\n",
      "1/1 - 0s - loss: 9728.4355\n",
      "1/1 - 0s - loss: 15785.0430\n",
      "1/1 - 0s - loss: 8291.1904\n",
      "1/1 - 0s - loss: 4403.4326\n",
      "Reducing exploration for all agents to 0.6935\n",
      "\n",
      "Episode 103: Starting computation.\n",
      "Random Seed Set to 203\n",
      "Episode 103: Finished running.\n",
      "Agent 0, Average Reward: -1830.89\n",
      "1/1 - 0s - loss: 4883.2051\n",
      "1/1 - 0s - loss: 9956.6367\n",
      "1/1 - 0s - loss: 11825.3906\n",
      "1/1 - 0s - loss: 3502.1531\n",
      "1/1 - 0s - loss: 4369.9146\n",
      "1/1 - 0s - loss: 7687.8159\n",
      "1/1 - 0s - loss: 9112.5000\n",
      "1/1 - 0s - loss: 5123.0767\n",
      "1/1 - 0s - loss: 2676.2068\n",
      "1/1 - 0s - loss: 4621.7188\n",
      "Reducing exploration for all agents to 0.6905\n",
      "\n",
      "Episode 104: Starting computation.\n",
      "Random Seed Set to 204\n",
      "Episode 104: Finished running.\n",
      "Agent 0, Average Reward: -1661.51\n",
      "1/1 - 0s - loss: 7702.9951\n",
      "1/1 - 0s - loss: 4119.6831\n",
      "1/1 - 0s - loss: 3522.8074\n",
      "1/1 - 0s - loss: 3671.4856\n",
      "1/1 - 0s - loss: 6078.0552\n",
      "1/1 - 0s - loss: 3745.1731\n",
      "1/1 - 0s - loss: 8166.8911\n",
      "1/1 - 0s - loss: 3601.7976\n",
      "1/1 - 0s - loss: 4431.4194\n",
      "1/1 - 0s - loss: 4176.4126\n",
      "Reducing exploration for all agents to 0.6875\n",
      "\n",
      "Episode 105: Starting computation.\n",
      "Random Seed Set to 205\n",
      "Episode 105: Finished running.\n",
      "Agent 0, Average Reward: -1792.82\n",
      "1/1 - 0s - loss: 3099.2292\n",
      "1/1 - 0s - loss: 3209.2043\n",
      "1/1 - 0s - loss: 3223.4839\n",
      "1/1 - 0s - loss: 3217.0208\n",
      "1/1 - 0s - loss: 3726.2175\n",
      "1/1 - 0s - loss: 3471.6123\n",
      "1/1 - 0s - loss: 4572.0938\n",
      "1/1 - 0s - loss: 3045.1621\n",
      "1/1 - 0s - loss: 4337.8677\n",
      "1/1 - 0s - loss: 3063.8770\n",
      "Reducing exploration for all agents to 0.6845\n",
      "\n",
      "Episode 106: Starting computation.\n",
      "Random Seed Set to 206\n",
      "Episode 106: Finished running.\n",
      "Agent 0, Average Reward: -1351.73\n",
      "1/1 - 0s - loss: 3895.3845\n",
      "1/1 - 0s - loss: 3325.8357\n",
      "1/1 - 0s - loss: 2878.8481\n",
      "1/1 - 0s - loss: 3099.8657\n",
      "1/1 - 0s - loss: 3377.0674\n",
      "1/1 - 0s - loss: 3296.4031\n",
      "1/1 - 0s - loss: 3736.8262\n",
      "1/1 - 0s - loss: 3443.7896\n",
      "1/1 - 0s - loss: 2922.7524\n",
      "1/1 - 0s - loss: 3337.4941\n",
      "Reducing exploration for all agents to 0.6815\n",
      "\n",
      "Episode 107: Starting computation.\n",
      "Random Seed Set to 207\n",
      "Episode 107: Finished running.\n",
      "Agent 0, Average Reward: -822.31\n",
      "1/1 - 0s - loss: 4990.3638\n",
      "1/1 - 0s - loss: 3249.3967\n",
      "1/1 - 0s - loss: 3829.3218\n",
      "1/1 - 0s - loss: 3962.2983\n",
      "1/1 - 0s - loss: 4036.1536\n",
      "1/1 - 0s - loss: 3935.7473\n",
      "1/1 - 0s - loss: 13640.7256\n",
      "1/1 - 0s - loss: 4675.8213\n",
      "1/1 - 0s - loss: 4609.8574\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 - 0s - loss: 3918.7864\n",
      "Reducing exploration for all agents to 0.6785\n",
      "\n",
      "Episode 108: Starting computation.\n",
      "Random Seed Set to 208\n",
      "Episode 108: Finished running.\n",
      "Agent 0, Average Reward: -1462.22\n",
      "1/1 - 0s - loss: 4804.9536\n",
      "1/1 - 0s - loss: 5255.2944\n",
      "1/1 - 0s - loss: 6230.2686\n",
      "1/1 - 0s - loss: 4501.5688\n",
      "1/1 - 0s - loss: 3187.3970\n",
      "1/1 - 0s - loss: 5347.9976\n",
      "1/1 - 0s - loss: 3468.2288\n",
      "1/1 - 0s - loss: 3902.9409\n",
      "1/1 - 0s - loss: 4215.7749\n",
      "1/1 - 0s - loss: 4022.8413\n",
      "Reducing exploration for all agents to 0.6755\n",
      "\n",
      "Episode 109: Starting computation.\n",
      "Random Seed Set to 209\n",
      "Episode 109: Finished running.\n",
      "Agent 0, Average Reward: -1324.88\n",
      "1/1 - 0s - loss: 4659.3970\n",
      "1/1 - 0s - loss: 6415.6816\n",
      "1/1 - 0s - loss: 3172.8394\n",
      "1/1 - 0s - loss: 3915.4871\n",
      "1/1 - 0s - loss: 5851.0938\n",
      "1/1 - 0s - loss: 3616.2581\n",
      "1/1 - 0s - loss: 3352.1670\n",
      "1/1 - 0s - loss: 3077.2083\n",
      "1/1 - 0s - loss: 4470.2300\n",
      "1/1 - 0s - loss: 3550.4260\n",
      "Reducing exploration for all agents to 0.6725\n",
      "\n",
      "Episode 110: Starting computation.\n",
      "Random Seed Set to 210\n",
      "Episode 110: Finished running.\n",
      "Agent 0, Average Reward: -1450.52\n",
      "1/1 - 0s - loss: 3394.6338\n",
      "1/1 - 0s - loss: 4314.8008\n",
      "1/1 - 0s - loss: 3786.4458\n",
      "1/1 - 0s - loss: 3931.0789\n",
      "1/1 - 0s - loss: 3288.9888\n",
      "1/1 - 0s - loss: 4122.1782\n",
      "1/1 - 0s - loss: 14519.4404\n",
      "1/1 - 0s - loss: 3228.4211\n",
      "1/1 - 0s - loss: 3355.8467\n",
      "1/1 - 0s - loss: 4665.2612\n",
      "Reducing exploration for all agents to 0.6695\n",
      "\n",
      "Episode 111: Starting computation.\n",
      "Random Seed Set to 211\n",
      "Episode 111: Finished running.\n",
      "Agent 0, Average Reward: -1262.77\n",
      "1/1 - 0s - loss: 2817.2561\n",
      "1/1 - 0s - loss: 2937.2354\n",
      "1/1 - 0s - loss: 2017.5964\n",
      "1/1 - 0s - loss: 3009.9646\n",
      "1/1 - 0s - loss: 4044.2698\n",
      "1/1 - 0s - loss: 2876.6863\n",
      "1/1 - 0s - loss: 3473.0156\n",
      "1/1 - 0s - loss: 4140.9800\n",
      "1/1 - 0s - loss: 3757.6294\n",
      "1/1 - 0s - loss: 2850.0723\n",
      "Reducing exploration for all agents to 0.6665\n",
      "\n",
      "Episode 112: Starting computation.\n",
      "Random Seed Set to 212\n",
      "Episode 112: Finished running.\n",
      "Agent 0, Average Reward: -1289.72\n",
      "1/1 - 0s - loss: 3293.3994\n",
      "1/1 - 0s - loss: 2534.1274\n",
      "1/1 - 0s - loss: 14426.8584\n",
      "1/1 - 0s - loss: 3359.8562\n",
      "1/1 - 0s - loss: 4127.1211\n",
      "1/1 - 0s - loss: 3372.1023\n",
      "1/1 - 0s - loss: 3949.7354\n",
      "1/1 - 0s - loss: 3822.3623\n",
      "1/1 - 0s - loss: 5322.5581\n",
      "1/1 - 0s - loss: 3662.1396\n",
      "Reducing exploration for all agents to 0.6635\n",
      "\n",
      "Episode 113: Starting computation.\n",
      "Random Seed Set to 213\n",
      "Episode 113: Finished running.\n",
      "Agent 0, Average Reward: -1316.29\n",
      "1/1 - 0s - loss: 3557.7510\n",
      "1/1 - 0s - loss: 4526.5811\n",
      "1/1 - 0s - loss: 5193.6509\n",
      "1/1 - 0s - loss: 3293.4639\n",
      "1/1 - 0s - loss: 4086.3838\n",
      "1/1 - 0s - loss: 2314.8708\n",
      "1/1 - 0s - loss: 3974.4780\n",
      "1/1 - 0s - loss: 4320.7251\n",
      "1/1 - 0s - loss: 3879.6904\n",
      "1/1 - 0s - loss: 2863.7671\n",
      "Reducing exploration for all agents to 0.6605\n",
      "\n",
      "Episode 114: Starting computation.\n",
      "Random Seed Set to 214\n",
      "Episode 114: Finished running.\n",
      "Agent 0, Average Reward: -1465.29\n",
      "1/1 - 0s - loss: 3282.6404\n",
      "1/1 - 0s - loss: 4034.7195\n",
      "1/1 - 0s - loss: 3681.7737\n",
      "1/1 - 0s - loss: 3395.5339\n",
      "1/1 - 0s - loss: 4375.2598\n",
      "1/1 - 0s - loss: 2344.4109\n",
      "1/1 - 0s - loss: 3714.9980\n",
      "1/1 - 0s - loss: 5704.8726\n",
      "1/1 - 0s - loss: 3427.9617\n",
      "1/1 - 0s - loss: 5184.7417\n",
      "Reducing exploration for all agents to 0.6575\n",
      "\n",
      "Episode 115: Starting computation.\n",
      "Random Seed Set to 215\n",
      "Episode 115: Finished running.\n",
      "Agent 0, Average Reward: -1437.94\n",
      "1/1 - 0s - loss: 3579.2444\n",
      "1/1 - 0s - loss: 3251.7168\n",
      "1/1 - 0s - loss: 4507.5752\n",
      "1/1 - 0s - loss: 3604.0471\n",
      "1/1 - 0s - loss: 3294.5161\n",
      "1/1 - 0s - loss: 3705.0168\n",
      "1/1 - 0s - loss: 4712.0459\n",
      "1/1 - 0s - loss: 2887.4846\n",
      "1/1 - 0s - loss: 2918.7871\n",
      "1/1 - 0s - loss: 4184.5488\n",
      "Reducing exploration for all agents to 0.6545\n",
      "\n",
      "Episode 116: Starting computation.\n",
      "Random Seed Set to 216\n",
      "Episode 116: Finished running.\n",
      "Agent 0, Average Reward: -1471.74\n",
      "1/1 - 0s - loss: 2929.8801\n",
      "1/1 - 0s - loss: 3901.9070\n",
      "1/1 - 0s - loss: 3946.6604\n",
      "1/1 - 0s - loss: 3383.8989\n",
      "1/1 - 0s - loss: 3432.1438\n",
      "1/1 - 0s - loss: 2810.7625\n",
      "1/1 - 0s - loss: 3516.8621\n",
      "1/1 - 0s - loss: 3995.9836\n",
      "1/1 - 0s - loss: 3024.8152\n",
      "1/1 - 0s - loss: 3825.3870\n",
      "Reducing exploration for all agents to 0.6515\n",
      "\n",
      "Episode 117: Starting computation.\n",
      "Random Seed Set to 217\n",
      "Episode 117: Finished running.\n",
      "Agent 0, Average Reward: -1269.14\n",
      "1/1 - 0s - loss: 2591.2334\n",
      "1/1 - 0s - loss: 4082.6897\n",
      "1/1 - 0s - loss: 3384.4861\n",
      "1/1 - 0s - loss: 2773.5020\n",
      "1/1 - 0s - loss: 2502.0464\n",
      "1/1 - 0s - loss: 4113.4224\n",
      "1/1 - 0s - loss: 15716.9590\n",
      "1/1 - 0s - loss: 2873.6477\n",
      "1/1 - 0s - loss: 3341.3086\n",
      "1/1 - 0s - loss: 4967.9731\n",
      "Reducing exploration for all agents to 0.6485\n",
      "\n",
      "Episode 118: Starting computation.\n",
      "Random Seed Set to 218\n",
      "Episode 118: Finished running.\n",
      "Agent 0, Average Reward: -1727.32\n",
      "1/1 - 0s - loss: 3224.1421\n",
      "1/1 - 0s - loss: 3055.4524\n",
      "1/1 - 0s - loss: 3791.9739\n",
      "1/1 - 0s - loss: 3184.6704\n",
      "1/1 - 0s - loss: 4264.1450\n",
      "1/1 - 0s - loss: 2890.8718\n",
      "1/1 - 0s - loss: 2952.6431\n",
      "1/1 - 0s - loss: 3998.3027\n",
      "1/1 - 0s - loss: 2736.7715\n",
      "1/1 - 0s - loss: 3562.2837\n",
      "Reducing exploration for all agents to 0.6455\n",
      "\n",
      "Episode 119: Starting computation.\n",
      "Random Seed Set to 219\n",
      "Episode 119: Finished running.\n",
      "Agent 0, Average Reward: -1323.83\n",
      "1/1 - 0s - loss: 3317.7988\n",
      "1/1 - 0s - loss: 2645.0430\n",
      "1/1 - 0s - loss: 2319.6130\n",
      "1/1 - 0s - loss: 3176.3621\n",
      "1/1 - 0s - loss: 2948.9297\n",
      "1/1 - 0s - loss: 5139.6494\n",
      "1/1 - 0s - loss: 3013.3889\n",
      "1/1 - 0s - loss: 3932.5002\n",
      "1/1 - 0s - loss: 3198.7788\n",
      "1/1 - 0s - loss: 3462.7966\n",
      "Reducing exploration for all agents to 0.6425\n",
      "\n",
      "Episode 120: Starting computation.\n",
      "Random Seed Set to 220\n",
      "Episode 120: Finished running.\n",
      "Agent 0, Average Reward: -1535.59\n",
      "1/1 - 0s - loss: 4294.9448\n",
      "1/1 - 0s - loss: 2933.8796\n",
      "1/1 - 0s - loss: 2744.8188\n",
      "1/1 - 0s - loss: 3467.4675\n",
      "1/1 - 0s - loss: 2928.0994\n",
      "1/1 - 0s - loss: 3269.1848\n",
      "1/1 - 0s - loss: 3038.9688\n",
      "1/1 - 0s - loss: 2791.2568\n",
      "1/1 - 0s - loss: 4722.9746\n",
      "1/1 - 0s - loss: 2194.7712\n",
      "Weights succesfully copied to Target model for Agent 0.\n",
      "Saving architecture, weights and optimizer state for agent-0\n",
      "Dumping agent-0 memory into pickle file\n",
      "Dumping Training Results into pickle file.\n",
      "Dumping Loss Results into pickle file.\n",
      "Reducing exploration for all agents to 0.6395\n",
      "\n",
      "Episode 121: Starting computation.\n",
      "Random Seed Set to 221\n",
      "Episode 121: Finished running.\n",
      "Agent 0, Average Reward: -1484.34\n",
      "1/1 - 0s - loss: 88307.9922\n",
      "1/1 - 0s - loss: 23893.3887\n",
      "1/1 - 0s - loss: 7281.3584\n",
      "1/1 - 0s - loss: 55563.1133\n",
      "1/1 - 0s - loss: 55033.1250\n",
      "1/1 - 0s - loss: 9809.9990\n",
      "1/1 - 0s - loss: 12618.2324\n",
      "1/1 - 0s - loss: 42150.0117\n",
      "1/1 - 0s - loss: 42877.3281\n",
      "1/1 - 0s - loss: 9164.4824\n",
      "Reducing exploration for all agents to 0.6365\n",
      "\n",
      "Episode 122: Starting computation.\n",
      "Random Seed Set to 222\n",
      "Episode 122: Finished running.\n",
      "Agent 0, Average Reward: -1506.81\n",
      "1/1 - 0s - loss: 9060.6484\n",
      "1/1 - 0s - loss: 28903.1035\n",
      "1/1 - 0s - loss: 32425.4395\n",
      "1/1 - 0s - loss: 6681.0649\n",
      "1/1 - 0s - loss: 9537.8955\n",
      "1/1 - 0s - loss: 25498.4336\n",
      "1/1 - 0s - loss: 18037.3398\n",
      "1/1 - 0s - loss: 5961.7383\n",
      "1/1 - 0s - loss: 8857.8213\n",
      "1/1 - 0s - loss: 17036.0605\n",
      "Reducing exploration for all agents to 0.6334\n",
      "\n",
      "Episode 123: Starting computation.\n",
      "Random Seed Set to 223\n",
      "Episode 123: Finished running.\n",
      "Agent 0, Average Reward: -1887.62\n",
      "1/1 - 0s - loss: 11667.0654\n",
      "1/1 - 0s - loss: 5711.8628\n",
      "1/1 - 0s - loss: 6863.9136\n",
      "1/1 - 0s - loss: 11213.6650\n",
      "1/1 - 0s - loss: 9071.8203\n",
      "1/1 - 0s - loss: 4676.2520\n",
      "1/1 - 0s - loss: 8192.6611\n",
      "1/1 - 0s - loss: 7569.8530\n",
      "1/1 - 0s - loss: 6672.2329\n",
      "1/1 - 0s - loss: 3490.1387\n",
      "Reducing exploration for all agents to 0.6304\n",
      "\n",
      "Episode 124: Starting computation.\n",
      "Random Seed Set to 224\n",
      "Episode 124: Finished running.\n",
      "Agent 0, Average Reward: -1435.21\n",
      "1/1 - 0s - loss: 3678.9041\n",
      "1/1 - 0s - loss: 7104.0146\n",
      "1/1 - 0s - loss: 4974.5005\n",
      "1/1 - 0s - loss: 5009.6968\n",
      "1/1 - 0s - loss: 4133.9722\n",
      "1/1 - 0s - loss: 4424.9014\n",
      "1/1 - 0s - loss: 3182.5056\n",
      "1/1 - 0s - loss: 2995.5388\n",
      "1/1 - 0s - loss: 3577.8589\n",
      "1/1 - 0s - loss: 5959.3232\n",
      "Reducing exploration for all agents to 0.6274\n",
      "\n",
      "Episode 125: Starting computation.\n",
      "Random Seed Set to 225\n",
      "Episode 125: Finished running.\n",
      "Agent 0, Average Reward: -1354.54\n",
      "1/1 - 0s - loss: 5339.5742\n",
      "1/1 - 0s - loss: 2810.1655\n",
      "1/1 - 0s - loss: 3162.2312\n",
      "1/1 - 0s - loss: 5619.9287\n",
      "1/1 - 0s - loss: 3888.0076\n",
      "1/1 - 0s - loss: 3092.0754\n",
      "1/1 - 0s - loss: 4111.3491\n",
      "1/1 - 0s - loss: 4053.2737\n",
      "1/1 - 0s - loss: 4330.2891\n",
      "1/1 - 0s - loss: 3413.5933\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reducing exploration for all agents to 0.6244\n",
      "\n",
      "Episode 126: Starting computation.\n",
      "Random Seed Set to 226\n",
      "Episode 126: Finished running.\n",
      "Agent 0, Average Reward: -1386.25\n",
      "1/1 - 0s - loss: 3098.7454\n",
      "1/1 - 0s - loss: 3072.1746\n",
      "1/1 - 0s - loss: 3476.1868\n",
      "1/1 - 0s - loss: 5569.7847\n",
      "1/1 - 0s - loss: 4049.9756\n",
      "1/1 - 0s - loss: 4071.7937\n",
      "1/1 - 0s - loss: 3633.1990\n",
      "1/1 - 0s - loss: 2520.3267\n",
      "1/1 - 0s - loss: 6190.8101\n",
      "1/1 - 0s - loss: 2307.9016\n",
      "Reducing exploration for all agents to 0.6214\n",
      "\n",
      "Episode 127: Starting computation.\n",
      "Random Seed Set to 227\n",
      "Episode 127: Finished running.\n",
      "Agent 0, Average Reward: -1497.47\n",
      "1/1 - 0s - loss: 3470.2930\n",
      "1/1 - 0s - loss: 3636.2512\n",
      "1/1 - 0s - loss: 3611.8967\n",
      "1/1 - 0s - loss: 2958.6965\n",
      "1/1 - 0s - loss: 3654.0127\n",
      "1/1 - 0s - loss: 3522.4973\n",
      "1/1 - 0s - loss: 3186.5479\n",
      "1/1 - 0s - loss: 2866.7422\n",
      "1/1 - 0s - loss: 2924.8496\n",
      "1/1 - 0s - loss: 2716.3367\n",
      "Reducing exploration for all agents to 0.6184\n",
      "\n",
      "Episode 128: Starting computation.\n",
      "Random Seed Set to 228\n",
      "Episode 128: Finished running.\n",
      "Agent 0, Average Reward: -1354.17\n",
      "1/1 - 0s - loss: 4249.8833\n",
      "1/1 - 0s - loss: 4160.1797\n",
      "1/1 - 0s - loss: 2554.9226\n",
      "1/1 - 0s - loss: 3166.8845\n",
      "1/1 - 0s - loss: 3610.9753\n",
      "1/1 - 0s - loss: 2880.9773\n",
      "1/1 - 0s - loss: 3195.0139\n",
      "1/1 - 0s - loss: 3514.9771\n",
      "1/1 - 0s - loss: 4133.5098\n",
      "1/1 - 0s - loss: 3148.3743\n",
      "Reducing exploration for all agents to 0.6154\n",
      "\n",
      "Episode 129: Starting computation.\n",
      "Random Seed Set to 229\n",
      "Episode 129: Finished running.\n",
      "Agent 0, Average Reward: -1596.37\n",
      "1/1 - 0s - loss: 3537.3528\n",
      "1/1 - 0s - loss: 2967.5039\n",
      "1/1 - 0s - loss: 3995.3806\n",
      "1/1 - 0s - loss: 4026.4192\n",
      "1/1 - 0s - loss: 4044.2273\n",
      "1/1 - 0s - loss: 2547.2004\n",
      "1/1 - 0s - loss: 4936.2026\n",
      "1/1 - 0s - loss: 4864.3374\n",
      "1/1 - 0s - loss: 4295.8662\n",
      "1/1 - 0s - loss: 3226.4131\n",
      "Reducing exploration for all agents to 0.6124\n",
      "\n",
      "Episode 130: Starting computation.\n",
      "Random Seed Set to 230\n",
      "Episode 130: Finished running.\n",
      "Agent 0, Average Reward: -1315.46\n",
      "1/1 - 0s - loss: 2836.7808\n",
      "1/1 - 0s - loss: 3883.5916\n",
      "1/1 - 0s - loss: 4540.7559\n",
      "1/1 - 0s - loss: 4453.2065\n",
      "1/1 - 0s - loss: 2631.0266\n",
      "1/1 - 0s - loss: 3198.8081\n",
      "1/1 - 0s - loss: 4508.6675\n",
      "1/1 - 0s - loss: 3957.7432\n",
      "1/1 - 0s - loss: 3563.3740\n",
      "1/1 - 0s - loss: 3133.3682\n",
      "Reducing exploration for all agents to 0.6094\n",
      "\n",
      "Episode 131: Starting computation.\n",
      "Random Seed Set to 231\n",
      "Episode 131: Finished running.\n",
      "Agent 0, Average Reward: -1461.18\n",
      "1/1 - 0s - loss: 3511.8286\n",
      "1/1 - 0s - loss: 2337.7046\n",
      "1/1 - 0s - loss: 2670.4028\n",
      "1/1 - 0s - loss: 2102.0352\n",
      "1/1 - 0s - loss: 3989.0112\n",
      "1/1 - 0s - loss: 3628.7214\n",
      "1/1 - 0s - loss: 3479.3589\n",
      "1/1 - 0s - loss: 3374.4062\n",
      "1/1 - 0s - loss: 2836.7183\n",
      "1/1 - 0s - loss: 3815.5845\n",
      "Reducing exploration for all agents to 0.6064\n",
      "\n",
      "Episode 132: Starting computation.\n",
      "Random Seed Set to 232\n",
      "Episode 132: Finished running.\n",
      "Agent 0, Average Reward: -1079.48\n",
      "1/1 - 0s - loss: 5024.8062\n",
      "1/1 - 0s - loss: 3629.1611\n",
      "1/1 - 0s - loss: 2580.2839\n",
      "1/1 - 0s - loss: 3127.8049\n",
      "1/1 - 0s - loss: 4979.8301\n",
      "1/1 - 0s - loss: 3293.8003\n",
      "1/1 - 0s - loss: 3134.2390\n",
      "1/1 - 0s - loss: 2762.0798\n",
      "1/1 - 0s - loss: 4312.2905\n",
      "1/1 - 0s - loss: 2809.0022\n",
      "Reducing exploration for all agents to 0.6034\n",
      "\n",
      "Episode 133: Starting computation.\n",
      "Random Seed Set to 233\n",
      "Episode 133: Finished running.\n",
      "Agent 0, Average Reward: -1230.38\n",
      "1/1 - 0s - loss: 2559.8591\n",
      "1/1 - 0s - loss: 2881.1687\n",
      "1/1 - 0s - loss: 5319.9805\n",
      "1/1 - 0s - loss: 3170.6404\n",
      "1/1 - 0s - loss: 3058.8870\n",
      "1/1 - 0s - loss: 3471.9939\n",
      "1/1 - 0s - loss: 2685.3059\n",
      "1/1 - 0s - loss: 3582.7671\n",
      "1/1 - 0s - loss: 3570.5620\n",
      "1/1 - 0s - loss: 2655.8850\n",
      "Reducing exploration for all agents to 0.6004\n",
      "\n",
      "Episode 134: Starting computation.\n",
      "Random Seed Set to 234\n",
      "Episode 134: Finished running.\n",
      "Agent 0, Average Reward: -1331.99\n",
      "1/1 - 0s - loss: 3376.4038\n",
      "1/1 - 0s - loss: 2826.3650\n",
      "1/1 - 0s - loss: 2789.6194\n",
      "1/1 - 0s - loss: 3395.1672\n",
      "1/1 - 0s - loss: 2580.8630\n",
      "1/1 - 0s - loss: 3800.9358\n",
      "1/1 - 0s - loss: 3852.3848\n",
      "1/1 - 0s - loss: 4454.3018\n",
      "1/1 - 0s - loss: 3107.7703\n",
      "1/1 - 0s - loss: 2631.5164\n",
      "Reducing exploration for all agents to 0.5974\n",
      "\n",
      "Episode 135: Starting computation.\n",
      "Random Seed Set to 235\n",
      "Episode 135: Finished running.\n",
      "Agent 0, Average Reward: -1206.88\n",
      "1/1 - 0s - loss: 3212.6370\n",
      "1/1 - 0s - loss: 3597.9451\n",
      "1/1 - 0s - loss: 3751.7546\n",
      "1/1 - 0s - loss: 3241.3030\n",
      "1/1 - 0s - loss: 3735.2190\n",
      "1/1 - 0s - loss: 5681.2788\n",
      "1/1 - 0s - loss: 5701.3579\n",
      "1/1 - 0s - loss: 3415.8735\n",
      "1/1 - 0s - loss: 2628.7434\n",
      "1/1 - 0s - loss: 3519.7517\n",
      "Reducing exploration for all agents to 0.5944\n",
      "\n",
      "Episode 136: Starting computation.\n",
      "Random Seed Set to 236\n",
      "Episode 136: Finished running.\n",
      "Agent 0, Average Reward: -1362.36\n",
      "1/1 - 0s - loss: 3129.3130\n",
      "1/1 - 0s - loss: 5449.0366\n",
      "1/1 - 0s - loss: 3431.5698\n",
      "1/1 - 0s - loss: 2849.6487\n",
      "1/1 - 0s - loss: 3020.5322\n",
      "1/1 - 0s - loss: 2603.3831\n",
      "1/1 - 0s - loss: 2077.0129\n",
      "1/1 - 0s - loss: 3182.5193\n",
      "1/1 - 0s - loss: 2380.4485\n",
      "1/1 - 0s - loss: 2480.9592\n",
      "Reducing exploration for all agents to 0.5914\n",
      "\n",
      "Episode 137: Starting computation.\n",
      "Random Seed Set to 237\n",
      "Episode 137: Finished running.\n",
      "Agent 0, Average Reward: -1369.69\n",
      "1/1 - 0s - loss: 2012.2944\n",
      "1/1 - 0s - loss: 2590.1277\n",
      "1/1 - 0s - loss: 3175.8118\n",
      "1/1 - 0s - loss: 4026.1602\n",
      "1/1 - 0s - loss: 3607.0781\n",
      "1/1 - 0s - loss: 2841.3118\n",
      "1/1 - 0s - loss: 2407.0498\n",
      "1/1 - 0s - loss: 5009.1211\n",
      "1/1 - 0s - loss: 2705.9028\n",
      "1/1 - 0s - loss: 2729.3535\n",
      "Reducing exploration for all agents to 0.5884\n",
      "\n",
      "Episode 138: Starting computation.\n",
      "Random Seed Set to 238\n",
      "Episode 138: Finished running.\n",
      "Agent 0, Average Reward: -1498.26\n",
      "1/1 - 0s - loss: 3394.6819\n",
      "1/1 - 0s - loss: 3979.0771\n",
      "1/1 - 0s - loss: 4456.8423\n",
      "1/1 - 0s - loss: 3967.7056\n",
      "1/1 - 0s - loss: 2597.5276\n",
      "1/1 - 0s - loss: 2800.2676\n",
      "1/1 - 0s - loss: 2800.0874\n",
      "1/1 - 0s - loss: 2829.5037\n",
      "1/1 - 0s - loss: 2937.4500\n",
      "1/1 - 0s - loss: 2845.7751\n",
      "Reducing exploration for all agents to 0.5854\n",
      "\n",
      "Episode 139: Starting computation.\n",
      "Random Seed Set to 239\n",
      "Episode 139: Finished running.\n",
      "Agent 0, Average Reward: -1356.02\n",
      "1/1 - 0s - loss: 2800.6594\n",
      "1/1 - 0s - loss: 2505.9045\n",
      "1/1 - 0s - loss: 2614.1572\n",
      "1/1 - 0s - loss: 2870.7266\n",
      "1/1 - 0s - loss: 2902.8455\n",
      "1/1 - 0s - loss: 2699.4392\n",
      "1/1 - 0s - loss: 2678.5972\n",
      "1/1 - 0s - loss: 3494.2249\n",
      "1/1 - 0s - loss: 2652.9458\n",
      "1/1 - 0s - loss: 2384.2476\n",
      "Reducing exploration for all agents to 0.5824\n",
      "\n",
      "Episode 140: Starting computation.\n",
      "Random Seed Set to 240\n",
      "Episode 140: Finished running.\n",
      "Agent 0, Average Reward: -1399.35\n",
      "1/1 - 0s - loss: 2814.4314\n",
      "1/1 - 0s - loss: 2521.9062\n",
      "1/1 - 0s - loss: 3143.0879\n",
      "1/1 - 0s - loss: 3227.7043\n",
      "1/1 - 0s - loss: 3520.2334\n",
      "1/1 - 0s - loss: 2449.3086\n",
      "1/1 - 0s - loss: 2857.9275\n",
      "1/1 - 0s - loss: 2729.0684\n",
      "1/1 - 0s - loss: 3388.6833\n",
      "1/1 - 0s - loss: 2962.4082\n",
      "Weights succesfully copied to Target model for Agent 0.\n",
      "Saving architecture, weights and optimizer state for agent-0\n",
      "Dumping agent-0 memory into pickle file\n",
      "Dumping Training Results into pickle file.\n",
      "Dumping Loss Results into pickle file.\n",
      "Reducing exploration for all agents to 0.5794\n",
      "\n",
      "Episode 141: Starting computation.\n",
      "Random Seed Set to 241\n",
      "Episode 141: Finished running.\n",
      "Agent 0, Average Reward: -1178.67\n",
      "1/1 - 0s - loss: 62984.3203\n",
      "1/1 - 0s - loss: 15399.5479\n",
      "1/1 - 0s - loss: 9224.3672\n",
      "1/1 - 0s - loss: 46109.2031\n",
      "1/1 - 0s - loss: 32875.8828\n",
      "1/1 - 0s - loss: 7228.9468\n",
      "1/1 - 0s - loss: 13729.5117\n",
      "1/1 - 0s - loss: 38179.4531\n",
      "1/1 - 0s - loss: 22496.8750\n",
      "1/1 - 0s - loss: 4092.6946\n",
      "Reducing exploration for all agents to 0.5764\n",
      "\n",
      "Episode 142: Starting computation.\n",
      "Random Seed Set to 242\n",
      "Episode 142: Finished running.\n",
      "Agent 0, Average Reward: -915.65\n",
      "1/1 - 0s - loss: 10629.2988\n",
      "1/1 - 0s - loss: 23365.8789\n",
      "1/1 - 0s - loss: 15916.8184\n",
      "1/1 - 0s - loss: 5267.8276\n",
      "1/1 - 0s - loss: 7042.1895\n",
      "1/1 - 0s - loss: 12272.4043\n",
      "1/1 - 0s - loss: 13233.3965\n",
      "1/1 - 0s - loss: 3732.7495\n",
      "1/1 - 0s - loss: 3622.7207\n",
      "1/1 - 0s - loss: 7781.9053\n",
      "Reducing exploration for all agents to 0.5734\n",
      "\n",
      "Episode 143: Starting computation.\n",
      "Random Seed Set to 243\n",
      "Episode 143: Finished running.\n",
      "Agent 0, Average Reward: -1629.93\n",
      "1/1 - 0s - loss: 9777.4990\n",
      "1/1 - 0s - loss: 5949.1079\n",
      "1/1 - 0s - loss: 4829.0347\n",
      "1/1 - 0s - loss: 7641.4136\n",
      "1/1 - 0s - loss: 6821.7319\n",
      "1/1 - 0s - loss: 6221.3252\n",
      "1/1 - 0s - loss: 3735.8428\n",
      "1/1 - 0s - loss: 4378.9966\n",
      "1/1 - 0s - loss: 4810.1021\n",
      "1/1 - 0s - loss: 4388.8530\n",
      "Reducing exploration for all agents to 0.5704\n",
      "\n",
      "Episode 144: Starting computation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Seed Set to 244\n",
      "Episode 144: Finished running.\n",
      "Agent 0, Average Reward: -1414.38\n",
      "1/1 - 0s - loss: 4219.0234\n",
      "1/1 - 0s - loss: 5295.8955\n",
      "1/1 - 0s - loss: 5636.5244\n",
      "1/1 - 0s - loss: 4377.4854\n",
      "1/1 - 0s - loss: 2952.3752\n",
      "1/1 - 0s - loss: 5286.1450\n",
      "1/1 - 0s - loss: 4868.3457\n",
      "1/1 - 0s - loss: 3469.7292\n",
      "1/1 - 0s - loss: 5839.6646\n",
      "1/1 - 0s - loss: 3547.7793\n",
      "Reducing exploration for all agents to 0.5674\n",
      "\n",
      "Episode 145: Starting computation.\n",
      "Random Seed Set to 245\n",
      "Episode 145: Finished running.\n",
      "Agent 0, Average Reward: -1586.76\n",
      "1/1 - 0s - loss: 4172.0161\n",
      "1/1 - 0s - loss: 3807.2898\n",
      "1/1 - 0s - loss: 3055.4587\n",
      "1/1 - 0s - loss: 5091.0605\n",
      "1/1 - 0s - loss: 3804.4451\n",
      "1/1 - 0s - loss: 3334.4150\n",
      "1/1 - 0s - loss: 4314.1924\n",
      "1/1 - 0s - loss: 3875.7649\n",
      "1/1 - 0s - loss: 3064.5688\n",
      "1/1 - 0s - loss: 3810.8044\n",
      "Reducing exploration for all agents to 0.5643\n",
      "\n",
      "Episode 146: Starting computation.\n",
      "Random Seed Set to 246\n",
      "Episode 146: Finished running.\n",
      "Agent 0, Average Reward: -1365.31\n",
      "1/1 - 0s - loss: 5659.1611\n",
      "1/1 - 0s - loss: 4275.7515\n",
      "1/1 - 0s - loss: 3260.0891\n",
      "1/1 - 0s - loss: 3906.7729\n",
      "1/1 - 0s - loss: 3378.3860\n",
      "1/1 - 0s - loss: 3945.0076\n",
      "1/1 - 0s - loss: 3563.4062\n",
      "1/1 - 0s - loss: 4585.6558\n",
      "1/1 - 0s - loss: 3211.6646\n",
      "1/1 - 0s - loss: 6098.6128\n",
      "Reducing exploration for all agents to 0.5613\n",
      "\n",
      "Episode 147: Starting computation.\n",
      "Random Seed Set to 247\n",
      "Episode 147: Finished running.\n",
      "Agent 0, Average Reward: -1487.69\n",
      "1/1 - 0s - loss: 3107.8491\n",
      "1/1 - 0s - loss: 5554.2852\n",
      "1/1 - 0s - loss: 3700.6873\n",
      "1/1 - 0s - loss: 4007.5449\n",
      "1/1 - 0s - loss: 6124.3989\n",
      "1/1 - 0s - loss: 3531.1492\n",
      "1/1 - 0s - loss: 7241.6240\n",
      "1/1 - 0s - loss: 4608.0029\n",
      "1/1 - 0s - loss: 3176.0610\n",
      "1/1 - 0s - loss: 4108.1206\n",
      "Reducing exploration for all agents to 0.5583\n",
      "\n",
      "Episode 148: Starting computation.\n",
      "Random Seed Set to 248\n",
      "Episode 148: Finished running.\n",
      "Agent 0, Average Reward: -1462.97\n",
      "1/1 - 0s - loss: 2164.3950\n",
      "1/1 - 0s - loss: 3362.7737\n",
      "1/1 - 0s - loss: 5698.5459\n",
      "1/1 - 0s - loss: 3429.6787\n",
      "1/1 - 0s - loss: 3203.8208\n",
      "1/1 - 0s - loss: 3106.1438\n",
      "1/1 - 0s - loss: 3540.6794\n",
      "1/1 - 0s - loss: 2901.3770\n",
      "1/1 - 0s - loss: 3763.8159\n",
      "1/1 - 0s - loss: 4533.2388\n",
      "Reducing exploration for all agents to 0.5553\n",
      "\n",
      "Episode 149: Starting computation.\n",
      "Random Seed Set to 249\n",
      "Episode 149: Finished running.\n",
      "Agent 0, Average Reward: -1459.3\n",
      "1/1 - 0s - loss: 3064.2261\n",
      "1/1 - 0s - loss: 3933.8877\n",
      "1/1 - 0s - loss: 4065.7131\n",
      "1/1 - 0s - loss: 2627.4153\n",
      "1/1 - 0s - loss: 5460.5664\n",
      "1/1 - 0s - loss: 4435.0361\n",
      "1/1 - 0s - loss: 2830.6531\n",
      "1/1 - 0s - loss: 3216.4741\n",
      "1/1 - 0s - loss: 3534.8618\n",
      "1/1 - 0s - loss: 3239.6611\n",
      "Reducing exploration for all agents to 0.5523\n",
      "\n",
      "Episode 150: Starting computation.\n",
      "Random Seed Set to 250\n",
      "Episode 150: Finished running.\n",
      "Agent 0, Average Reward: -1614.78\n",
      "1/1 - 0s - loss: 3487.1997\n",
      "1/1 - 0s - loss: 2939.0596\n",
      "1/1 - 0s - loss: 3586.6895\n",
      "1/1 - 0s - loss: 3152.0503\n",
      "1/1 - 0s - loss: 3069.9590\n",
      "1/1 - 0s - loss: 3045.0723\n",
      "1/1 - 0s - loss: 4058.7939\n",
      "1/1 - 0s - loss: 3368.4480\n",
      "1/1 - 0s - loss: 3571.2368\n",
      "1/1 - 0s - loss: 4862.4590\n",
      "Reducing exploration for all agents to 0.5493\n",
      "\n",
      "Episode 151: Starting computation.\n",
      "Random Seed Set to 251\n",
      "Episode 151: Finished running.\n",
      "Agent 0, Average Reward: -1311.37\n",
      "1/1 - 0s - loss: 3975.8818\n",
      "1/1 - 0s - loss: 3658.4814\n",
      "1/1 - 0s - loss: 4222.8608\n",
      "1/1 - 0s - loss: 4779.8574\n",
      "1/1 - 0s - loss: 4876.6641\n",
      "1/1 - 0s - loss: 3548.9121\n",
      "1/1 - 0s - loss: 4341.0576\n",
      "1/1 - 0s - loss: 5436.8359\n",
      "1/1 - 0s - loss: 3747.2324\n",
      "1/1 - 0s - loss: 3445.0710\n",
      "Reducing exploration for all agents to 0.5463\n",
      "\n",
      "Episode 152: Starting computation.\n",
      "Random Seed Set to 252\n",
      "Episode 152: Finished running.\n",
      "Agent 0, Average Reward: -1248.6\n",
      "1/1 - 0s - loss: 4345.6543\n",
      "1/1 - 0s - loss: 3908.0889\n",
      "1/1 - 0s - loss: 3218.5554\n",
      "1/1 - 0s - loss: 3051.3862\n",
      "1/1 - 0s - loss: 3930.6108\n",
      "1/1 - 0s - loss: 5840.0776\n",
      "1/1 - 0s - loss: 2459.1660\n",
      "1/1 - 0s - loss: 2823.5405\n",
      "1/1 - 0s - loss: 4325.9150\n",
      "1/1 - 0s - loss: 3869.2253\n",
      "Reducing exploration for all agents to 0.5433\n",
      "\n",
      "Episode 153: Starting computation.\n",
      "Random Seed Set to 253\n",
      "Episode 153: Finished running.\n",
      "Agent 0, Average Reward: -1085.66\n",
      "1/1 - 0s - loss: 3652.7183\n",
      "1/1 - 0s - loss: 2925.8816\n",
      "1/1 - 0s - loss: 3784.6306\n",
      "1/1 - 0s - loss: 2997.0215\n",
      "1/1 - 0s - loss: 3793.7178\n",
      "1/1 - 0s - loss: 3959.3811\n",
      "1/1 - 0s - loss: 3547.5386\n",
      "1/1 - 0s - loss: 4395.3516\n",
      "1/1 - 0s - loss: 4215.3389\n",
      "1/1 - 0s - loss: 3299.9058\n",
      "Reducing exploration for all agents to 0.5403\n",
      "\n",
      "Episode 154: Starting computation.\n",
      "Random Seed Set to 254\n",
      "Episode 154: Finished running.\n",
      "Agent 0, Average Reward: -1438.26\n",
      "1/1 - 0s - loss: 3006.6616\n",
      "1/1 - 0s - loss: 3620.2380\n",
      "1/1 - 0s - loss: 4114.8584\n",
      "1/1 - 0s - loss: 3479.6968\n",
      "1/1 - 0s - loss: 2875.3320\n",
      "1/1 - 0s - loss: 4158.9585\n",
      "1/1 - 0s - loss: 2798.8542\n",
      "1/1 - 0s - loss: 6126.6489\n",
      "1/1 - 0s - loss: 4287.9648\n",
      "1/1 - 0s - loss: 4457.3457\n",
      "Reducing exploration for all agents to 0.5373\n",
      "\n",
      "Episode 155: Starting computation.\n",
      "Random Seed Set to 255\n",
      "Episode 155: Finished running.\n",
      "Agent 0, Average Reward: -1672.74\n",
      "1/1 - 0s - loss: 2779.2849\n",
      "1/1 - 0s - loss: 3559.9844\n",
      "1/1 - 0s - loss: 3437.0823\n",
      "1/1 - 0s - loss: 3100.4858\n",
      "1/1 - 0s - loss: 2150.0574\n",
      "1/1 - 0s - loss: 3335.7842\n",
      "1/1 - 0s - loss: 2943.4910\n",
      "1/1 - 0s - loss: 5098.0659\n",
      "1/1 - 0s - loss: 2622.6492\n",
      "1/1 - 0s - loss: 4552.5806\n",
      "Reducing exploration for all agents to 0.5343\n",
      "\n",
      "Episode 156: Starting computation.\n",
      "Random Seed Set to 256\n",
      "Episode 156: Finished running.\n",
      "Agent 0, Average Reward: -1268.19\n",
      "1/1 - 0s - loss: 4444.6890\n",
      "1/1 - 0s - loss: 3127.3813\n",
      "1/1 - 0s - loss: 3775.4312\n",
      "1/1 - 0s - loss: 3773.4548\n",
      "1/1 - 0s - loss: 3813.5752\n",
      "1/1 - 0s - loss: 2598.3879\n",
      "1/1 - 0s - loss: 2702.5129\n",
      "1/1 - 0s - loss: 4529.7563\n",
      "1/1 - 0s - loss: 3857.0801\n",
      "1/1 - 0s - loss: 3652.2839\n",
      "Reducing exploration for all agents to 0.5313\n",
      "\n",
      "Episode 157: Starting computation.\n",
      "Random Seed Set to 257\n",
      "Episode 157: Finished running.\n",
      "Agent 0, Average Reward: -1411.64\n",
      "1/1 - 0s - loss: 5599.6753\n",
      "1/1 - 0s - loss: 4166.7993\n",
      "1/1 - 0s - loss: 3601.2520\n",
      "1/1 - 0s - loss: 3549.9221\n",
      "1/1 - 0s - loss: 3785.4512\n",
      "1/1 - 0s - loss: 3139.0188\n",
      "1/1 - 0s - loss: 4730.7686\n",
      "1/1 - 0s - loss: 4966.4434\n",
      "1/1 - 0s - loss: 2676.2881\n",
      "1/1 - 0s - loss: 3781.4048\n",
      "Reducing exploration for all agents to 0.5283\n",
      "\n",
      "Episode 158: Starting computation.\n",
      "Random Seed Set to 258\n",
      "Episode 158: Finished running.\n",
      "Agent 0, Average Reward: -1526.92\n",
      "1/1 - 0s - loss: 3792.7224\n",
      "1/1 - 0s - loss: 3273.5054\n",
      "1/1 - 0s - loss: 4447.4365\n",
      "1/1 - 0s - loss: 3066.4255\n",
      "1/1 - 0s - loss: 3241.0210\n",
      "1/1 - 0s - loss: 3650.4185\n",
      "1/1 - 0s - loss: 2494.8145\n",
      "1/1 - 0s - loss: 2629.5957\n",
      "1/1 - 0s - loss: 2793.4924\n",
      "1/1 - 0s - loss: 3608.3455\n",
      "Reducing exploration for all agents to 0.5253\n",
      "\n",
      "Episode 159: Starting computation.\n",
      "Random Seed Set to 259\n",
      "Episode 159: Finished running.\n",
      "Agent 0, Average Reward: -1422.85\n",
      "1/1 - 0s - loss: 2719.3533\n",
      "1/1 - 0s - loss: 2953.6455\n",
      "1/1 - 0s - loss: 2854.6382\n",
      "1/1 - 0s - loss: 4336.6455\n",
      "1/1 - 0s - loss: 3590.0833\n",
      "1/1 - 0s - loss: 3003.0063\n",
      "1/1 - 0s - loss: 3725.4280\n",
      "1/1 - 0s - loss: 2793.1038\n",
      "1/1 - 0s - loss: 3986.7190\n",
      "1/1 - 0s - loss: 3190.2798\n",
      "Reducing exploration for all agents to 0.5223\n",
      "\n",
      "Episode 160: Starting computation.\n",
      "Random Seed Set to 260\n",
      "Episode 160: Finished running.\n",
      "Agent 0, Average Reward: -1507.47\n",
      "1/1 - 0s - loss: 3268.1870\n",
      "1/1 - 0s - loss: 4954.1611\n",
      "1/1 - 0s - loss: 1931.4849\n",
      "1/1 - 0s - loss: 2848.8569\n",
      "1/1 - 0s - loss: 2639.8323\n",
      "1/1 - 0s - loss: 3525.7952\n",
      "1/1 - 0s - loss: 2554.8301\n",
      "1/1 - 0s - loss: 2224.6003\n",
      "1/1 - 0s - loss: 3685.7920\n",
      "1/1 - 0s - loss: 3448.5342\n",
      "Weights succesfully copied to Target model for Agent 0.\n",
      "Saving architecture, weights and optimizer state for agent-0\n",
      "Dumping agent-0 memory into pickle file\n",
      "Dumping Training Results into pickle file.\n",
      "Dumping Loss Results into pickle file.\n",
      "Reducing exploration for all agents to 0.5193\n",
      "\n",
      "Episode 161: Starting computation.\n",
      "Random Seed Set to 261\n",
      "Episode 161: Finished running.\n",
      "Agent 0, Average Reward: -1389.38\n",
      "1/1 - 0s - loss: 60473.5000\n",
      "1/1 - 0s - loss: 7342.5269\n",
      "1/1 - 0s - loss: 31276.1504\n",
      "1/1 - 0s - loss: 48641.5391\n",
      "1/1 - 0s - loss: 9811.8652\n",
      "1/1 - 0s - loss: 12945.4629\n",
      "1/1 - 0s - loss: 35643.4766\n",
      "1/1 - 0s - loss: 22224.7012\n",
      "1/1 - 0s - loss: 3772.6826\n",
      "1/1 - 0s - loss: 21706.1074\n",
      "Reducing exploration for all agents to 0.5163\n",
      "\n",
      "Episode 162: Starting computation.\n",
      "Random Seed Set to 262\n",
      "Episode 162: Finished running.\n",
      "Agent 0, Average Reward: -1260.16\n",
      "1/1 - 0s - loss: 20312.9512\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 - 0s - loss: 7328.1875\n",
      "1/1 - 0s - loss: 8403.1582\n",
      "1/1 - 0s - loss: 16137.7393\n",
      "1/1 - 0s - loss: 10415.3730\n",
      "1/1 - 0s - loss: 4967.4902\n",
      "1/1 - 0s - loss: 8408.1816\n",
      "1/1 - 0s - loss: 11955.1289\n",
      "1/1 - 0s - loss: 10121.7559\n",
      "1/1 - 0s - loss: 3268.1602\n",
      "Reducing exploration for all agents to 0.5133\n",
      "\n",
      "Episode 163: Starting computation.\n",
      "Random Seed Set to 263\n",
      "Episode 163: Finished running.\n",
      "Agent 0, Average Reward: -1242.72\n",
      "1/1 - 0s - loss: 9100.3535\n",
      "1/1 - 0s - loss: 11382.1211\n",
      "1/1 - 0s - loss: 7298.4409\n",
      "1/1 - 0s - loss: 3873.1960\n",
      "1/1 - 0s - loss: 10667.7988\n",
      "1/1 - 0s - loss: 6592.3755\n",
      "1/1 - 0s - loss: 4831.8433\n",
      "1/1 - 0s - loss: 5271.3457\n",
      "1/1 - 0s - loss: 8479.6152\n",
      "1/1 - 0s - loss: 3189.3008\n",
      "Reducing exploration for all agents to 0.5103\n",
      "\n",
      "Episode 164: Starting computation.\n",
      "Random Seed Set to 264\n",
      "Episode 164: Finished running.\n",
      "Agent 0, Average Reward: -1434.29\n",
      "1/1 - 0s - loss: 5266.3838\n",
      "1/1 - 0s - loss: 5840.6392\n",
      "1/1 - 0s - loss: 4595.7930\n",
      "1/1 - 0s - loss: 5279.6982\n",
      "1/1 - 0s - loss: 5379.2627\n",
      "1/1 - 0s - loss: 4741.8418\n",
      "1/1 - 0s - loss: 2977.6777\n",
      "1/1 - 0s - loss: 6379.1313\n",
      "1/1 - 0s - loss: 6354.1548\n",
      "1/1 - 0s - loss: 5359.5898\n",
      "Reducing exploration for all agents to 0.5073\n",
      "\n",
      "Episode 165: Starting computation.\n",
      "Random Seed Set to 265\n",
      "Episode 165: Finished running.\n",
      "Agent 0, Average Reward: -1529.04\n",
      "1/1 - 0s - loss: 3615.2620\n",
      "1/1 - 0s - loss: 4249.7588\n",
      "1/1 - 0s - loss: 6990.4292\n",
      "1/1 - 0s - loss: 4375.3931\n",
      "1/1 - 0s - loss: 7459.4829\n",
      "1/1 - 0s - loss: 4234.2778\n",
      "1/1 - 0s - loss: 4192.5020\n",
      "1/1 - 0s - loss: 3185.3401\n",
      "1/1 - 0s - loss: 4230.0508\n",
      "1/1 - 0s - loss: 5199.7017\n",
      "Reducing exploration for all agents to 0.5043\n",
      "\n",
      "Episode 166: Starting computation.\n",
      "Random Seed Set to 266\n",
      "Episode 166: Finished running.\n",
      "Agent 0, Average Reward: -1770.56\n",
      "1/1 - 0s - loss: 4892.1567\n",
      "1/1 - 0s - loss: 4093.2224\n",
      "1/1 - 0s - loss: 3911.5896\n",
      "1/1 - 0s - loss: 3657.7205\n",
      "1/1 - 0s - loss: 4104.0854\n",
      "1/1 - 0s - loss: 7136.5957\n",
      "1/1 - 0s - loss: 5110.6172\n",
      "1/1 - 0s - loss: 3974.7532\n",
      "1/1 - 0s - loss: 5380.1797\n",
      "1/1 - 0s - loss: 4124.5508\n",
      "Reducing exploration for all agents to 0.5013\n",
      "\n",
      "Episode 167: Starting computation.\n",
      "Random Seed Set to 267\n",
      "Episode 167: Finished running.\n",
      "Agent 0, Average Reward: -1333.98\n",
      "1/1 - 0s - loss: 6924.0669\n",
      "1/1 - 0s - loss: 4642.6816\n",
      "1/1 - 0s - loss: 4476.7861\n",
      "1/1 - 0s - loss: 4963.7285\n",
      "1/1 - 0s - loss: 3754.5991\n",
      "1/1 - 0s - loss: 6258.6831\n",
      "1/1 - 0s - loss: 4463.1890\n",
      "1/1 - 0s - loss: 3724.9695\n",
      "1/1 - 0s - loss: 4653.6909\n",
      "1/1 - 0s - loss: 6851.4224\n",
      "Reducing exploration for all agents to 0.4982\n",
      "\n",
      "Episode 168: Starting computation.\n",
      "Random Seed Set to 268\n",
      "Episode 168: Finished running.\n",
      "Agent 0, Average Reward: -1150.42\n",
      "1/1 - 0s - loss: 5201.2114\n",
      "1/1 - 0s - loss: 5117.6460\n",
      "1/1 - 0s - loss: 4303.9375\n",
      "1/1 - 0s - loss: 3948.8582\n",
      "1/1 - 0s - loss: 5111.8867\n",
      "1/1 - 0s - loss: 4104.7212\n",
      "1/1 - 0s - loss: 4820.4351\n",
      "1/1 - 0s - loss: 5119.4980\n",
      "1/1 - 0s - loss: 5155.1777\n",
      "1/1 - 0s - loss: 5105.7417\n",
      "Reducing exploration for all agents to 0.4952\n",
      "\n",
      "Episode 169: Starting computation.\n",
      "Random Seed Set to 269\n",
      "Episode 169: Finished running.\n",
      "Agent 0, Average Reward: -1114.07\n",
      "1/1 - 0s - loss: 6177.5737\n",
      "1/1 - 0s - loss: 5098.4863\n",
      "1/1 - 0s - loss: 4491.3462\n",
      "1/1 - 0s - loss: 3829.1746\n",
      "1/1 - 0s - loss: 5168.2007\n",
      "1/1 - 0s - loss: 5305.3931\n",
      "1/1 - 0s - loss: 4211.7075\n",
      "1/1 - 0s - loss: 5965.3823\n",
      "1/1 - 0s - loss: 3854.1934\n",
      "1/1 - 0s - loss: 4191.8008\n",
      "Reducing exploration for all agents to 0.4922\n",
      "\n",
      "Episode 170: Starting computation.\n",
      "Random Seed Set to 270\n",
      "Episode 170: Finished running.\n",
      "Agent 0, Average Reward: -1341.82\n",
      "1/1 - 0s - loss: 6276.8208\n",
      "1/1 - 0s - loss: 4335.0586\n",
      "1/1 - 0s - loss: 5478.7305\n",
      "1/1 - 0s - loss: 4618.2349\n",
      "1/1 - 0s - loss: 3866.1489\n",
      "1/1 - 0s - loss: 2748.0583\n",
      "1/1 - 0s - loss: 4705.0005\n",
      "1/1 - 0s - loss: 4024.1641\n",
      "1/1 - 0s - loss: 4530.2759\n",
      "1/1 - 0s - loss: 8383.4072\n",
      "Reducing exploration for all agents to 0.4892\n",
      "\n",
      "Episode 171: Starting computation.\n",
      "Random Seed Set to 271\n",
      "Episode 171: Finished running.\n",
      "Agent 0, Average Reward: -1249.63\n",
      "1/1 - 0s - loss: 5970.3384\n",
      "1/1 - 0s - loss: 6174.8364\n",
      "1/1 - 0s - loss: 5431.5107\n",
      "1/1 - 0s - loss: 3654.5691\n",
      "1/1 - 0s - loss: 5792.0322\n",
      "1/1 - 0s - loss: 7374.0859\n",
      "1/1 - 0s - loss: 13036.0674\n",
      "1/1 - 0s - loss: 5990.6787\n",
      "1/1 - 0s - loss: 7102.2241\n",
      "1/1 - 0s - loss: 4377.3271\n",
      "Reducing exploration for all agents to 0.4862\n",
      "\n",
      "Episode 172: Starting computation.\n",
      "Random Seed Set to 272\n",
      "Episode 172: Finished running.\n",
      "Agent 0, Average Reward: -1340.08\n",
      "1/1 - 0s - loss: 7070.9004\n",
      "1/1 - 0s - loss: 4790.2246\n",
      "1/1 - 0s - loss: 5214.2256\n",
      "1/1 - 0s - loss: 3174.5386\n",
      "1/1 - 0s - loss: 5627.6562\n",
      "1/1 - 0s - loss: 4905.6460\n",
      "1/1 - 0s - loss: 4376.0146\n",
      "1/1 - 0s - loss: 7003.9189\n",
      "1/1 - 0s - loss: 11264.5771\n",
      "1/1 - 0s - loss: 4076.0669\n",
      "Reducing exploration for all agents to 0.4832\n",
      "\n",
      "Episode 173: Starting computation.\n",
      "Random Seed Set to 273\n",
      "Episode 173: Finished running.\n",
      "Agent 0, Average Reward: -1394.72\n",
      "1/1 - 0s - loss: 3729.5654\n",
      "1/1 - 0s - loss: 6430.0156\n",
      "1/1 - 0s - loss: 5714.9990\n",
      "1/1 - 0s - loss: 6420.3267\n",
      "1/1 - 0s - loss: 5611.5938\n",
      "1/1 - 0s - loss: 5159.5034\n",
      "1/1 - 0s - loss: 5841.4731\n",
      "1/1 - 0s - loss: 4001.3301\n",
      "1/1 - 0s - loss: 4759.8794\n",
      "1/1 - 0s - loss: 13017.8877\n",
      "Reducing exploration for all agents to 0.4802\n",
      "\n",
      "Episode 174: Starting computation.\n",
      "Random Seed Set to 274\n",
      "Episode 174: Finished running.\n",
      "Agent 0, Average Reward: -978.95\n",
      "1/1 - 0s - loss: 5793.2280\n",
      "1/1 - 0s - loss: 6907.3203\n",
      "1/1 - 0s - loss: 4774.9346\n",
      "1/1 - 0s - loss: 10603.5322\n",
      "1/1 - 0s - loss: 5367.0215\n",
      "1/1 - 0s - loss: 6267.4580\n",
      "1/1 - 0s - loss: 4806.6729\n",
      "1/1 - 0s - loss: 5662.9849\n",
      "1/1 - 0s - loss: 4360.9692\n",
      "1/1 - 0s - loss: 4353.0684\n",
      "Reducing exploration for all agents to 0.4772\n",
      "\n",
      "Episode 175: Starting computation.\n",
      "Random Seed Set to 275\n",
      "Episode 175: Finished running.\n",
      "Agent 0, Average Reward: -1128.31\n",
      "1/1 - 0s - loss: 5760.7119\n",
      "1/1 - 0s - loss: 6419.7603\n",
      "1/1 - 0s - loss: 6328.2515\n",
      "1/1 - 0s - loss: 3953.7385\n",
      "1/1 - 0s - loss: 8629.0420\n",
      "1/1 - 0s - loss: 5731.8882\n",
      "1/1 - 0s - loss: 7657.5801\n",
      "1/1 - 0s - loss: 6056.3047\n",
      "1/1 - 0s - loss: 13513.8027\n",
      "1/1 - 0s - loss: 8414.1621\n",
      "Reducing exploration for all agents to 0.4742\n",
      "\n",
      "Episode 176: Starting computation.\n",
      "Random Seed Set to 276\n",
      "Episode 176: Finished running.\n",
      "Agent 0, Average Reward: -1490.19\n",
      "1/1 - 0s - loss: 3883.9253\n",
      "1/1 - 0s - loss: 6838.5918\n",
      "1/1 - 0s - loss: 4588.5474\n",
      "1/1 - 0s - loss: 3581.2583\n",
      "1/1 - 0s - loss: 4704.7998\n",
      "1/1 - 0s - loss: 3431.7290\n",
      "1/1 - 0s - loss: 3925.4316\n",
      "1/1 - 0s - loss: 4873.2124\n",
      "1/1 - 0s - loss: 4328.8125\n",
      "1/1 - 0s - loss: 4654.1826\n",
      "Reducing exploration for all agents to 0.4712\n",
      "\n",
      "Episode 177: Starting computation.\n",
      "Random Seed Set to 277\n",
      "Episode 177: Finished running.\n",
      "Agent 0, Average Reward: -1335.37\n",
      "1/1 - 0s - loss: 6873.4121\n",
      "1/1 - 0s - loss: 6508.3525\n",
      "1/1 - 0s - loss: 6647.4668\n",
      "1/1 - 0s - loss: 15215.2822\n",
      "1/1 - 0s - loss: 4669.9961\n",
      "1/1 - 0s - loss: 9382.5107\n",
      "1/1 - 0s - loss: 7399.3110\n",
      "1/1 - 0s - loss: 6843.5674\n",
      "1/1 - 0s - loss: 5736.9209\n",
      "1/1 - 0s - loss: 4523.2114\n",
      "Reducing exploration for all agents to 0.4682\n",
      "\n",
      "Episode 178: Starting computation.\n",
      "Random Seed Set to 278\n",
      "Episode 178: Finished running.\n",
      "Agent 0, Average Reward: -1409.9\n",
      "1/1 - 0s - loss: 5410.7402\n",
      "1/1 - 0s - loss: 4543.3491\n",
      "1/1 - 0s - loss: 4205.4570\n",
      "1/1 - 0s - loss: 4745.9023\n",
      "1/1 - 0s - loss: 4923.7197\n",
      "1/1 - 0s - loss: 4012.9424\n",
      "1/1 - 0s - loss: 3998.3940\n",
      "1/1 - 0s - loss: 5264.3682\n",
      "1/1 - 0s - loss: 5827.9619\n",
      "1/1 - 0s - loss: 4320.0317\n",
      "Reducing exploration for all agents to 0.4652\n",
      "\n",
      "Episode 179: Starting computation.\n",
      "Random Seed Set to 279\n",
      "Episode 179: Finished running.\n",
      "Agent 0, Average Reward: -1236.29\n",
      "1/1 - 0s - loss: 3827.8945\n",
      "1/1 - 0s - loss: 5735.8794\n",
      "1/1 - 0s - loss: 4251.3169\n",
      "1/1 - 0s - loss: 3968.9124\n",
      "1/1 - 0s - loss: 4459.6040\n",
      "1/1 - 0s - loss: 3989.4607\n",
      "1/1 - 0s - loss: 3446.8035\n",
      "1/1 - 0s - loss: 4413.9131\n",
      "1/1 - 0s - loss: 4586.1099\n",
      "1/1 - 0s - loss: 5477.2334\n",
      "Reducing exploration for all agents to 0.4622\n",
      "\n",
      "Episode 180: Starting computation.\n",
      "Random Seed Set to 280\n",
      "Episode 180: Finished running.\n",
      "Agent 0, Average Reward: -1162.53\n",
      "1/1 - 0s - loss: 7052.8418\n",
      "1/1 - 0s - loss: 7817.3701\n",
      "1/1 - 0s - loss: 3546.3235\n",
      "1/1 - 0s - loss: 4089.4355\n",
      "1/1 - 0s - loss: 3749.7317\n",
      "1/1 - 0s - loss: 3896.6208\n",
      "1/1 - 0s - loss: 3830.7598\n",
      "1/1 - 0s - loss: 4966.2852\n",
      "1/1 - 0s - loss: 6338.9658\n",
      "1/1 - 0s - loss: 4936.2871\n",
      "Weights succesfully copied to Target model for Agent 0.\n",
      "Saving architecture, weights and optimizer state for agent-0\n",
      "Dumping agent-0 memory into pickle file\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dumping Training Results into pickle file.\n",
      "Dumping Loss Results into pickle file.\n",
      "Reducing exploration for all agents to 0.4592\n",
      "\n",
      "Episode 181: Starting computation.\n",
      "Random Seed Set to 281\n",
      "Episode 181: Finished running.\n",
      "Agent 0, Average Reward: -1555.52\n",
      "1/1 - 0s - loss: 51474.7773\n",
      "1/1 - 0s - loss: 8896.0391\n",
      "1/1 - 0s - loss: 55661.6641\n",
      "1/1 - 0s - loss: 8020.8379\n",
      "1/1 - 0s - loss: 26499.2773\n",
      "1/1 - 0s - loss: 33108.8906\n",
      "1/1 - 0s - loss: 5878.8159\n",
      "1/1 - 0s - loss: 20031.7305\n",
      "1/1 - 0s - loss: 16893.4844\n",
      "1/1 - 0s - loss: 6697.6719\n",
      "Reducing exploration for all agents to 0.4562\n",
      "\n",
      "Episode 182: Starting computation.\n",
      "Random Seed Set to 282\n",
      "Episode 182: Finished running.\n",
      "Agent 0, Average Reward: -1388.23\n",
      "1/1 - 0s - loss: 16712.8770\n",
      "1/1 - 0s - loss: 12969.6133\n",
      "1/1 - 0s - loss: 4729.2480\n",
      "1/1 - 0s - loss: 10286.8623\n",
      "1/1 - 0s - loss: 12054.1895\n",
      "1/1 - 0s - loss: 4846.0503\n",
      "1/1 - 0s - loss: 10053.4414\n",
      "1/1 - 0s - loss: 8466.4404\n",
      "1/1 - 0s - loss: 4006.7612\n",
      "1/1 - 0s - loss: 7678.2163\n",
      "Reducing exploration for all agents to 0.4532\n",
      "\n",
      "Episode 183: Starting computation.\n",
      "Random Seed Set to 283\n",
      "Episode 183: Finished running.\n",
      "Agent 0, Average Reward: -1658.25\n",
      "1/1 - 0s - loss: 8059.1304\n",
      "1/1 - 0s - loss: 4878.6587\n",
      "1/1 - 0s - loss: 6173.1519\n",
      "1/1 - 0s - loss: 6780.3970\n",
      "1/1 - 0s - loss: 4857.3740\n",
      "1/1 - 0s - loss: 6631.4062\n",
      "1/1 - 0s - loss: 6153.3164\n",
      "1/1 - 0s - loss: 6379.5098\n",
      "1/1 - 0s - loss: 4276.3447\n",
      "1/1 - 0s - loss: 5605.0142\n",
      "Reducing exploration for all agents to 0.4502\n",
      "\n",
      "Episode 184: Starting computation.\n",
      "Random Seed Set to 284\n",
      "Episode 184: Finished running.\n",
      "Agent 0, Average Reward: -1011.56\n",
      "1/1 - 0s - loss: 5959.5957\n",
      "1/1 - 0s - loss: 5434.4521\n",
      "1/1 - 0s - loss: 5071.6992\n",
      "1/1 - 0s - loss: 5809.0161\n",
      "1/1 - 0s - loss: 4690.0708\n",
      "1/1 - 0s - loss: 5911.2256\n",
      "1/1 - 0s - loss: 4622.3223\n",
      "1/1 - 0s - loss: 5174.3320\n",
      "1/1 - 0s - loss: 5463.7837\n",
      "1/1 - 0s - loss: 5748.3462\n",
      "Reducing exploration for all agents to 0.4472\n",
      "\n",
      "Episode 185: Starting computation.\n",
      "Random Seed Set to 285\n",
      "Episode 185: Finished running.\n",
      "Agent 0, Average Reward: -1373.49\n",
      "1/1 - 0s - loss: 4330.4707\n",
      "1/1 - 0s - loss: 4842.3110\n",
      "1/1 - 0s - loss: 5799.7593\n",
      "1/1 - 0s - loss: 4875.1895\n",
      "1/1 - 0s - loss: 6029.2393\n",
      "1/1 - 0s - loss: 6595.7173\n",
      "1/1 - 0s - loss: 4829.1411\n",
      "1/1 - 0s - loss: 4133.5562\n",
      "1/1 - 0s - loss: 4969.5195\n",
      "1/1 - 0s - loss: 4767.5811\n",
      "Reducing exploration for all agents to 0.4442\n",
      "\n",
      "Episode 186: Starting computation.\n",
      "Random Seed Set to 286\n",
      "Episode 186: Finished running.\n",
      "Agent 0, Average Reward: -1475.14\n",
      "1/1 - 0s - loss: 4044.5020\n",
      "1/1 - 0s - loss: 3724.8611\n",
      "1/1 - 0s - loss: 5722.7788\n",
      "1/1 - 0s - loss: 2595.3184\n",
      "1/1 - 0s - loss: 3525.5283\n",
      "1/1 - 0s - loss: 5589.2500\n",
      "1/1 - 0s - loss: 4312.9492\n",
      "1/1 - 0s - loss: 3620.3567\n",
      "1/1 - 0s - loss: 3719.9961\n",
      "1/1 - 0s - loss: 3063.5396\n",
      "Reducing exploration for all agents to 0.4412\n",
      "\n",
      "Episode 187: Starting computation.\n",
      "Random Seed Set to 287\n",
      "Episode 187: Finished running.\n",
      "Agent 0, Average Reward: -1523.62\n",
      "1/1 - 0s - loss: 4559.0176\n",
      "1/1 - 0s - loss: 3962.8765\n",
      "1/1 - 0s - loss: 5496.3809\n",
      "1/1 - 0s - loss: 4313.2959\n",
      "1/1 - 0s - loss: 6941.0591\n",
      "1/1 - 0s - loss: 3051.7476\n",
      "1/1 - 0s - loss: 4918.0312\n",
      "1/1 - 0s - loss: 3874.3926\n",
      "1/1 - 0s - loss: 5305.4229\n",
      "1/1 - 0s - loss: 4112.3291\n",
      "Reducing exploration for all agents to 0.4382\n",
      "\n",
      "Episode 188: Starting computation.\n",
      "Random Seed Set to 288\n",
      "Episode 188: Finished running.\n",
      "Agent 0, Average Reward: -1443.94\n",
      "1/1 - 0s - loss: 6163.2524\n",
      "1/1 - 0s - loss: 5334.9609\n",
      "1/1 - 0s - loss: 4042.4768\n",
      "1/1 - 0s - loss: 4190.4497\n",
      "1/1 - 0s - loss: 3770.7390\n",
      "1/1 - 0s - loss: 3111.4109\n",
      "1/1 - 0s - loss: 4833.0557\n",
      "1/1 - 0s - loss: 3285.1653\n",
      "1/1 - 0s - loss: 5317.1245\n",
      "1/1 - 0s - loss: 4081.8879\n",
      "Reducing exploration for all agents to 0.4352\n",
      "\n",
      "Episode 189: Starting computation.\n",
      "Random Seed Set to 289\n",
      "Episode 189: Finished running.\n",
      "Agent 0, Average Reward: -1326.53\n",
      "1/1 - 0s - loss: 4385.0073\n",
      "1/1 - 0s - loss: 4414.6162\n",
      "1/1 - 0s - loss: 5656.2310\n",
      "1/1 - 0s - loss: 3943.6990\n",
      "1/1 - 0s - loss: 4213.1489\n",
      "1/1 - 0s - loss: 5079.4448\n",
      "1/1 - 0s - loss: 5095.8286\n",
      "1/1 - 0s - loss: 3946.2468\n",
      "1/1 - 0s - loss: 5734.9946\n",
      "1/1 - 0s - loss: 5258.9927\n",
      "Reducing exploration for all agents to 0.4321\n",
      "\n",
      "Episode 190: Starting computation.\n",
      "Random Seed Set to 290\n",
      "Episode 190: Finished running.\n",
      "Agent 0, Average Reward: -1575.15\n",
      "1/1 - 0s - loss: 5021.8721\n",
      "1/1 - 0s - loss: 7763.5352\n",
      "1/1 - 0s - loss: 4393.7920\n",
      "1/1 - 0s - loss: 5125.4990\n",
      "1/1 - 0s - loss: 4874.1094\n",
      "1/1 - 0s - loss: 5021.6001\n",
      "1/1 - 0s - loss: 5323.1235\n",
      "1/1 - 0s - loss: 5100.3892\n",
      "1/1 - 0s - loss: 4204.0840\n",
      "1/1 - 0s - loss: 6705.3823\n",
      "Reducing exploration for all agents to 0.4291\n",
      "\n",
      "Episode 191: Starting computation.\n",
      "Random Seed Set to 291\n",
      "Episode 191: Finished running.\n",
      "Agent 0, Average Reward: -1297.01\n",
      "1/1 - 0s - loss: 3545.0344\n",
      "1/1 - 0s - loss: 4089.2559\n",
      "1/1 - 0s - loss: 3833.0100\n",
      "1/1 - 0s - loss: 3917.3647\n",
      "1/1 - 0s - loss: 4652.2505\n",
      "1/1 - 0s - loss: 5847.2476\n",
      "1/1 - 0s - loss: 3391.7905\n",
      "1/1 - 0s - loss: 4249.8594\n",
      "1/1 - 0s - loss: 4461.9526\n",
      "1/1 - 0s - loss: 3552.0291\n",
      "Reducing exploration for all agents to 0.4261\n",
      "\n",
      "Episode 192: Starting computation.\n",
      "Random Seed Set to 292\n",
      "Episode 192: Finished running.\n",
      "Agent 0, Average Reward: -1299.92\n",
      "1/1 - 0s - loss: 5210.2236\n",
      "1/1 - 0s - loss: 4624.4805\n",
      "1/1 - 0s - loss: 3948.6431\n",
      "1/1 - 0s - loss: 3938.9807\n",
      "1/1 - 0s - loss: 4396.9287\n",
      "1/1 - 0s - loss: 4033.8528\n",
      "1/1 - 0s - loss: 3482.9387\n",
      "1/1 - 0s - loss: 2931.9338\n",
      "1/1 - 0s - loss: 5683.6348\n",
      "1/1 - 0s - loss: 5434.1553\n",
      "Reducing exploration for all agents to 0.4231\n",
      "\n",
      "Episode 193: Starting computation.\n",
      "Random Seed Set to 293\n",
      "Episode 193: Finished running.\n",
      "Agent 0, Average Reward: -1362.67\n",
      "1/1 - 0s - loss: 4838.2471\n",
      "1/1 - 0s - loss: 4017.3975\n",
      "1/1 - 0s - loss: 6153.8765\n",
      "1/1 - 0s - loss: 4613.4468\n",
      "1/1 - 0s - loss: 7549.3213\n",
      "1/1 - 0s - loss: 3503.1877\n",
      "1/1 - 0s - loss: 3608.5229\n",
      "1/1 - 0s - loss: 4722.7646\n",
      "1/1 - 0s - loss: 3933.2791\n",
      "1/1 - 0s - loss: 4834.2495\n",
      "Reducing exploration for all agents to 0.4201\n",
      "\n",
      "Episode 194: Starting computation.\n",
      "Random Seed Set to 294\n",
      "Episode 194: Finished running.\n",
      "Agent 0, Average Reward: -1432.59\n",
      "1/1 - 0s - loss: 5820.7959\n",
      "1/1 - 0s - loss: 4463.5591\n",
      "1/1 - 0s - loss: 3679.6577\n",
      "1/1 - 0s - loss: 3490.7012\n",
      "1/1 - 0s - loss: 3589.7842\n",
      "1/1 - 0s - loss: 4504.0981\n",
      "1/1 - 0s - loss: 4012.7024\n",
      "1/1 - 0s - loss: 3786.3101\n",
      "1/1 - 0s - loss: 3374.3809\n",
      "1/1 - 0s - loss: 5496.6401\n",
      "Reducing exploration for all agents to 0.4171\n",
      "\n",
      "Episode 195: Starting computation.\n",
      "Random Seed Set to 295\n",
      "Episode 195: Finished running.\n",
      "Agent 0, Average Reward: -1411.28\n",
      "1/1 - 0s - loss: 3441.5869\n",
      "1/1 - 0s - loss: 3844.6697\n",
      "1/1 - 0s - loss: 4340.6328\n",
      "1/1 - 0s - loss: 2912.2637\n",
      "1/1 - 0s - loss: 5751.5698\n",
      "1/1 - 0s - loss: 4277.7197\n",
      "1/1 - 0s - loss: 4448.5596\n",
      "1/1 - 0s - loss: 3460.4749\n",
      "1/1 - 0s - loss: 4775.7949\n",
      "1/1 - 0s - loss: 3118.7148\n",
      "Reducing exploration for all agents to 0.4141\n",
      "\n",
      "Episode 196: Starting computation.\n",
      "Random Seed Set to 296\n",
      "Episode 196: Finished running.\n",
      "Agent 0, Average Reward: -1565.14\n",
      "1/1 - 0s - loss: 3957.8779\n",
      "1/1 - 0s - loss: 4408.0298\n",
      "1/1 - 0s - loss: 4468.5439\n",
      "1/1 - 0s - loss: 4559.8228\n",
      "1/1 - 0s - loss: 6075.0620\n",
      "1/1 - 0s - loss: 3884.7217\n",
      "1/1 - 0s - loss: 4547.5337\n",
      "1/1 - 0s - loss: 3469.9138\n",
      "1/1 - 0s - loss: 3395.2476\n",
      "1/1 - 0s - loss: 4398.8794\n",
      "Reducing exploration for all agents to 0.4111\n",
      "\n",
      "Episode 197: Starting computation.\n",
      "Random Seed Set to 297\n",
      "Episode 197: Finished running.\n",
      "Agent 0, Average Reward: -1454.91\n",
      "1/1 - 0s - loss: 3183.3101\n",
      "1/1 - 0s - loss: 3272.5671\n",
      "1/1 - 0s - loss: 2676.2495\n",
      "1/1 - 0s - loss: 3996.0503\n",
      "1/1 - 0s - loss: 4223.2168\n",
      "1/1 - 0s - loss: 4438.5771\n",
      "1/1 - 0s - loss: 2950.7966\n",
      "1/1 - 0s - loss: 3655.7385\n",
      "1/1 - 0s - loss: 2857.7288\n",
      "1/1 - 0s - loss: 3468.9824\n",
      "Reducing exploration for all agents to 0.4081\n",
      "\n",
      "Episode 198: Starting computation.\n",
      "Random Seed Set to 298\n",
      "Episode 198: Finished running.\n",
      "Agent 0, Average Reward: -1350.71\n",
      "1/1 - 0s - loss: 3946.6499\n",
      "1/1 - 0s - loss: 3238.8701\n",
      "1/1 - 0s - loss: 3503.8833\n",
      "1/1 - 0s - loss: 5333.7485\n",
      "1/1 - 0s - loss: 5829.3032\n",
      "1/1 - 0s - loss: 6028.5903\n",
      "1/1 - 0s - loss: 3206.0535\n",
      "1/1 - 0s - loss: 4783.5859\n",
      "1/1 - 0s - loss: 3905.9309\n",
      "1/1 - 0s - loss: 3756.9846\n",
      "Reducing exploration for all agents to 0.4051\n",
      "\n",
      "Episode 199: Starting computation.\n",
      "Random Seed Set to 299\n",
      "Episode 199: Finished running.\n",
      "Agent 0, Average Reward: -1264.66\n",
      "1/1 - 0s - loss: 3890.9065\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 - 0s - loss: 3685.4182\n",
      "1/1 - 0s - loss: 4958.7241\n",
      "1/1 - 0s - loss: 4882.3105\n",
      "1/1 - 0s - loss: 5128.8818\n",
      "1/1 - 0s - loss: 4619.4751\n",
      "1/1 - 0s - loss: 4573.9854\n",
      "1/1 - 0s - loss: 3155.8694\n",
      "1/1 - 0s - loss: 5023.1611\n",
      "1/1 - 0s - loss: 3427.7107\n",
      "Reducing exploration for all agents to 0.4021\n",
      "\n",
      "Episode 200: Starting computation.\n",
      "Random Seed Set to 300\n",
      "Episode 200: Finished running.\n",
      "Agent 0, Average Reward: -1460.6\n",
      "1/1 - 0s - loss: 4973.9302\n",
      "1/1 - 0s - loss: 5789.1841\n",
      "1/1 - 0s - loss: 3529.8447\n",
      "1/1 - 0s - loss: 4844.5625\n",
      "1/1 - 0s - loss: 6476.2861\n",
      "1/1 - 0s - loss: 4380.6206\n",
      "1/1 - 0s - loss: 4605.8906\n",
      "1/1 - 0s - loss: 3632.8628\n",
      "1/1 - 0s - loss: 3811.0918\n",
      "1/1 - 0s - loss: 4483.0254\n",
      "Weights succesfully copied to Target model for Agent 0.\n",
      "Saving architecture, weights and optimizer state for agent-0\n",
      "Dumping agent-0 memory into pickle file\n",
      "Dumping Training Results into pickle file.\n",
      "Dumping Loss Results into pickle file.\n",
      "Reducing exploration for all agents to 0.3991\n",
      "\n",
      "Episode 201: Starting computation.\n",
      "Random Seed Set to 301\n",
      "Episode 201: Finished running.\n",
      "Agent 0, Average Reward: -1460.01\n",
      "1/1 - 0s - loss: 51966.3711\n",
      "1/1 - 0s - loss: 5070.2378\n",
      "1/1 - 0s - loss: 49400.1953\n",
      "1/1 - 0s - loss: 11055.3154\n",
      "1/1 - 0s - loss: 20113.9160\n",
      "1/1 - 0s - loss: 28397.8711\n",
      "1/1 - 0s - loss: 4647.7368\n",
      "1/1 - 0s - loss: 22205.1582\n",
      "1/1 - 0s - loss: 16882.0723\n",
      "1/1 - 0s - loss: 6880.3574\n",
      "Reducing exploration for all agents to 0.3961\n",
      "\n",
      "Episode 202: Starting computation.\n",
      "Random Seed Set to 302\n",
      "Episode 202: Finished running.\n",
      "Agent 0, Average Reward: -1462.98\n",
      "1/1 - 0s - loss: 19403.9590\n",
      "1/1 - 0s - loss: 11188.1484\n",
      "1/1 - 0s - loss: 6268.6245\n",
      "1/1 - 0s - loss: 21185.3984\n",
      "1/1 - 0s - loss: 10629.9863\n",
      "1/1 - 0s - loss: 7747.1523\n",
      "1/1 - 0s - loss: 17619.0312\n",
      "1/1 - 0s - loss: 6161.7866\n",
      "1/1 - 0s - loss: 6722.6025\n",
      "1/1 - 0s - loss: 13780.2617\n",
      "Reducing exploration for all agents to 0.3931\n",
      "\n",
      "Episode 203: Starting computation.\n",
      "Random Seed Set to 303\n",
      "Episode 203: Finished running.\n",
      "Agent 0, Average Reward: -1549.23\n",
      "1/1 - 0s - loss: 3889.4426\n",
      "1/1 - 0s - loss: 6097.5459\n",
      "1/1 - 0s - loss: 9707.6387\n",
      "1/1 - 0s - loss: 4657.2505\n",
      "1/1 - 0s - loss: 7168.5952\n",
      "1/1 - 0s - loss: 8817.9590\n",
      "1/1 - 0s - loss: 5169.0693\n",
      "1/1 - 0s - loss: 3791.7368\n",
      "1/1 - 0s - loss: 5253.3525\n",
      "1/1 - 0s - loss: 4664.3760\n",
      "Reducing exploration for all agents to 0.3901\n",
      "\n",
      "Episode 204: Starting computation.\n",
      "Random Seed Set to 304\n",
      "Episode 204: Finished running.\n",
      "Agent 0, Average Reward: -2219.17\n",
      "1/1 - 0s - loss: 6154.5059\n",
      "1/1 - 0s - loss: 5563.1650\n",
      "1/1 - 0s - loss: 5190.4199\n",
      "1/1 - 0s - loss: 4195.8003\n",
      "1/1 - 0s - loss: 14227.2275\n",
      "1/1 - 0s - loss: 5779.3062\n",
      "1/1 - 0s - loss: 4236.3135\n",
      "1/1 - 0s - loss: 5441.7993\n",
      "1/1 - 0s - loss: 4298.9429\n",
      "1/1 - 0s - loss: 4155.3833\n",
      "Reducing exploration for all agents to 0.3871\n",
      "\n",
      "Episode 205: Starting computation.\n",
      "Random Seed Set to 305\n",
      "Episode 205: Finished running.\n",
      "Agent 0, Average Reward: -1959.88\n",
      "1/1 - 0s - loss: 4104.2905\n",
      "1/1 - 0s - loss: 4814.5986\n",
      "1/1 - 0s - loss: 3873.4080\n",
      "1/1 - 0s - loss: 6851.2026\n",
      "1/1 - 0s - loss: 3525.7415\n",
      "1/1 - 0s - loss: 4101.4961\n",
      "1/1 - 0s - loss: 4190.7524\n",
      "1/1 - 0s - loss: 3852.9390\n",
      "1/1 - 0s - loss: 3572.8706\n",
      "1/1 - 0s - loss: 3977.2773\n",
      "Reducing exploration for all agents to 0.3841\n",
      "\n",
      "Episode 206: Starting computation.\n",
      "Random Seed Set to 306\n",
      "Episode 206: Finished running.\n",
      "Agent 0, Average Reward: -1178.74\n",
      "1/1 - 0s - loss: 7906.3940\n",
      "1/1 - 0s - loss: 4712.0913\n",
      "1/1 - 0s - loss: 4149.2144\n",
      "1/1 - 0s - loss: 4718.5508\n",
      "1/1 - 0s - loss: 5600.7817\n",
      "1/1 - 0s - loss: 6563.3594\n",
      "1/1 - 0s - loss: 4387.0332\n",
      "1/1 - 0s - loss: 4298.6509\n",
      "1/1 - 0s - loss: 3656.2119\n",
      "1/1 - 0s - loss: 13316.7441\n",
      "Reducing exploration for all agents to 0.3811\n",
      "\n",
      "Episode 207: Starting computation.\n",
      "Random Seed Set to 307\n",
      "Episode 207: Finished running.\n",
      "Agent 0, Average Reward: -1487.0\n",
      "1/1 - 0s - loss: 4089.6936\n",
      "1/1 - 0s - loss: 5549.1143\n",
      "1/1 - 0s - loss: 3140.8013\n",
      "1/1 - 0s - loss: 11874.0264\n",
      "1/1 - 0s - loss: 3814.1812\n",
      "1/1 - 0s - loss: 4234.1016\n",
      "1/1 - 0s - loss: 4490.3867\n",
      "1/1 - 0s - loss: 4231.3760\n",
      "1/1 - 0s - loss: 3481.2205\n",
      "1/1 - 0s - loss: 3407.1768\n",
      "Reducing exploration for all agents to 0.3781\n",
      "\n",
      "Episode 208: Starting computation.\n",
      "Random Seed Set to 308\n",
      "Episode 208: Finished running.\n",
      "Agent 0, Average Reward: -1423.97\n",
      "1/1 - 0s - loss: 5502.4307\n",
      "1/1 - 0s - loss: 4632.2529\n",
      "1/1 - 0s - loss: 3925.5532\n",
      "1/1 - 0s - loss: 3396.0786\n",
      "1/1 - 0s - loss: 3810.3977\n",
      "1/1 - 0s - loss: 3925.6279\n",
      "1/1 - 0s - loss: 4635.5684\n",
      "1/1 - 0s - loss: 3651.7888\n",
      "1/1 - 0s - loss: 5512.4277\n",
      "1/1 - 0s - loss: 5603.4736\n",
      "Reducing exploration for all agents to 0.3751\n",
      "\n",
      "Episode 209: Starting computation.\n",
      "Random Seed Set to 309\n",
      "Episode 209: Finished running.\n",
      "Agent 0, Average Reward: -1576.17\n",
      "1/1 - 0s - loss: 5553.1626\n",
      "1/1 - 0s - loss: 5478.4497\n",
      "1/1 - 0s - loss: 3643.2009\n",
      "1/1 - 0s - loss: 5193.9844\n",
      "1/1 - 0s - loss: 5054.6729\n",
      "1/1 - 0s - loss: 4388.8315\n",
      "1/1 - 0s - loss: 4875.1016\n",
      "1/1 - 0s - loss: 2987.4287\n",
      "1/1 - 0s - loss: 3700.1335\n",
      "1/1 - 0s - loss: 5128.2373\n",
      "Reducing exploration for all agents to 0.3721\n",
      "\n",
      "Episode 210: Starting computation.\n",
      "Random Seed Set to 310\n",
      "Episode 210: Finished running.\n",
      "Agent 0, Average Reward: -1320.03\n",
      "1/1 - 0s - loss: 3621.0166\n",
      "1/1 - 0s - loss: 3465.7246\n",
      "1/1 - 0s - loss: 3954.5420\n",
      "1/1 - 0s - loss: 2600.9465\n",
      "1/1 - 0s - loss: 5107.3960\n",
      "1/1 - 0s - loss: 4585.0571\n",
      "1/1 - 0s - loss: 3666.9536\n",
      "1/1 - 0s - loss: 4871.7891\n",
      "1/1 - 0s - loss: 3001.7100\n",
      "1/1 - 0s - loss: 4783.3613\n",
      "Reducing exploration for all agents to 0.3691\n",
      "\n",
      "Episode 211: Starting computation.\n",
      "Random Seed Set to 311\n",
      "Episode 211: Finished running.\n",
      "Agent 0, Average Reward: -1329.1\n",
      "1/1 - 0s - loss: 4011.4150\n",
      "1/1 - 0s - loss: 4846.9912\n",
      "1/1 - 0s - loss: 4245.4468\n",
      "1/1 - 0s - loss: 5730.2827\n",
      "1/1 - 0s - loss: 3815.9004\n",
      "1/1 - 0s - loss: 4618.3076\n",
      "1/1 - 0s - loss: 3823.0852\n",
      "1/1 - 0s - loss: 5876.9150\n",
      "1/1 - 0s - loss: 3580.0112\n",
      "1/1 - 0s - loss: 3796.4089\n",
      "Reducing exploration for all agents to 0.366\n",
      "\n",
      "Episode 212: Starting computation.\n",
      "Random Seed Set to 312\n",
      "Episode 212: Finished running.\n",
      "Agent 0, Average Reward: -1631.64\n",
      "1/1 - 0s - loss: 4269.9326\n",
      "1/1 - 0s - loss: 3231.0852\n",
      "1/1 - 0s - loss: 11404.4561\n",
      "1/1 - 0s - loss: 4530.3838\n",
      "1/1 - 0s - loss: 5074.0781\n",
      "1/1 - 0s - loss: 4970.5337\n",
      "1/1 - 0s - loss: 3684.0166\n",
      "1/1 - 0s - loss: 4543.5518\n",
      "1/1 - 0s - loss: 3302.1606\n",
      "1/1 - 0s - loss: 4778.1250\n",
      "Reducing exploration for all agents to 0.363\n",
      "\n",
      "Episode 213: Starting computation.\n",
      "Random Seed Set to 313\n",
      "Episode 213: Finished running.\n",
      "Agent 0, Average Reward: -1537.03\n",
      "1/1 - 0s - loss: 4460.3306\n",
      "1/1 - 0s - loss: 4319.3301\n",
      "1/1 - 0s - loss: 4049.6482\n",
      "1/1 - 0s - loss: 3341.4883\n",
      "1/1 - 0s - loss: 5017.4385\n",
      "1/1 - 0s - loss: 3016.8948\n",
      "1/1 - 0s - loss: 2973.0090\n",
      "1/1 - 0s - loss: 3255.2229\n",
      "1/1 - 0s - loss: 3682.4197\n",
      "1/1 - 0s - loss: 3088.5432\n",
      "Reducing exploration for all agents to 0.36\n",
      "\n",
      "Episode 214: Starting computation.\n",
      "Random Seed Set to 314\n",
      "Episode 214: Finished running.\n",
      "Agent 0, Average Reward: -1595.53\n",
      "1/1 - 0s - loss: 5079.7578\n",
      "1/1 - 0s - loss: 4749.4565\n",
      "1/1 - 0s - loss: 3731.7971\n",
      "1/1 - 0s - loss: 4259.3306\n",
      "1/1 - 0s - loss: 3978.0938\n",
      "1/1 - 0s - loss: 3951.1702\n",
      "1/1 - 0s - loss: 3885.9653\n",
      "1/1 - 0s - loss: 2622.2410\n",
      "1/1 - 0s - loss: 3521.1292\n",
      "1/1 - 0s - loss: 5186.0942\n",
      "Reducing exploration for all agents to 0.357\n",
      "\n",
      "Episode 215: Starting computation.\n",
      "Random Seed Set to 315\n",
      "Episode 215: Finished running.\n",
      "Agent 0, Average Reward: -1676.15\n",
      "1/1 - 0s - loss: 3211.7085\n",
      "1/1 - 0s - loss: 3974.4819\n",
      "1/1 - 0s - loss: 5698.3833\n",
      "1/1 - 0s - loss: 4928.0991\n",
      "1/1 - 0s - loss: 4507.1138\n",
      "1/1 - 0s - loss: 4393.2642\n",
      "1/1 - 0s - loss: 3839.7432\n",
      "1/1 - 0s - loss: 3057.9031\n",
      "1/1 - 0s - loss: 4556.1504\n",
      "1/1 - 0s - loss: 3151.6584\n",
      "Reducing exploration for all agents to 0.354\n",
      "\n",
      "Episode 216: Starting computation.\n",
      "Random Seed Set to 316\n",
      "Episode 216: Finished running.\n",
      "Agent 0, Average Reward: -1546.42\n",
      "1/1 - 0s - loss: 3376.9321\n",
      "1/1 - 0s - loss: 3515.6804\n",
      "1/1 - 0s - loss: 5144.6055\n",
      "1/1 - 0s - loss: 3149.7178\n",
      "1/1 - 0s - loss: 5800.4678\n",
      "1/1 - 0s - loss: 3065.6233\n",
      "1/1 - 0s - loss: 3402.6477\n",
      "1/1 - 0s - loss: 4588.6040\n",
      "1/1 - 0s - loss: 4511.5029\n",
      "1/1 - 0s - loss: 3843.8894\n",
      "Reducing exploration for all agents to 0.351\n",
      "\n",
      "Episode 217: Starting computation.\n",
      "Random Seed Set to 317\n",
      "Episode 217: Finished running.\n",
      "Agent 0, Average Reward: -1438.89\n",
      "1/1 - 0s - loss: 3508.8489\n",
      "1/1 - 0s - loss: 4646.2285\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 - 0s - loss: 4591.1777\n",
      "1/1 - 0s - loss: 4033.4260\n",
      "1/1 - 0s - loss: 3233.1064\n",
      "1/1 - 0s - loss: 3721.2944\n",
      "1/1 - 0s - loss: 3426.9463\n",
      "1/1 - 0s - loss: 4225.0547\n",
      "1/1 - 0s - loss: 3486.4683\n",
      "1/1 - 0s - loss: 3837.7554\n",
      "Reducing exploration for all agents to 0.348\n",
      "\n",
      "Episode 218: Starting computation.\n",
      "Random Seed Set to 318\n",
      "Episode 218: Finished running.\n",
      "Agent 0, Average Reward: -1399.13\n",
      "1/1 - 0s - loss: 2635.6895\n",
      "1/1 - 0s - loss: 3184.3228\n",
      "1/1 - 0s - loss: 3231.5210\n",
      "1/1 - 0s - loss: 2758.3271\n",
      "1/1 - 0s - loss: 3374.4194\n",
      "1/1 - 0s - loss: 4029.8547\n",
      "1/1 - 0s - loss: 4066.7346\n",
      "1/1 - 0s - loss: 4319.9746\n",
      "1/1 - 0s - loss: 3892.5422\n",
      "1/1 - 0s - loss: 2829.6763\n",
      "Reducing exploration for all agents to 0.345\n",
      "\n",
      "Episode 219: Starting computation.\n",
      "Random Seed Set to 319\n",
      "Episode 219: Finished running.\n",
      "Agent 0, Average Reward: -1679.77\n",
      "1/1 - 0s - loss: 3557.1697\n",
      "1/1 - 0s - loss: 3750.5793\n",
      "1/1 - 0s - loss: 3736.2571\n",
      "1/1 - 0s - loss: 3443.2708\n",
      "1/1 - 0s - loss: 3256.2190\n",
      "1/1 - 0s - loss: 3559.6711\n",
      "1/1 - 0s - loss: 3111.3401\n",
      "1/1 - 0s - loss: 3682.2007\n",
      "1/1 - 0s - loss: 2901.9194\n",
      "1/1 - 0s - loss: 3423.6028\n",
      "Reducing exploration for all agents to 0.342\n",
      "\n",
      "Episode 220: Starting computation.\n",
      "Random Seed Set to 320\n",
      "Episode 220: Finished running.\n",
      "Agent 0, Average Reward: -1651.66\n",
      "1/1 - 0s - loss: 3629.5662\n",
      "1/1 - 0s - loss: 4926.8892\n",
      "1/1 - 0s - loss: 4687.0972\n",
      "1/1 - 0s - loss: 3645.8672\n",
      "1/1 - 0s - loss: 3730.2180\n",
      "1/1 - 0s - loss: 3186.9702\n",
      "1/1 - 0s - loss: 3477.9160\n",
      "1/1 - 0s - loss: 5132.9155\n",
      "1/1 - 0s - loss: 3720.0569\n",
      "1/1 - 0s - loss: 3111.1985\n",
      "Weights succesfully copied to Target model for Agent 0.\n",
      "Saving architecture, weights and optimizer state for agent-0\n",
      "Dumping agent-0 memory into pickle file\n",
      "Dumping Training Results into pickle file.\n",
      "Dumping Loss Results into pickle file.\n",
      "Reducing exploration for all agents to 0.339\n",
      "\n",
      "Episode 221: Starting computation.\n",
      "Random Seed Set to 321\n",
      "Episode 221: Finished running.\n",
      "Agent 0, Average Reward: -1523.94\n",
      "1/1 - 0s - loss: 48827.4102\n",
      "1/1 - 0s - loss: 7894.8076\n",
      "1/1 - 0s - loss: 59197.4688\n",
      "1/1 - 0s - loss: 9086.1758\n",
      "1/1 - 0s - loss: 29318.3730\n",
      "1/1 - 0s - loss: 38754.1484\n",
      "1/1 - 0s - loss: 4279.1104\n",
      "1/1 - 0s - loss: 29422.8965\n",
      "1/1 - 0s - loss: 15901.6123\n",
      "1/1 - 0s - loss: 7077.9551\n",
      "Reducing exploration for all agents to 0.336\n",
      "\n",
      "Episode 222: Starting computation.\n",
      "Random Seed Set to 322\n",
      "Episode 222: Finished running.\n",
      "Agent 0, Average Reward: -1738.02\n",
      "1/1 - 0s - loss: 24826.8613\n",
      "1/1 - 0s - loss: 10123.8330\n",
      "1/1 - 0s - loss: 6488.1802\n",
      "1/1 - 0s - loss: 24757.5742\n",
      "1/1 - 0s - loss: 5016.6089\n",
      "1/1 - 0s - loss: 11293.9160\n",
      "1/1 - 0s - loss: 12874.3652\n",
      "1/1 - 0s - loss: 2808.9302\n",
      "1/1 - 0s - loss: 8658.2041\n",
      "1/1 - 0s - loss: 6285.2847\n",
      "Reducing exploration for all agents to 0.333\n",
      "\n",
      "Episode 223: Starting computation.\n",
      "Random Seed Set to 323\n",
      "Episode 223: Finished running.\n",
      "Agent 0, Average Reward: -1093.36\n",
      "1/1 - 0s - loss: 4912.1021\n",
      "1/1 - 0s - loss: 8762.7012\n",
      "1/1 - 0s - loss: 8322.7695\n",
      "1/1 - 0s - loss: 3844.5615\n",
      "1/1 - 0s - loss: 7980.0513\n",
      "1/1 - 0s - loss: 4772.0430\n",
      "1/1 - 0s - loss: 4256.3350\n",
      "1/1 - 0s - loss: 8098.2900\n",
      "1/1 - 0s - loss: 4600.4634\n",
      "1/1 - 0s - loss: 5959.2163\n",
      "Reducing exploration for all agents to 0.33\n",
      "\n",
      "Episode 224: Starting computation.\n",
      "Random Seed Set to 324\n",
      "Episode 224: Finished running.\n",
      "Agent 0, Average Reward: -1608.09\n",
      "1/1 - 0s - loss: 5912.6743\n",
      "1/1 - 0s - loss: 3344.6348\n",
      "1/1 - 0s - loss: 4929.7603\n",
      "1/1 - 0s - loss: 7200.7427\n",
      "1/1 - 0s - loss: 4376.7427\n",
      "1/1 - 0s - loss: 8993.0781\n",
      "1/1 - 0s - loss: 4137.0103\n",
      "1/1 - 0s - loss: 5309.1265\n",
      "1/1 - 0s - loss: 4785.0776\n",
      "1/1 - 0s - loss: 3648.3569\n",
      "Reducing exploration for all agents to 0.327\n",
      "\n",
      "Episode 225: Starting computation.\n",
      "Random Seed Set to 325\n",
      "Episode 225: Finished running.\n",
      "Agent 0, Average Reward: -1681.17\n",
      "1/1 - 0s - loss: 3421.6541\n",
      "1/1 - 0s - loss: 4498.5532\n",
      "1/1 - 0s - loss: 4680.7407\n",
      "1/1 - 0s - loss: 3619.4883\n",
      "1/1 - 0s - loss: 4121.5654\n",
      "1/1 - 0s - loss: 3435.9846\n",
      "1/1 - 0s - loss: 3654.1658\n",
      "1/1 - 0s - loss: 4310.9722\n",
      "1/1 - 0s - loss: 3676.1936\n",
      "1/1 - 0s - loss: 4214.5659\n",
      "Reducing exploration for all agents to 0.324\n",
      "\n",
      "Episode 226: Starting computation.\n",
      "Random Seed Set to 326\n",
      "Episode 226: Finished running.\n",
      "Agent 0, Average Reward: -1637.55\n",
      "1/1 - 0s - loss: 4692.4629\n",
      "1/1 - 0s - loss: 2483.2727\n",
      "1/1 - 0s - loss: 3723.0168\n",
      "1/1 - 0s - loss: 3604.4875\n",
      "1/1 - 0s - loss: 3279.6436\n",
      "1/1 - 0s - loss: 2663.5168\n",
      "1/1 - 0s - loss: 5905.7056\n",
      "1/1 - 0s - loss: 16896.8789\n",
      "1/1 - 0s - loss: 3131.8320\n",
      "1/1 - 0s - loss: 5654.7915\n",
      "Reducing exploration for all agents to 0.321\n",
      "\n",
      "Episode 227: Starting computation.\n",
      "Random Seed Set to 327\n",
      "Episode 227: Finished running.\n",
      "Agent 0, Average Reward: -1435.36\n",
      "1/1 - 0s - loss: 4083.4111\n",
      "1/1 - 0s - loss: 4648.5127\n",
      "1/1 - 0s - loss: 5184.9170\n",
      "1/1 - 0s - loss: 3990.9646\n",
      "1/1 - 0s - loss: 3462.3071\n",
      "1/1 - 0s - loss: 3188.0188\n",
      "1/1 - 0s - loss: 4262.9629\n",
      "1/1 - 0s - loss: 5156.8394\n",
      "1/1 - 0s - loss: 3741.6589\n",
      "1/1 - 0s - loss: 5472.2725\n",
      "Reducing exploration for all agents to 0.318\n",
      "\n",
      "Episode 228: Starting computation.\n",
      "Random Seed Set to 328\n",
      "Episode 228: Finished running.\n",
      "Agent 0, Average Reward: -1428.96\n",
      "1/1 - 0s - loss: 6011.6787\n",
      "1/1 - 0s - loss: 4411.2637\n",
      "1/1 - 0s - loss: 4857.7197\n",
      "1/1 - 0s - loss: 6304.2637\n",
      "1/1 - 0s - loss: 4284.7573\n",
      "1/1 - 0s - loss: 4353.4810\n",
      "1/1 - 0s - loss: 4134.5435\n",
      "1/1 - 0s - loss: 5091.5996\n",
      "1/1 - 0s - loss: 4267.3926\n",
      "1/1 - 0s - loss: 3465.1753\n",
      "Reducing exploration for all agents to 0.315\n",
      "\n",
      "Episode 229: Starting computation.\n",
      "Random Seed Set to 329\n",
      "Episode 229: Finished running.\n",
      "Agent 0, Average Reward: -1781.6\n",
      "1/1 - 0s - loss: 4787.2666\n",
      "1/1 - 0s - loss: 7655.6997\n",
      "1/1 - 0s - loss: 4728.3145\n",
      "1/1 - 0s - loss: 4607.1685\n",
      "1/1 - 0s - loss: 4279.8057\n",
      "1/1 - 0s - loss: 3442.8159\n",
      "1/1 - 0s - loss: 5179.9736\n",
      "1/1 - 0s - loss: 5923.3379\n",
      "1/1 - 0s - loss: 5729.8594\n",
      "1/1 - 0s - loss: 5204.5078\n",
      "Reducing exploration for all agents to 0.312\n",
      "\n",
      "Episode 230: Starting computation.\n",
      "Random Seed Set to 330\n",
      "Episode 230: Finished running.\n",
      "Agent 0, Average Reward: -1617.07\n",
      "1/1 - 0s - loss: 5381.2881\n",
      "1/1 - 0s - loss: 4277.6099\n",
      "1/1 - 0s - loss: 4214.2622\n",
      "1/1 - 0s - loss: 3107.7800\n",
      "1/1 - 0s - loss: 4736.1191\n",
      "1/1 - 0s - loss: 5290.3721\n",
      "1/1 - 0s - loss: 3162.6704\n",
      "1/1 - 0s - loss: 2812.3652\n",
      "1/1 - 0s - loss: 4261.3809\n",
      "1/1 - 0s - loss: 4779.1387\n",
      "Reducing exploration for all agents to 0.309\n",
      "\n",
      "Episode 231: Starting computation.\n",
      "Random Seed Set to 331\n",
      "Episode 231: Finished running.\n",
      "Agent 0, Average Reward: -1501.79\n",
      "1/1 - 0s - loss: 6299.7998\n",
      "1/1 - 0s - loss: 6150.4893\n",
      "1/1 - 0s - loss: 5301.2227\n",
      "1/1 - 0s - loss: 6432.6118\n",
      "1/1 - 0s - loss: 6027.5566\n",
      "1/1 - 0s - loss: 5722.8525\n",
      "1/1 - 0s - loss: 4644.2725\n",
      "1/1 - 0s - loss: 4325.6826\n",
      "1/1 - 0s - loss: 4520.1821\n",
      "1/1 - 0s - loss: 5304.4458\n",
      "Reducing exploration for all agents to 0.306\n",
      "\n",
      "Episode 232: Starting computation.\n",
      "Random Seed Set to 332\n",
      "Episode 232: Finished running.\n",
      "Agent 0, Average Reward: -1579.52\n",
      "1/1 - 0s - loss: 3361.4912\n",
      "1/1 - 0s - loss: 3820.2952\n",
      "1/1 - 0s - loss: 6767.4326\n",
      "1/1 - 0s - loss: 4696.7930\n",
      "1/1 - 0s - loss: 4023.7483\n",
      "1/1 - 0s - loss: 4905.3960\n",
      "1/1 - 0s - loss: 4250.2617\n",
      "1/1 - 0s - loss: 4503.6216\n",
      "1/1 - 0s - loss: 4283.1006\n",
      "1/1 - 0s - loss: 3653.8081\n",
      "Reducing exploration for all agents to 0.303\n",
      "\n",
      "Episode 233: Starting computation.\n",
      "Random Seed Set to 333\n",
      "Episode 233: Finished running.\n",
      "Agent 0, Average Reward: -1620.04\n",
      "1/1 - 0s - loss: 4311.2437\n",
      "1/1 - 0s - loss: 5707.6343\n",
      "1/1 - 0s - loss: 4146.3618\n",
      "1/1 - 0s - loss: 4282.6123\n",
      "1/1 - 0s - loss: 5749.9497\n",
      "1/1 - 0s - loss: 3805.4429\n",
      "1/1 - 0s - loss: 4022.7817\n",
      "1/1 - 0s - loss: 5641.2554\n",
      "1/1 - 0s - loss: 5511.9624\n",
      "1/1 - 0s - loss: 4806.1934\n",
      "Reducing exploration for all agents to 0.2999\n",
      "\n",
      "Episode 234: Starting computation.\n",
      "Random Seed Set to 334\n",
      "Episode 234: Finished running.\n",
      "Agent 0, Average Reward: -1569.34\n",
      "1/1 - 0s - loss: 5072.7495\n",
      "1/1 - 0s - loss: 4085.2563\n",
      "1/1 - 0s - loss: 4041.2712\n",
      "1/1 - 0s - loss: 3762.0674\n",
      "1/1 - 0s - loss: 4253.2671\n",
      "1/1 - 0s - loss: 4292.9165\n",
      "1/1 - 0s - loss: 7777.6357\n",
      "1/1 - 0s - loss: 5326.6440\n",
      "1/1 - 0s - loss: 4396.1904\n",
      "1/1 - 0s - loss: 6350.1655\n",
      "Reducing exploration for all agents to 0.2969\n",
      "\n",
      "Episode 235: Starting computation.\n",
      "Random Seed Set to 335\n",
      "Episode 235: Finished running.\n",
      "Agent 0, Average Reward: -1738.03\n",
      "1/1 - 0s - loss: 4827.4111\n",
      "1/1 - 0s - loss: 3538.4866\n",
      "1/1 - 0s - loss: 3485.6702\n",
      "1/1 - 0s - loss: 3798.9485\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 - 0s - loss: 5010.8149\n",
      "1/1 - 0s - loss: 3489.8755\n",
      "1/1 - 0s - loss: 5697.4761\n",
      "1/1 - 0s - loss: 3323.8152\n",
      "1/1 - 0s - loss: 5383.6948\n",
      "1/1 - 0s - loss: 3446.2493\n",
      "Reducing exploration for all agents to 0.2939\n",
      "\n",
      "Episode 236: Starting computation.\n",
      "Random Seed Set to 336\n",
      "Episode 236: Finished running.\n",
      "Agent 0, Average Reward: -1595.31\n",
      "1/1 - 0s - loss: 3991.6995\n",
      "1/1 - 0s - loss: 2502.2634\n",
      "1/1 - 0s - loss: 4711.1631\n",
      "1/1 - 0s - loss: 4234.2573\n",
      "1/1 - 0s - loss: 2901.5369\n",
      "1/1 - 0s - loss: 2688.3730\n",
      "1/1 - 0s - loss: 3289.7883\n",
      "1/1 - 0s - loss: 3279.8354\n",
      "1/1 - 0s - loss: 3021.6868\n",
      "1/1 - 0s - loss: 3376.6611\n",
      "Reducing exploration for all agents to 0.2909\n",
      "\n",
      "Episode 237: Starting computation.\n",
      "Random Seed Set to 337\n",
      "Episode 237: Finished running.\n",
      "Agent 0, Average Reward: -1545.23\n",
      "1/1 - 0s - loss: 3165.8767\n",
      "1/1 - 0s - loss: 4617.2676\n",
      "1/1 - 0s - loss: 2896.7280\n",
      "1/1 - 0s - loss: 4349.7661\n",
      "1/1 - 0s - loss: 4932.6284\n",
      "1/1 - 0s - loss: 4597.6694\n",
      "1/1 - 0s - loss: 3690.3867\n",
      "1/1 - 0s - loss: 3576.8950\n",
      "1/1 - 0s - loss: 3661.2681\n",
      "1/1 - 0s - loss: 3408.5732\n",
      "Reducing exploration for all agents to 0.2879\n",
      "\n",
      "Episode 238: Starting computation.\n",
      "Random Seed Set to 338\n",
      "Episode 238: Finished running.\n",
      "Agent 0, Average Reward: -1832.15\n",
      "1/1 - 0s - loss: 3237.1621\n",
      "1/1 - 0s - loss: 3765.8623\n",
      "1/1 - 0s - loss: 3166.5776\n",
      "1/1 - 0s - loss: 3955.1062\n",
      "1/1 - 0s - loss: 3405.6438\n",
      "1/1 - 0s - loss: 3813.6914\n",
      "1/1 - 0s - loss: 3456.3867\n",
      "1/1 - 0s - loss: 3747.5742\n",
      "1/1 - 0s - loss: 2799.6057\n",
      "1/1 - 0s - loss: 3861.3835\n",
      "Reducing exploration for all agents to 0.2849\n",
      "\n",
      "Episode 239: Starting computation.\n",
      "Random Seed Set to 339\n",
      "Episode 239: Finished running.\n",
      "Agent 0, Average Reward: -1714.9\n",
      "1/1 - 0s - loss: 3481.1475\n",
      "1/1 - 0s - loss: 3229.8457\n",
      "1/1 - 0s - loss: 4563.1597\n",
      "1/1 - 0s - loss: 5009.2397\n",
      "1/1 - 0s - loss: 4736.7100\n",
      "1/1 - 0s - loss: 2922.0330\n",
      "1/1 - 0s - loss: 5000.4404\n",
      "1/1 - 0s - loss: 4997.4771\n",
      "1/1 - 0s - loss: 4273.5107\n",
      "1/1 - 0s - loss: 5020.0039\n",
      "Reducing exploration for all agents to 0.2819\n",
      "\n",
      "Episode 240: Starting computation.\n",
      "Random Seed Set to 340\n",
      "Episode 240: Finished running.\n",
      "Agent 0, Average Reward: -1580.49\n",
      "1/1 - 0s - loss: 5115.4956\n",
      "1/1 - 0s - loss: 4840.9819\n",
      "1/1 - 0s - loss: 3673.2349\n",
      "1/1 - 0s - loss: 4749.5122\n",
      "1/1 - 0s - loss: 5210.5869\n",
      "1/1 - 0s - loss: 3211.8474\n",
      "1/1 - 0s - loss: 4883.1782\n",
      "1/1 - 0s - loss: 4384.8823\n",
      "1/1 - 0s - loss: 4532.1514\n",
      "1/1 - 0s - loss: 5094.8765\n",
      "Weights succesfully copied to Target model for Agent 0.\n",
      "Saving architecture, weights and optimizer state for agent-0\n",
      "Dumping agent-0 memory into pickle file\n",
      "Dumping Training Results into pickle file.\n",
      "Dumping Loss Results into pickle file.\n",
      "Reducing exploration for all agents to 0.2789\n",
      "\n",
      "Episode 241: Starting computation.\n",
      "Random Seed Set to 341\n",
      "Episode 241: Finished running.\n",
      "Agent 0, Average Reward: -1584.3\n",
      "1/1 - 0s - loss: 42935.8477\n",
      "1/1 - 0s - loss: 15896.4805\n",
      "1/1 - 0s - loss: 50794.6016\n",
      "1/1 - 0s - loss: 3555.7817\n",
      "1/1 - 0s - loss: 40698.8320\n",
      "1/1 - 0s - loss: 17529.2266\n",
      "1/1 - 0s - loss: 12985.6104\n",
      "1/1 - 0s - loss: 28707.3164\n",
      "1/1 - 0s - loss: 2957.9519\n",
      "1/1 - 0s - loss: 17589.9609\n",
      "Reducing exploration for all agents to 0.2759\n",
      "\n",
      "Episode 242: Starting computation.\n",
      "Random Seed Set to 342\n",
      "Episode 242: Finished running.\n",
      "Agent 0, Average Reward: -1370.03\n",
      "1/1 - 0s - loss: 14220.9316\n",
      "1/1 - 0s - loss: 4973.4717\n",
      "1/1 - 0s - loss: 17629.2734\n",
      "1/1 - 0s - loss: 7823.7632\n",
      "1/1 - 0s - loss: 8918.7354\n",
      "1/1 - 0s - loss: 15343.2158\n",
      "1/1 - 0s - loss: 5169.5117\n",
      "1/1 - 0s - loss: 10368.6865\n",
      "1/1 - 0s - loss: 13017.1875\n",
      "1/1 - 0s - loss: 4446.0454\n",
      "Reducing exploration for all agents to 0.2729\n",
      "\n",
      "Episode 243: Starting computation.\n",
      "Random Seed Set to 343\n",
      "Episode 243: Finished running.\n",
      "Agent 0, Average Reward: -1743.41\n",
      "1/1 - 0s - loss: 12192.0332\n",
      "1/1 - 0s - loss: 6467.5415\n",
      "1/1 - 0s - loss: 5152.5190\n",
      "1/1 - 0s - loss: 8076.5342\n",
      "1/1 - 0s - loss: 5822.5747\n",
      "1/1 - 0s - loss: 5483.0562\n",
      "1/1 - 0s - loss: 5274.7329\n",
      "1/1 - 0s - loss: 4916.3398\n",
      "1/1 - 0s - loss: 5278.2549\n",
      "1/1 - 0s - loss: 6641.9868\n",
      "Reducing exploration for all agents to 0.2699\n",
      "\n",
      "Episode 244: Starting computation.\n",
      "Random Seed Set to 344\n",
      "Episode 244: Finished running.\n",
      "Agent 0, Average Reward: -1826.43\n",
      "1/1 - 0s - loss: 7790.4453\n",
      "1/1 - 0s - loss: 5259.9268\n",
      "1/1 - 0s - loss: 3016.7354\n",
      "1/1 - 0s - loss: 4164.4487\n",
      "1/1 - 0s - loss: 3871.3083\n",
      "1/1 - 0s - loss: 3186.1504\n",
      "1/1 - 0s - loss: 4618.8003\n",
      "1/1 - 0s - loss: 4689.6426\n",
      "1/1 - 0s - loss: 3700.7258\n",
      "1/1 - 0s - loss: 4983.0884\n",
      "Reducing exploration for all agents to 0.2669\n",
      "\n",
      "Episode 245: Starting computation.\n",
      "Random Seed Set to 345\n",
      "Episode 245: Finished running.\n",
      "Agent 0, Average Reward: -1667.66\n",
      "1/1 - 0s - loss: 4225.7080\n",
      "1/1 - 0s - loss: 2547.1543\n",
      "1/1 - 0s - loss: 3240.7781\n",
      "1/1 - 0s - loss: 5339.3892\n",
      "1/1 - 0s - loss: 4254.5444\n",
      "1/1 - 0s - loss: 3315.2695\n",
      "1/1 - 0s - loss: 2910.0764\n",
      "1/1 - 0s - loss: 5155.7578\n",
      "1/1 - 0s - loss: 4306.5801\n",
      "1/1 - 0s - loss: 4064.1277\n",
      "Reducing exploration for all agents to 0.2639\n",
      "\n",
      "Episode 246: Starting computation.\n",
      "Random Seed Set to 346\n",
      "Episode 246: Finished running.\n",
      "Agent 0, Average Reward: -1770.68\n",
      "1/1 - 0s - loss: 4606.2432\n",
      "1/1 - 0s - loss: 2490.4067\n",
      "1/1 - 0s - loss: 3196.8904\n",
      "1/1 - 0s - loss: 4782.9224\n",
      "1/1 - 0s - loss: 3263.2571\n",
      "1/1 - 0s - loss: 5494.8657\n",
      "1/1 - 0s - loss: 5136.8623\n",
      "1/1 - 0s - loss: 3647.9915\n",
      "1/1 - 0s - loss: 4369.3613\n",
      "1/1 - 0s - loss: 4901.9736\n",
      "Reducing exploration for all agents to 0.2609\n",
      "\n",
      "Episode 247: Starting computation.\n",
      "Random Seed Set to 347\n",
      "Episode 247: Finished running.\n",
      "Agent 0, Average Reward: -1844.65\n",
      "1/1 - 0s - loss: 3786.2134\n",
      "1/1 - 0s - loss: 2775.8552\n",
      "1/1 - 0s - loss: 2758.7998\n",
      "1/1 - 0s - loss: 3256.5820\n",
      "1/1 - 0s - loss: 2911.2278\n",
      "1/1 - 0s - loss: 3348.9055\n",
      "1/1 - 0s - loss: 3488.2476\n",
      "1/1 - 0s - loss: 3141.7625\n",
      "1/1 - 0s - loss: 3178.7244\n",
      "1/1 - 0s - loss: 4886.7300\n",
      "Reducing exploration for all agents to 0.2579\n",
      "\n",
      "Episode 248: Starting computation.\n",
      "Random Seed Set to 348\n",
      "Episode 248: Finished running.\n",
      "Agent 0, Average Reward: -1922.48\n",
      "1/1 - 0s - loss: 2933.5405\n",
      "1/1 - 0s - loss: 2906.2485\n",
      "1/1 - 0s - loss: 3162.9780\n",
      "1/1 - 0s - loss: 2886.5774\n",
      "1/1 - 0s - loss: 2700.7527\n",
      "1/1 - 0s - loss: 3911.4231\n",
      "1/1 - 0s - loss: 4482.3291\n",
      "1/1 - 0s - loss: 3215.3862\n",
      "1/1 - 0s - loss: 2712.6504\n",
      "1/1 - 0s - loss: 3960.8076\n",
      "Reducing exploration for all agents to 0.2549\n",
      "\n",
      "Episode 249: Starting computation.\n",
      "Random Seed Set to 349\n",
      "Episode 249: Finished running.\n",
      "Agent 0, Average Reward: -2040.52\n",
      "1/1 - 0s - loss: 3339.8674\n",
      "1/1 - 0s - loss: 3958.6724\n",
      "1/1 - 0s - loss: 4892.9351\n",
      "1/1 - 0s - loss: 3971.9683\n",
      "1/1 - 0s - loss: 4228.7603\n",
      "1/1 - 0s - loss: 5334.2158\n",
      "1/1 - 0s - loss: 3757.2163\n",
      "1/1 - 0s - loss: 4319.3877\n",
      "1/1 - 0s - loss: 3326.5652\n",
      "1/1 - 0s - loss: 3914.2490\n",
      "Reducing exploration for all agents to 0.2519\n",
      "\n",
      "Episode 250: Starting computation.\n",
      "Random Seed Set to 350\n",
      "Episode 250: Finished running.\n",
      "Agent 0, Average Reward: -1762.92\n",
      "1/1 - 0s - loss: 4031.2114\n",
      "1/1 - 0s - loss: 4240.8350\n",
      "1/1 - 0s - loss: 3306.0891\n",
      "1/1 - 0s - loss: 3159.5847\n",
      "1/1 - 0s - loss: 2713.6355\n",
      "1/1 - 0s - loss: 3095.4465\n",
      "1/1 - 0s - loss: 2936.2749\n",
      "1/1 - 0s - loss: 4049.9978\n",
      "1/1 - 0s - loss: 3718.1655\n",
      "1/1 - 0s - loss: 5406.9209\n",
      "Reducing exploration for all agents to 0.2489\n",
      "\n",
      "Episode 251: Starting computation.\n",
      "Random Seed Set to 351\n",
      "Episode 251: Finished running.\n",
      "Agent 0, Average Reward: -1988.94\n",
      "1/1 - 0s - loss: 3423.4680\n",
      "1/1 - 0s - loss: 3068.0505\n",
      "1/1 - 0s - loss: 3246.3699\n",
      "1/1 - 0s - loss: 6864.0181\n",
      "1/1 - 0s - loss: 3268.6658\n",
      "1/1 - 0s - loss: 3753.6155\n",
      "1/1 - 0s - loss: 2937.8423\n",
      "1/1 - 0s - loss: 2965.1133\n",
      "1/1 - 0s - loss: 3494.9023\n",
      "1/1 - 0s - loss: 5877.8340\n",
      "Reducing exploration for all agents to 0.2459\n",
      "\n",
      "Episode 252: Starting computation.\n",
      "Random Seed Set to 352\n",
      "Episode 252: Finished running.\n",
      "Agent 0, Average Reward: -1781.1\n",
      "1/1 - 0s - loss: 3231.9497\n",
      "1/1 - 0s - loss: 3471.5293\n",
      "1/1 - 0s - loss: 3315.3066\n",
      "1/1 - 0s - loss: 3495.1472\n",
      "1/1 - 0s - loss: 6280.3716\n",
      "1/1 - 0s - loss: 5532.3213\n",
      "1/1 - 0s - loss: 3212.3118\n",
      "1/1 - 0s - loss: 6668.5171\n",
      "1/1 - 0s - loss: 3560.3430\n",
      "1/1 - 0s - loss: 2976.4583\n",
      "Reducing exploration for all agents to 0.2429\n",
      "\n",
      "Episode 253: Starting computation.\n",
      "Random Seed Set to 353\n",
      "Episode 253: Finished running.\n",
      "Agent 0, Average Reward: -2073.88\n",
      "1/1 - 0s - loss: 5897.2681\n",
      "1/1 - 0s - loss: 3822.1328\n",
      "1/1 - 0s - loss: 2878.0085\n",
      "1/1 - 0s - loss: 2529.2380\n",
      "1/1 - 0s - loss: 3107.6296\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 - 0s - loss: 4927.5278\n",
      "1/1 - 0s - loss: 2442.2803\n",
      "1/1 - 0s - loss: 3514.4558\n",
      "1/1 - 0s - loss: 3326.8418\n",
      "1/1 - 0s - loss: 3371.2847\n",
      "Reducing exploration for all agents to 0.2399\n",
      "\n",
      "Episode 254: Starting computation.\n",
      "Random Seed Set to 354\n",
      "Episode 254: Finished running.\n",
      "Agent 0, Average Reward: -1556.48\n",
      "1/1 - 0s - loss: 4259.3320\n",
      "1/1 - 0s - loss: 6170.5522\n",
      "1/1 - 0s - loss: 3544.3728\n",
      "1/1 - 0s - loss: 3277.1931\n",
      "1/1 - 0s - loss: 2402.2095\n",
      "1/1 - 0s - loss: 3479.3142\n",
      "1/1 - 0s - loss: 6303.5371\n",
      "1/1 - 0s - loss: 2911.2297\n",
      "1/1 - 0s - loss: 2990.7603\n",
      "1/1 - 0s - loss: 2802.6831\n",
      "Reducing exploration for all agents to 0.2369\n",
      "\n",
      "Episode 255: Starting computation.\n",
      "Random Seed Set to 355\n",
      "Episode 255: Finished running.\n",
      "Agent 0, Average Reward: -1580.38\n",
      "1/1 - 0s - loss: 2431.5173\n",
      "1/1 - 0s - loss: 3315.9172\n",
      "1/1 - 0s - loss: 3557.7598\n",
      "1/1 - 0s - loss: 3122.0835\n",
      "1/1 - 0s - loss: 3458.8159\n",
      "1/1 - 0s - loss: 3378.0811\n",
      "1/1 - 0s - loss: 7424.2729\n",
      "1/1 - 0s - loss: 2679.4521\n",
      "1/1 - 0s - loss: 4893.5376\n",
      "1/1 - 0s - loss: 3761.6948\n",
      "Reducing exploration for all agents to 0.2338\n",
      "\n",
      "Episode 256: Starting computation.\n",
      "Random Seed Set to 356\n",
      "Episode 256: Finished running.\n",
      "Agent 0, Average Reward: -1703.67\n",
      "1/1 - 0s - loss: 2694.3550\n",
      "1/1 - 0s - loss: 2655.5696\n",
      "1/1 - 0s - loss: 3096.6289\n",
      "1/1 - 0s - loss: 1615.8433\n",
      "1/1 - 0s - loss: 2663.0469\n",
      "1/1 - 0s - loss: 3265.7412\n",
      "1/1 - 0s - loss: 5911.0801\n",
      "1/1 - 0s - loss: 3165.3525\n",
      "1/1 - 0s - loss: 4686.6470\n",
      "1/1 - 0s - loss: 3460.2900\n",
      "Reducing exploration for all agents to 0.2308\n",
      "\n",
      "Episode 257: Starting computation.\n",
      "Random Seed Set to 357\n",
      "Episode 257: Finished running.\n",
      "Agent 0, Average Reward: -1666.24\n",
      "1/1 - 0s - loss: 3702.4971\n",
      "1/1 - 0s - loss: 2864.6909\n",
      "1/1 - 0s - loss: 3065.7969\n",
      "1/1 - 0s - loss: 3230.6011\n",
      "1/1 - 0s - loss: 2130.1133\n",
      "1/1 - 0s - loss: 2733.1238\n",
      "1/1 - 0s - loss: 1983.1945\n",
      "1/1 - 0s - loss: 2138.9771\n",
      "1/1 - 0s - loss: 2872.0071\n",
      "1/1 - 0s - loss: 2611.8459\n",
      "Reducing exploration for all agents to 0.2278\n",
      "\n",
      "Episode 258: Starting computation.\n",
      "Random Seed Set to 358\n",
      "Episode 258: Finished running.\n",
      "Agent 0, Average Reward: -1976.09\n",
      "1/1 - 0s - loss: 3083.1616\n",
      "1/1 - 0s - loss: 3318.9570\n",
      "1/1 - 0s - loss: 2531.2585\n",
      "1/1 - 0s - loss: 4324.8408\n",
      "1/1 - 0s - loss: 2995.5657\n",
      "1/1 - 0s - loss: 3105.9863\n",
      "1/1 - 0s - loss: 3631.5217\n",
      "1/1 - 0s - loss: 3199.0771\n",
      "1/1 - 0s - loss: 4440.5508\n",
      "1/1 - 0s - loss: 6132.7544\n",
      "Reducing exploration for all agents to 0.2248\n",
      "\n",
      "Episode 259: Starting computation.\n",
      "Random Seed Set to 359\n",
      "Episode 259: Finished running.\n",
      "Agent 0, Average Reward: -1946.23\n",
      "1/1 - 0s - loss: 2866.8269\n",
      "1/1 - 0s - loss: 7104.5156\n",
      "1/1 - 0s - loss: 5601.1431\n",
      "1/1 - 0s - loss: 2351.3242\n",
      "1/1 - 0s - loss: 2629.1541\n",
      "1/1 - 0s - loss: 3464.8230\n",
      "1/1 - 0s - loss: 3022.3911\n",
      "1/1 - 0s - loss: 2343.0059\n",
      "1/1 - 0s - loss: 2876.2769\n",
      "1/1 - 0s - loss: 3377.1873\n",
      "Reducing exploration for all agents to 0.2218\n",
      "\n",
      "Episode 260: Starting computation.\n",
      "Random Seed Set to 360\n",
      "Episode 260: Finished running.\n",
      "Agent 0, Average Reward: -1961.2\n",
      "1/1 - 0s - loss: 5126.6270\n",
      "1/1 - 0s - loss: 2832.0645\n",
      "1/1 - 0s - loss: 3216.7603\n",
      "1/1 - 0s - loss: 2474.9626\n",
      "1/1 - 0s - loss: 2948.3057\n",
      "1/1 - 0s - loss: 2147.0359\n",
      "1/1 - 0s - loss: 2632.2490\n",
      "1/1 - 0s - loss: 3011.6609\n",
      "1/1 - 0s - loss: 2716.8799\n",
      "1/1 - 0s - loss: 3207.0078\n",
      "Weights succesfully copied to Target model for Agent 0.\n",
      "Saving architecture, weights and optimizer state for agent-0\n",
      "Dumping agent-0 memory into pickle file\n",
      "Dumping Training Results into pickle file.\n",
      "Dumping Loss Results into pickle file.\n",
      "Reducing exploration for all agents to 0.2188\n",
      "\n",
      "Episode 261: Starting computation.\n",
      "Random Seed Set to 361\n",
      "Episode 261: Finished running.\n",
      "Agent 0, Average Reward: -1797.18\n",
      "1/1 - 0s - loss: 44623.1094\n",
      "1/1 - 0s - loss: 23761.8945\n",
      "1/1 - 0s - loss: 42183.0625\n",
      "1/1 - 0s - loss: 10974.6875\n",
      "1/1 - 0s - loss: 50153.9609\n",
      "1/1 - 0s - loss: 2817.5466\n",
      "1/1 - 0s - loss: 38696.3867\n",
      "1/1 - 0s - loss: 8940.8457\n",
      "1/1 - 0s - loss: 26342.7188\n",
      "1/1 - 0s - loss: 22682.5293\n",
      "Reducing exploration for all agents to 0.2158\n",
      "\n",
      "Episode 262: Starting computation.\n",
      "Random Seed Set to 362\n",
      "Episode 262: Finished running.\n",
      "Agent 0, Average Reward: -1852.27\n",
      "1/1 - 0s - loss: 8354.0791\n",
      "1/1 - 0s - loss: 28298.0176\n",
      "1/1 - 0s - loss: 3624.6313\n",
      "1/1 - 0s - loss: 23142.7070\n",
      "1/1 - 0s - loss: 13929.3711\n",
      "1/1 - 0s - loss: 8402.2451\n",
      "1/1 - 0s - loss: 18128.9141\n",
      "1/1 - 0s - loss: 3867.5469\n",
      "1/1 - 0s - loss: 13574.2744\n",
      "1/1 - 0s - loss: 11505.9648\n",
      "Reducing exploration for all agents to 0.2128\n",
      "\n",
      "Episode 263: Starting computation.\n",
      "Random Seed Set to 363\n",
      "Episode 263: Finished running.\n",
      "Agent 0, Average Reward: -1778.93\n",
      "1/1 - 0s - loss: 4027.1118\n",
      "1/1 - 0s - loss: 14938.2920\n",
      "1/1 - 0s - loss: 3463.4915\n",
      "1/1 - 0s - loss: 9960.1006\n",
      "1/1 - 0s - loss: 7443.0771\n",
      "1/1 - 0s - loss: 3335.4607\n",
      "1/1 - 0s - loss: 9267.6084\n",
      "1/1 - 0s - loss: 3881.5164\n",
      "1/1 - 0s - loss: 6092.0557\n",
      "1/1 - 0s - loss: 7682.9814\n",
      "Reducing exploration for all agents to 0.2098\n",
      "\n",
      "Episode 264: Starting computation.\n",
      "Random Seed Set to 364\n",
      "Episode 264: Finished running.\n",
      "Agent 0, Average Reward: -2063.2\n",
      "1/1 - 0s - loss: 4168.8252\n",
      "1/1 - 0s - loss: 6126.8682\n",
      "1/1 - 0s - loss: 5703.5874\n",
      "1/1 - 0s - loss: 3668.8027\n",
      "1/1 - 0s - loss: 6055.8188\n",
      "1/1 - 0s - loss: 2712.8716\n",
      "1/1 - 0s - loss: 5239.1787\n",
      "1/1 - 0s - loss: 3278.0476\n",
      "1/1 - 0s - loss: 5956.4741\n",
      "1/1 - 0s - loss: 3646.0256\n",
      "Reducing exploration for all agents to 0.2068\n",
      "\n",
      "Episode 265: Starting computation.\n",
      "Random Seed Set to 365\n",
      "Episode 265: Finished running.\n",
      "Agent 0, Average Reward: -1976.38\n",
      "1/1 - 0s - loss: 3507.2532\n",
      "1/1 - 0s - loss: 3574.8010\n",
      "1/1 - 0s - loss: 4565.9448\n",
      "1/1 - 0s - loss: 3152.3284\n",
      "1/1 - 0s - loss: 4073.2539\n",
      "1/1 - 0s - loss: 2898.1426\n",
      "1/1 - 0s - loss: 3339.0225\n",
      "1/1 - 0s - loss: 2582.6802\n",
      "1/1 - 0s - loss: 1968.0885\n",
      "1/1 - 0s - loss: 3593.7078\n",
      "Reducing exploration for all agents to 0.2038\n",
      "\n",
      "Episode 266: Starting computation.\n",
      "Random Seed Set to 366\n",
      "Episode 266: Finished running.\n",
      "Agent 0, Average Reward: -1912.84\n",
      "1/1 - 0s - loss: 2762.9377\n",
      "1/1 - 0s - loss: 4385.3911\n",
      "1/1 - 0s - loss: 4698.1128\n",
      "1/1 - 0s - loss: 2851.5720\n",
      "1/1 - 0s - loss: 3426.4712\n",
      "1/1 - 0s - loss: 6006.4336\n",
      "1/1 - 0s - loss: 3461.7021\n",
      "1/1 - 0s - loss: 3464.5923\n",
      "1/1 - 0s - loss: 3475.0059\n",
      "1/1 - 0s - loss: 4501.9409\n",
      "Reducing exploration for all agents to 0.2008\n",
      "\n",
      "Episode 267: Starting computation.\n",
      "Random Seed Set to 367\n",
      "Episode 267: Finished running.\n",
      "Agent 0, Average Reward: -1965.91\n",
      "1/1 - 0s - loss: 2941.0903\n",
      "1/1 - 0s - loss: 3532.0798\n",
      "1/1 - 0s - loss: 2649.3677\n",
      "1/1 - 0s - loss: 3333.0193\n",
      "1/1 - 0s - loss: 3011.4487\n",
      "1/1 - 0s - loss: 3429.7690\n",
      "1/1 - 0s - loss: 2983.7788\n",
      "1/1 - 0s - loss: 3051.6250\n",
      "1/1 - 0s - loss: 3097.6267\n",
      "1/1 - 0s - loss: 3259.0317\n",
      "Reducing exploration for all agents to 0.1978\n",
      "\n",
      "Episode 268: Starting computation.\n",
      "Random Seed Set to 368\n",
      "Episode 268: Finished running.\n",
      "Agent 0, Average Reward: -1802.01\n",
      "1/1 - 0s - loss: 2608.8101\n",
      "1/1 - 0s - loss: 3724.5591\n",
      "1/1 - 0s - loss: 3104.9390\n",
      "1/1 - 0s - loss: 4750.9663\n",
      "1/1 - 0s - loss: 5315.7847\n",
      "1/1 - 0s - loss: 3574.7927\n",
      "1/1 - 0s - loss: 3230.7209\n",
      "1/1 - 0s - loss: 4427.6470\n",
      "1/1 - 0s - loss: 3996.0056\n",
      "1/1 - 0s - loss: 5860.5474\n",
      "Reducing exploration for all agents to 0.1948\n",
      "\n",
      "Episode 269: Starting computation.\n",
      "Random Seed Set to 369\n",
      "Episode 269: Finished running.\n",
      "Agent 0, Average Reward: -1917.04\n",
      "1/1 - 0s - loss: 3979.0063\n",
      "1/1 - 0s - loss: 8074.2524\n",
      "1/1 - 0s - loss: 3378.0715\n",
      "1/1 - 0s - loss: 3114.7988\n",
      "1/1 - 0s - loss: 2651.8938\n",
      "1/1 - 0s - loss: 3047.1528\n",
      "1/1 - 0s - loss: 2585.3438\n",
      "1/1 - 0s - loss: 5484.7920\n",
      "1/1 - 0s - loss: 3110.6589\n",
      "1/1 - 0s - loss: 3429.1746\n",
      "Reducing exploration for all agents to 0.1918\n",
      "\n",
      "Episode 270: Starting computation.\n",
      "Random Seed Set to 370\n",
      "Episode 270: Finished running.\n",
      "Agent 0, Average Reward: -1893.84\n",
      "1/1 - 0s - loss: 4832.9023\n",
      "1/1 - 0s - loss: 3411.8618\n",
      "1/1 - 0s - loss: 4391.8354\n",
      "1/1 - 0s - loss: 3037.5042\n",
      "1/1 - 0s - loss: 4714.0469\n",
      "1/1 - 0s - loss: 4025.7593\n",
      "1/1 - 0s - loss: 2768.7229\n",
      "1/1 - 0s - loss: 2436.1365\n",
      "1/1 - 0s - loss: 2631.4917\n",
      "1/1 - 0s - loss: 2267.8481\n",
      "Reducing exploration for all agents to 0.1888\n",
      "\n",
      "Episode 271: Starting computation.\n",
      "Random Seed Set to 371\n",
      "Episode 271: Finished running.\n",
      "Agent 0, Average Reward: -1979.9\n",
      "1/1 - 0s - loss: 3468.5811\n",
      "1/1 - 0s - loss: 6011.1851\n",
      "1/1 - 0s - loss: 2513.2324\n",
      "1/1 - 0s - loss: 4358.6392\n",
      "1/1 - 0s - loss: 2890.6628\n",
      "1/1 - 0s - loss: 3644.3865\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 - 0s - loss: 2472.3154\n",
      "1/1 - 0s - loss: 2795.6868\n",
      "1/1 - 0s - loss: 3781.5283\n",
      "1/1 - 0s - loss: 3353.4792\n",
      "Reducing exploration for all agents to 0.1858\n",
      "\n",
      "Episode 272: Starting computation.\n",
      "Random Seed Set to 372\n",
      "Episode 272: Finished running.\n",
      "Agent 0, Average Reward: -1891.35\n",
      "1/1 - 0s - loss: 4457.1455\n",
      "1/1 - 0s - loss: 2666.9436\n",
      "1/1 - 0s - loss: 3122.6040\n",
      "1/1 - 0s - loss: 3255.7910\n",
      "1/1 - 0s - loss: 3230.3926\n",
      "1/1 - 0s - loss: 3516.7400\n",
      "1/1 - 0s - loss: 6382.0649\n",
      "1/1 - 0s - loss: 1950.6274\n",
      "1/1 - 0s - loss: 2295.5339\n",
      "1/1 - 0s - loss: 3734.9573\n",
      "Reducing exploration for all agents to 0.1828\n",
      "\n",
      "Episode 273: Starting computation.\n",
      "Random Seed Set to 373\n",
      "Episode 273: Finished running.\n",
      "Agent 0, Average Reward: -1890.44\n",
      "1/1 - 0s - loss: 2498.2354\n",
      "1/1 - 0s - loss: 1879.3788\n",
      "1/1 - 0s - loss: 2623.3420\n",
      "1/1 - 0s - loss: 4608.1318\n",
      "1/1 - 0s - loss: 3366.8696\n",
      "1/1 - 0s - loss: 3169.6997\n",
      "1/1 - 0s - loss: 2672.0635\n",
      "1/1 - 0s - loss: 2852.0630\n",
      "1/1 - 0s - loss: 3665.4631\n",
      "1/1 - 0s - loss: 3250.4509\n",
      "Reducing exploration for all agents to 0.1798\n",
      "\n",
      "Episode 274: Starting computation.\n",
      "Random Seed Set to 374\n",
      "Episode 274: Finished running.\n",
      "Agent 0, Average Reward: -1960.52\n",
      "1/1 - 0s - loss: 5863.2925\n",
      "1/1 - 0s - loss: 3941.5266\n",
      "1/1 - 0s - loss: 2957.9680\n",
      "1/1 - 0s - loss: 3351.6929\n",
      "1/1 - 0s - loss: 2971.0388\n",
      "1/1 - 0s - loss: 3054.2515\n",
      "1/1 - 0s - loss: 2866.7197\n",
      "1/1 - 0s - loss: 3205.7222\n",
      "1/1 - 0s - loss: 2691.2271\n",
      "1/1 - 0s - loss: 2440.0596\n",
      "Reducing exploration for all agents to 0.1768\n",
      "\n",
      "Episode 275: Starting computation.\n",
      "Random Seed Set to 375\n",
      "Episode 275: Finished running.\n",
      "Agent 0, Average Reward: -1777.97\n",
      "1/1 - 0s - loss: 2798.2634\n",
      "1/1 - 0s - loss: 2886.2134\n",
      "1/1 - 0s - loss: 2466.5479\n",
      "1/1 - 0s - loss: 3027.7332\n",
      "1/1 - 0s - loss: 2724.7551\n",
      "1/1 - 0s - loss: 5894.1890\n",
      "1/1 - 0s - loss: 2035.1115\n",
      "1/1 - 0s - loss: 5519.8672\n",
      "1/1 - 0s - loss: 3198.1265\n",
      "1/1 - 0s - loss: 2283.8987\n",
      "Reducing exploration for all agents to 0.1738\n",
      "\n",
      "Episode 276: Starting computation.\n",
      "Random Seed Set to 376\n",
      "Episode 276: Finished running.\n",
      "Agent 0, Average Reward: -2135.62\n",
      "1/1 - 0s - loss: 3494.5125\n",
      "1/1 - 0s - loss: 2552.5913\n",
      "1/1 - 0s - loss: 3219.7351\n",
      "1/1 - 0s - loss: 2586.6182\n",
      "1/1 - 0s - loss: 2803.8860\n",
      "1/1 - 0s - loss: 2943.8652\n",
      "1/1 - 0s - loss: 3499.2180\n",
      "1/1 - 0s - loss: 3874.2739\n",
      "1/1 - 0s - loss: 3139.3250\n",
      "1/1 - 0s - loss: 3822.3274\n",
      "Reducing exploration for all agents to 0.1708\n",
      "\n",
      "Episode 277: Starting computation.\n",
      "Random Seed Set to 377\n",
      "Episode 277: Finished running.\n",
      "Agent 0, Average Reward: -1912.11\n",
      "1/1 - 0s - loss: 2925.5825\n",
      "1/1 - 0s - loss: 2618.0957\n",
      "1/1 - 0s - loss: 2613.9307\n",
      "1/1 - 0s - loss: 2544.7734\n",
      "1/1 - 0s - loss: 3892.2222\n",
      "1/1 - 0s - loss: 2051.1863\n",
      "1/1 - 0s - loss: 2518.0378\n",
      "1/1 - 0s - loss: 2310.7688\n",
      "1/1 - 0s - loss: 3888.1216\n",
      "1/1 - 0s - loss: 2365.9250\n",
      "Reducing exploration for all agents to 0.1678\n",
      "\n",
      "Episode 278: Starting computation.\n",
      "Random Seed Set to 378\n",
      "Episode 278: Finished running.\n",
      "Agent 0, Average Reward: -1993.89\n",
      "1/1 - 0s - loss: 3385.4734\n",
      "1/1 - 0s - loss: 2265.8086\n",
      "1/1 - 0s - loss: 2722.0261\n",
      "1/1 - 0s - loss: 2578.6375\n",
      "1/1 - 0s - loss: 3137.8757\n",
      "1/1 - 0s - loss: 2059.5276\n",
      "1/1 - 0s - loss: 3059.8123\n",
      "1/1 - 0s - loss: 2487.8789\n",
      "1/1 - 0s - loss: 3204.7917\n",
      "1/1 - 0s - loss: 2231.8682\n",
      "Reducing exploration for all agents to 0.1647\n",
      "\n",
      "Episode 279: Starting computation.\n",
      "Random Seed Set to 379\n",
      "Episode 279: Finished running.\n",
      "Agent 0, Average Reward: -1968.26\n",
      "1/1 - 0s - loss: 2734.4150\n",
      "1/1 - 0s - loss: 2953.8296\n",
      "1/1 - 0s - loss: 2682.7820\n",
      "1/1 - 0s - loss: 2131.0630\n",
      "1/1 - 0s - loss: 2150.9434\n",
      "1/1 - 0s - loss: 2099.9915\n",
      "1/1 - 0s - loss: 3516.7959\n",
      "1/1 - 0s - loss: 2389.0454\n",
      "1/1 - 0s - loss: 2615.3306\n",
      "1/1 - 0s - loss: 2145.8315\n",
      "Reducing exploration for all agents to 0.1617\n",
      "\n",
      "Episode 280: Starting computation.\n",
      "Random Seed Set to 380\n",
      "Episode 280: Finished running.\n",
      "Agent 0, Average Reward: -1974.93\n",
      "1/1 - 0s - loss: 2395.4197\n",
      "1/1 - 0s - loss: 3643.5557\n",
      "1/1 - 0s - loss: 2973.9736\n",
      "1/1 - 0s - loss: 3621.1299\n",
      "1/1 - 0s - loss: 3699.9541\n",
      "1/1 - 0s - loss: 2950.6924\n",
      "1/1 - 0s - loss: 2283.8787\n",
      "1/1 - 0s - loss: 2174.5295\n",
      "1/1 - 0s - loss: 2581.7546\n",
      "1/1 - 0s - loss: 2549.1543\n",
      "Weights succesfully copied to Target model for Agent 0.\n",
      "Saving architecture, weights and optimizer state for agent-0\n",
      "Dumping agent-0 memory into pickle file\n",
      "Dumping Training Results into pickle file.\n",
      "Dumping Loss Results into pickle file.\n",
      "Reducing exploration for all agents to 0.1587\n",
      "\n",
      "Episode 281: Starting computation.\n",
      "Random Seed Set to 381\n",
      "Episode 281: Finished running.\n",
      "Agent 0, Average Reward: -1819.99\n",
      "1/1 - 0s - loss: 40238.5117\n",
      "1/1 - 0s - loss: 15685.3320\n",
      "1/1 - 0s - loss: 46979.4258\n",
      "1/1 - 0s - loss: 8898.3096\n",
      "1/1 - 0s - loss: 41701.4961\n",
      "1/1 - 0s - loss: 3535.9138\n",
      "1/1 - 0s - loss: 33295.5898\n",
      "1/1 - 0s - loss: 8750.9277\n",
      "1/1 - 0s - loss: 19059.3770\n",
      "1/1 - 0s - loss: 18715.6992\n",
      "Reducing exploration for all agents to 0.1557\n",
      "\n",
      "Episode 282: Starting computation.\n",
      "Random Seed Set to 382\n",
      "Episode 282: Finished running.\n",
      "Agent 0, Average Reward: -2178.2\n",
      "1/1 - 0s - loss: 6869.2036\n",
      "1/1 - 0s - loss: 21825.8672\n",
      "1/1 - 0s - loss: 2398.3569\n",
      "1/1 - 0s - loss: 23237.5645\n",
      "1/1 - 0s - loss: 4841.3882\n",
      "1/1 - 0s - loss: 11514.6211\n",
      "1/1 - 0s - loss: 14163.8018\n",
      "1/1 - 0s - loss: 4392.4878\n",
      "1/1 - 0s - loss: 14551.4316\n",
      "1/1 - 0s - loss: 5166.1196\n",
      "Reducing exploration for all agents to 0.1527\n",
      "\n",
      "Episode 283: Starting computation.\n",
      "Random Seed Set to 383\n",
      "Episode 283: Finished running.\n",
      "Agent 0, Average Reward: -2219.41\n",
      "1/1 - 0s - loss: 9600.6338\n",
      "1/1 - 0s - loss: 7808.7383\n",
      "1/1 - 0s - loss: 3692.7043\n",
      "1/1 - 0s - loss: 10768.7686\n",
      "1/1 - 0s - loss: 4210.4580\n",
      "1/1 - 0s - loss: 8853.9473\n",
      "1/1 - 0s - loss: 5600.5820\n",
      "1/1 - 0s - loss: 4668.1396\n",
      "1/1 - 0s - loss: 6579.1104\n",
      "1/1 - 0s - loss: 4390.5210\n",
      "Reducing exploration for all agents to 0.1497\n",
      "\n",
      "Episode 284: Starting computation.\n",
      "Random Seed Set to 384\n",
      "Episode 284: Finished running.\n",
      "Agent 0, Average Reward: -2043.31\n",
      "1/1 - 0s - loss: 4974.8691\n",
      "1/1 - 0s - loss: 2904.9712\n",
      "1/1 - 0s - loss: 3889.8643\n",
      "1/1 - 0s - loss: 3197.9812\n",
      "1/1 - 0s - loss: 5670.4814\n",
      "1/1 - 0s - loss: 2855.6228\n",
      "1/1 - 0s - loss: 4331.8037\n",
      "1/1 - 0s - loss: 3169.5186\n",
      "1/1 - 0s - loss: 4896.3647\n",
      "1/1 - 0s - loss: 4669.6201\n",
      "Reducing exploration for all agents to 0.1467\n",
      "\n",
      "Episode 285: Starting computation.\n",
      "Random Seed Set to 385\n",
      "Episode 285: Finished running.\n",
      "Agent 0, Average Reward: -2008.7\n",
      "1/1 - 0s - loss: 3727.4751\n",
      "1/1 - 0s - loss: 4197.3945\n",
      "1/1 - 0s - loss: 2805.8977\n",
      "1/1 - 0s - loss: 2565.4080\n",
      "1/1 - 0s - loss: 5392.0464\n",
      "1/1 - 0s - loss: 3198.0396\n",
      "1/1 - 0s - loss: 1865.0938\n",
      "1/1 - 0s - loss: 3168.6641\n",
      "1/1 - 0s - loss: 2732.7144\n",
      "1/1 - 0s - loss: 3075.4294\n",
      "Reducing exploration for all agents to 0.1437\n",
      "\n",
      "Episode 286: Starting computation.\n"
     ]
    },
    {
     "ename": "com_error",
     "evalue": "(-2147352567, 'Exception occurred.', (0, None, None, None, 0, -2147467259), None)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mcom_error\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-41-da8ead60966a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mSingle_Cross_Triple8_MultiDQN_Agents\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepisodes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Desktop\\15_Timescales_utc\\Timescales_and_Discount_Factor_in_UTC\\MasterDQN_Agent.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, number_of_episode)\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\15_Timescales_utc\\Timescales_and_Discount_Factor_in_UTC\\Vissim_env_class.py\u001b[0m in \u001b[0;36mstep_to_next_action\u001b[1;34m(self, actions)\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\15_Timescales_utc\\Timescales_and_Discount_Factor_in_UTC\\Vissim_env_class.py\u001b[0m in \u001b[0;36mstep\u001b[1;34m(self, actions, green_time)\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\vissim\\lib\\site-packages\\win32com\\client\\dynamic.py\u001b[0m in \u001b[0;36mRunSingleStep\u001b[1;34m(self)\u001b[0m\n",
      "\u001b[1;31mcom_error\u001b[0m: (-2147352567, 'Exception occurred.', (0, None, None, None, 0, -2147467259), None)"
     ]
    }
   ],
   "source": [
    "Single_Cross_Triple8_MultiDQN_Agents.train(episodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working Directory set to: C:\\Users\\acabrejasegea\\Desktop\\15_Timescales_utc\\Timescales_and_Discount_Factor_in_UTC\n",
      "Generating Cache...\n",
      "Cache generated.\n",
      "\n",
      "****************************\n",
      "*   COM Server dispatched  *\n",
      "****************************\n",
      "\n",
      "Attempting to load Model File: Single_Cross_Triple.inpx ...\n",
      "Model File load process successful.\n",
      "Simulation length set to 3601 seconds.\n",
      "Results from Previous Simulations: Deleted. Fresh Start Available.\n",
      "Fetched and containerized Network Object \n",
      "\n",
      "*******************************************************\n",
      "*                                                     *\n",
      "*                COM SETUP COMPLETE                   *\n",
      "*                                                     *\n",
      "*******************************************************\n",
      "\n",
      "Random seed set in simulator. Random Seed = 945\n",
      "Deploying Network Parser...\n",
      "Successful Network Crawl: Identified SignalControllers, Links, Lanes and Vehicle Inputs.\n",
      "\n",
      "Setting Simulation mode to: demo\n",
      "Starting Deployments of Signal Control Units...\n",
      "SCUs successfully deployed. Elapsed time 3.03 seconds.\n",
      "\n"
     ]
    },
    {
     "ename": "com_error",
     "evalue": "(-2147352567, 'Exception occurred.', (0, None, None, None, 0, -2147467259), None)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mcom_error\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-d9255ff0a2ac>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mSingle_Cross_Triple8_MultiDQN_Agents\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdemo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Desktop\\15_Timescales_utc\\Timescales_and_Discount_Factor_in_UTC\\MasterDQN_Agent.py\u001b[0m in \u001b[0;36mdemo\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    251\u001b[0m                 \u001b[1;32mwhile\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdone\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    252\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 253\u001b[1;33m                         \u001b[0mSARSDs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mactions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    254\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    255\u001b[0m                         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maction_required\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\15_Timescales_utc\\Timescales_and_Discount_Factor_in_UTC\\Vissim_env_class.py\u001b[0m in \u001b[0;36mstep\u001b[1;34m(self, actions, green_time)\u001b[0m\n\u001b[0;32m    207\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    208\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtimesteps_per_second\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 209\u001b[1;33m                         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mVissim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSimulation\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mRunSingleStep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    210\u001b[0m                 \u001b[1;31m# increase the update counter by one each step (until reach simulation length)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    211\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mglobal_counter\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\vissim\\lib\\site-packages\\win32com\\client\\dynamic.py\u001b[0m in \u001b[0;36mRunSingleStep\u001b[1;34m(self)\u001b[0m\n",
      "\u001b[1;31mcom_error\u001b[0m: (-2147352567, 'Exception occurred.', (0, None, None, None, 0, -2147467259), None)"
     ]
    }
   ],
   "source": [
    "Single_Cross_Triple8_MultiDQN_Agents.demo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "filename = os.path.join(vissim_working_directory, model_name, \"Agents_Results\", agent_type, Session_ID) + \"\\\\memoryD3QN.pkl\"\n",
    "memory = Single_Cross_Triple8_MultiDQN_Agents.Agents[0].memory2\n",
    "pickle.dump(memory, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## AGENT TRAINING RESULTS\n",
    "# Path to results folder\n",
    "results_path = os.path.join(vissim_working_directory, model_name, \"Agents_Results\", agent_type, Session_ID)\n",
    "\n",
    "# Loop over each agent\n",
    "for idx , agent in Single_Cross_Triple8_MultiDQN_Agents.Agents.items():\n",
    "    intersection_number_in_vissim = Single_Cross_Triple8_MultiDQN_Agents.Agents[0].signal_id + 1\n",
    "    print(\"Intersection \"+str(intersection_number_in_vissim))\n",
    "    \n",
    "    ## SAVE TRAINING DATA TO JSON.\n",
    "    json_filename = \"Agent{}_Loss_average_reward.json\".format(intersection_number_in_vissim)\n",
    "    Loss_reward = dict()   \n",
    "    # Loss dictionary\n",
    "    for epoch, loss in enumerate(agent.loss):\n",
    "        loss_dict = { epoch : loss }\n",
    "    Loss_reward['Agent{} loss'.format(intersection_number_in_vissim)] = loss_dict\n",
    "    # Reward dictionary            \n",
    "    episode = [i for i in range(len(agent.reward_storage))]\n",
    "    Loss_reward['Agent{} Average_Reward'.format(intersection_number_in_vissim)] = agent.reward_storage\n",
    "    # Store as JSON\n",
    "    with open(results_path + \"/\" + json_filename, 'w') as f:\n",
    "        json.dump(Loss_reward, f)\n",
    "    print(\"Agent {}: Training Loss and Average Reward during training successfuly saved to file:\".format(intersection_number_in_vissim))\n",
    "    print(results_path + \"/\" + json_filename)\n",
    "    \n",
    "    ## LOADING DATA FROM JSON\n",
    "    #results_path = os.path.join(vissim_working_directory, model_name, \"Agents_Results\", agent_type, Session_ID)\n",
    "    #dictionary_filename = \"Agent{}_Loss_average_reward.json\".format(intersection_number_in_vissim)\n",
    "    #with open(results_path + \"/\" + json_filename, 'r') as fp:\n",
    "    #    data = json.load(fp)\n",
    "    #print(data)\n",
    "    \n",
    "    ## TRAINING PLOTS\n",
    "    loss_plot_filename  = \"Agent{}_Loss.png\".format(intersection_number_in_vissim)\n",
    "    reward_plot_filename  = \"Agent{}_average_reward.png\".format(intersection_number_in_vissim) \n",
    "    \n",
    "    ## Loss Plot\n",
    "    plt.figure('LossAgent'+str(idx),figsize=(16,9))\n",
    "    plt.plot(agent.loss)\n",
    "    #plt.yscale('log')\n",
    "\n",
    "    plt.xlabel('Training Epoch',fontsize=18)\n",
    "    plt.ylabel('Loss',fontsize=18)\n",
    "    plt.title('Agent {} Loss over training'.format(intersection_number_in_vissim),fontsize=18)\n",
    "    plt.savefig(results_path + \"/\" + loss_plot_filename)\n",
    "\n",
    "    ## Average Reward Plot\n",
    "    plt.figure('RewardAgent'+str(idx),figsize=(16,9))\n",
    "    plt.plot(agent.reward_storage)\n",
    "    plt.xlabel('Training Episode',fontsize=18)\n",
    "    plt.ylabel('Average reward',fontsize=18)\n",
    "    plt.title('Agent {} average reward over training'.format(intersection_number_in_vissim),fontsize=18)\n",
    "    plt.savefig(results_path + \"/\" + reward_plot_filename)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Single_Cross_Triple8_MultiDQN_Agents.save(401)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Single_Cross_Triple8_MultiDQN_Agents.load(400,best = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Single_Cross_Triple8_MultiDQN_Agents.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "time = [t for t in range(len(Single_Cross_Triple8_MultiDQN_Agents.Cumulative_Totale_network_stop_delay))]\n",
    "\n",
    "# Queues ovzer time for each junction\n",
    "for idx, queues in Single_Cross_Triple8_MultiDQN_Agents.Episode_Queues.items():\n",
    "    queues = np.array(queues)\n",
    "    queues = queues.T\n",
    "    \n",
    "    plt.figure('1'+str(idx),figsize=(16, 9))\n",
    "    \n",
    "    Queuesdf = pd.DataFrame()\n",
    "    \n",
    "    Queuesdf['Time'] = time\n",
    "    Queues_legend = []\n",
    "    \n",
    "    for i, queue in enumerate(queues):\n",
    "        plt.plot(queue, label = \"Queue\"+str(i))\n",
    "        Queuesdf[str(i)] = queue\n",
    "        Queues_legend.append(\"Queue\"+str(i))\n",
    "        \n",
    "    plt.xlabel('Time [s]',fontsize=18)\n",
    "    plt.ylabel('Queue Length',fontsize=18)\n",
    "    plt.title('Junction {} Queue length'.format(idx),fontsize=18)\n",
    "    #plt.gca().legend(Queues_legend)\n",
    "    \n",
    "    Path = os.path.join(vissim_working_directory, model_name, \"Agents_Results\", Session_ID,\\\n",
    "                        \"Junction{}_Queues.png\".format(idx))               \n",
    "    plt.savefig(Path)\n",
    "    \n",
    "    csv_Path = os.path.join(vissim_working_directory, model_name, \"Agents_Results\", Session_ID,\\\n",
    "                        \"Junction{}_Queues.csv\".format(idx))        \n",
    "   \n",
    "    Queuesdf.to_csv(csv_Path,index=False)\n",
    "    plt.legend()\n",
    "        \n",
    "        \n",
    "# Accumulated delay over time for each junction\n",
    "for idx, delay in Single_Cross_Triple8_MultiDQN_Agents.Cumulative_Episode_Delays.items():\n",
    "    \n",
    "    plt.figure('2'+str(idx),figsize=(16, 9))\n",
    "    \n",
    "    delaydf = pd.DataFrame()   \n",
    "    delaydf['Time'] = time\n",
    "    delaydf['Junction {} delay'.format(idx)] = delay\n",
    "    \n",
    "    plt.plot(delay)\n",
    "    plt.xlabel('Time [s]',fontsize=18)\n",
    "    plt.ylabel('Accumulated Delay',fontsize=18)\n",
    "    plt.title('Junction {} Delay'.format(idx),fontsize=18)\n",
    "    plt.gca().legend('Junction accumulated delay')\n",
    "    \n",
    "    Path = os.path.join(vissim_working_directory, model_name, \"Agents_Results\", Session_ID,\\\n",
    "                            \"Junction{}_Cumulative_Delay.png\".format(idx))\n",
    "    csv_Path = os.path.join(vissim_working_directory, model_name, \"Agents_Results\", Session_ID,\\\n",
    "                        \"Junction{}_Cumulative_Delay.csv\".format(idx))   \n",
    "    plt.savefig(Path)\n",
    "\n",
    "    delaydf.to_csv(csv_Path,index=False)\n",
    "    \n",
    "    \n",
    "# Accumulated stop delay over time for each junction\n",
    "for idx, stop_delay in Single_Cross_Triple8_MultiDQN_Agents.Cumulative_Episode_stop_Delays.items():\n",
    "    \n",
    "    plt.figure('3'+str(idx),figsize=(16, 9))\n",
    "    \n",
    "    stop_delaydf = pd.DataFrame()   \n",
    "    stop_delaydf['Time'] = time\n",
    "    stop_delaydf['Junction {} stop delay'.format(idx)] = stop_delay\n",
    "\n",
    "    plt.plot(stop_delay)\n",
    "    plt.xlabel('Time [s]',fontsize=18)\n",
    "    plt.ylabel('Accumulated Stop Delay',fontsize=18)\n",
    "    plt.title('Junction {} Stop Delay'.format(idx),fontsize=18)\n",
    "    plt.gca().legend('Junction accumulated Stop delay')\n",
    "    \n",
    "    Path = os.path.join(vissim_working_directory, model_name, \"Agents_Results\", Session_ID,\\\n",
    "                            \"Junction{}_Cumulative_stop_Delay.png\".format(idx))\n",
    "    csv_Path = os.path.join(vissim_working_directory, model_name, \"Agents_Results\", Session_ID,\\\n",
    "                        \"Junction{}_Cumulative_stop_Delay.csv\".format(idx))\n",
    "    plt.savefig(Path)\n",
    "    stop_delaydf.to_csv(csv_Path,index=False)\n",
    "    \n",
    "# Global Accumulated delay over time\n",
    "plt.figure('4',figsize=(16,9))\n",
    "\n",
    "\n",
    "Global_delaydf = pd.DataFrame()   \n",
    "Global_delaydf['Time'] = time\n",
    "Global_delaydf['Global accumulated Delay'] = Single_Cross_Triple8_MultiDQN_Agents.Cumulative_Totale_network_delay\n",
    "\n",
    "plt.plot(Single_Cross_Triple8_MultiDQN_Agents.Cumulative_Totale_network_delay)\n",
    "plt.xlabel('Time [s]',fontsize=18)\n",
    "plt.ylabel('Global accumulated Delay',fontsize=18)\n",
    "plt.title('Global accumulated Delay',fontsize=18)\n",
    "plt.gca().legend('Global accumulated delay')\n",
    "\n",
    "Path = os.path.join(vissim_working_directory, model_name, \"Agents_Results\", Session_ID,\\\n",
    "                        \"Total_Cumulative_Delay.png\")\n",
    "csv_Path = os.path.join(vissim_working_directory, model_name, \"Agents_Results\", Session_ID,\\\n",
    "                        \"Total_Cumulative_Delay.csv\")\n",
    "plt.savefig(Path)\n",
    "Global_delaydf.to_csv(csv_Path,index=False)\n",
    "\n",
    "# Global Accumulated stop delay over time\n",
    "plt.figure('5'+str(idx),figsize=(16, 9))\n",
    "\n",
    "Global_stop_delaydf = pd.DataFrame()   \n",
    "Global_stop_delaydf['Time'] = time\n",
    "Global_stop_delaydf['Global accumulated stop Delay'] = Single_Cross_Triple8_MultiDQN_Agents.Cumulative_Totale_network_stop_delay\n",
    "\n",
    "plt.plot(Single_Cross_Triple8_MultiDQN_Agents.Cumulative_Totale_network_stop_delay)\n",
    "plt.xlabel('Time [s]',fontsize=18)\n",
    "plt.ylabel('Global accumulated stop Delay',fontsize=18)\n",
    "plt.title('Global accumulated stop Delay',fontsize=18)\n",
    "plt.gca().legend('Global accumulated stop Delay')\n",
    "\n",
    "Path = os.path.join(vissim_working_directory, model_name, \"Agents_Results\", Session_ID,\\\n",
    "                        \"Total_Cumulative_stop_Delay.png\")\n",
    "csv_Path = os.path.join(vissim_working_directory, model_name, \"Agents_Results\", Session_ID,\\\n",
    "                        \"Total_Cumulative_stop_Delay.csv\")\n",
    "plt.savefig(Path)\n",
    "Global_stop_delaydf.to_csv(csv_Path,index=False)\n",
    "\n",
    "\n",
    "# For the agent training\n",
    "\n",
    "for idx , agent in Single_Cross_Triple8_MultiDQN_Agents.Agents.items():  \n",
    "    plt.figure('6'+str(idx),figsize=(16, 9))\n",
    "    \n",
    "    Loss_rewarddf = pd.DataFrame()   \n",
    "    \n",
    "    plt.plot(agent.loss)\n",
    "    plt.xlabel('Episode',fontsize=18)\n",
    "    plt.ylabel('Loss',fontsize=18)\n",
    "    plt.title('Agent{} Loss over training'.format(idx),fontsize=18)\n",
    "    plt.gca().legend('Agent Loss over training')\n",
    "    \n",
    "    Path  = os.path.join(vissim_working_directory, model_name, \"Agents_Results\", Session_ID,\\\n",
    "                        \"Agent{}_Loss.png\".format(idx)) \n",
    "    plt.savefig(Path)\n",
    "    \n",
    "    csv_Path = os.path.join(vissim_working_directory, model_name, \"Agents_Results\", Session_ID,\\\n",
    "                           \"Agent{}_Loss_average_reward.csv\".format(idx)) \n",
    "    \n",
    "    \n",
    "    plt.figure('7'+str(idx),figsize=(16, 9))\n",
    "    plt.plot(agent.reward_storage)\n",
    "    plt.xlabel('Episode',fontsize=18)\n",
    "    plt.ylabel('Average reward',fontsize=18)\n",
    "    plt.title('Agent{} average reward over training'.format(idx),fontsize=18)\n",
    "    plt.gca().legend('Agent reward over training')\n",
    "    \n",
    "    Path  = os.path.join(vissim_working_directory, model_name, \"Agents_Results\", Session_ID,\\\n",
    "                        \"Agent{}_average_reward.png\".format(idx)) \n",
    "    plt.savefig(Path)\n",
    "    \n",
    "    \n",
    "    episode = [i for i in range(len(agent.reward_storage))]\n",
    "    \n",
    "    Loss_rewarddf['episode'] = episode \n",
    "    Loss_rewarddf['Agent{} loss'.format(idx)] = agent.loss\n",
    "    Loss_rewarddf['Agent{} Average_Reward'.format(idx)] = agent.reward_storage\n",
    "    \n",
    "    Loss_rewarddf.to_csv(csv_Path,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Single_Cross_Triple8_MultiDQN_Agents.demo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Single_Cross_Triple8_MultiDQN_Agents.Episode_Queues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Five intersection DQN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name  = 'Five_intersection'\n",
    "#vissim_working_directory =  'C:\\\\Users\\\\Rzhang\\\\Desktop\\\\MLforFlowOptimisationOrigine\\\\Vissim\\\\'\n",
    "vissim_working_directory = 'C:\\\\Users\\\\acabrejasegea\\\\OneDrive - The Alan Turing Institute\\\\Desktop\\\\ATI\\\\0_TMF\\\\MLforFlowOptimisation\\\\Vissim\\\\'\n",
    "\n",
    "sim_length = 3601\n",
    "\n",
    "agent_type = \"DuelingDDQN\"\n",
    "Session_ID = \"Five5transfert\"\n",
    "\n",
    "# all controller actions\n",
    "Five_intersection_dictionary =\\\n",
    "{\\\n",
    "    # Controller Number 0 \n",
    "   'junctions' : {0 : {'default_actions' :  {    0 : [1,1,1,0,0,0,0,0,0,0,0,0],\n",
    "                                             1 : [0,0,0,1,1,1,0,0,0,0,0,0],\n",
    "                                             2 : [0,0,0,0,0,0,1,1,1,0,0,0],\n",
    "                                             3 : [0,0,0,0,0,0,0,0,0,1,1,1],\n",
    "                                             4 : [1,0,0,0,0,0,1,0,0,0,0,0],\n",
    "                                             5 : [0,0,0,1,0,0,0,0,0,1,0,0],\n",
    "                                             6 : [0,1,1,0,0,0,0,1,1,0,0,0],\n",
    "                                             7 : [0,0,0,0,1,1,0,0,0,0,1,1]},\n",
    "         \n",
    "         'all_actions' :        {            0 : [1,1,1,0,0,0,0,0,0,0,0,0],\n",
    "                                             1 : [0,0,0,1,1,1,0,0,0,0,0,0],\n",
    "                                             2 : [0,0,0,0,0,0,1,1,1,0,0,0],\n",
    "                                             3 : [0,0,0,0,0,0,0,0,0,1,1,1],\n",
    "                                             4 : [1,0,0,0,0,0,1,0,0,0,0,0],\n",
    "                                             5 : [0,0,0,1,0,0,0,0,0,1,0,0],\n",
    "                                             6 : [0,1,1,0,0,0,0,1,1,0,0,0],\n",
    "                                             7 : [0,0,0,0,1,1,0,0,0,0,1,1]},\n",
    " \n",
    "         'link' : [],\n",
    "         'lane' : ['11-1', '11-2', '11-3', '12-1', '12-2', '12-3', '13-1', '13-2', '13-3', '14-1', '14-2', '14-3'],\n",
    "         \n",
    "         'controled_by_com' : True,\n",
    "         'agent_type' : agent_type,\n",
    "         'green_time' : 6,\n",
    "         'redamber_time' : 0,\n",
    "         'amber_time' : 3, \n",
    "         'red_time' : 0,\n",
    "         'state_size' : [13],\n",
    "         'state_type' : 'QueuesSig',\n",
    "         'reward_type' : 'Queues',\n",
    "         'queues_counter_ID' : [1,2,3,4,5,6,7,8,9,10,11,12]\n",
    "         },\n",
    "                  1 : {'default_actions' :  {    0 : [1,1,1,0,0,0,0,0,0,0,0,0],\n",
    "                                             1 : [0,0,0,1,1,1,0,0,0,0,0,0],\n",
    "                                             2 : [0,0,0,0,0,0,1,1,1,0,0,0],\n",
    "                                             3 : [0,0,0,0,0,0,0,0,0,1,1,1],\n",
    "                                             4 : [1,0,0,0,0,0,1,0,0,0,0,0],\n",
    "                                             5 : [0,0,0,1,0,0,0,0,0,1,0,0],\n",
    "                                             6 : [0,1,1,0,0,0,0,1,1,0,0,0],\n",
    "                                             7 : [0,0,0,0,1,1,0,0,0,0,1,1]},\n",
    "         \n",
    "         'all_actions' :        {            0 : [1,1,1,0,0,0,0,0,0,0,0,0],\n",
    "                                             1 : [0,0,0,1,1,1,0,0,0,0,0,0],\n",
    "                                             2 : [0,0,0,0,0,0,1,1,1,0,0,0],\n",
    "                                             3 : [0,0,0,0,0,0,0,0,0,1,1,1],\n",
    "                                             4 : [1,0,0,0,0,0,1,0,0,0,0,0],\n",
    "                                             5 : [0,0,0,1,0,0,0,0,0,1,0,0],\n",
    "                                             6 : [0,1,1,0,0,0,0,1,1,0,0,0],\n",
    "                                             7 : [0,0,0,0,1,1,0,0,0,0,1,1]},\n",
    " \n",
    "         'link' : [],\n",
    "         'lane' : ['21-1', '21-2', '21-3', '22-1', '22-2', '22-3', '23-1', '23-2', '23-3', '24-1', '24-2', '24-3'],\n",
    "         \n",
    "         'controled_by_com' : True,\n",
    "         'agent_type' : agent_type,\n",
    "         'green_time' : 6,\n",
    "         'redamber_time' : 0,\n",
    "         'amber_time' : 3, \n",
    "         'red_time' : 0,\n",
    "         'state_size' : [13],\n",
    "         'state_type' : 'QueuesSig',\n",
    "         'reward_type' : 'Queues' ,\n",
    "        'queues_counter_ID' : [13,14,15,16,17,18,19,20,21,22,23,24]\n",
    "         },\n",
    "                  2 : {'default_actions' :  {    0 : [1,1,1,0,0,0,0,0,0,0,0,0],\n",
    "                                             1 : [0,0,0,1,1,1,0,0,0,0,0,0],\n",
    "                                             2 : [0,0,0,0,0,0,1,1,1,0,0,0],\n",
    "                                             3 : [0,0,0,0,0,0,0,0,0,1,1,1],\n",
    "                                             4 : [1,0,0,0,0,0,1,0,0,0,0,0],\n",
    "                                             5 : [0,0,0,1,0,0,0,0,0,1,0,0],\n",
    "                                             6 : [0,1,1,0,0,0,0,1,1,0,0,0],\n",
    "                                             7 : [0,0,0,0,1,1,0,0,0,0,1,1]},\n",
    "         \n",
    "         'all_actions' :        {            0 : [1,1,1,0,0,0,0,0,0,0,0,0],\n",
    "                                             1 : [0,0,0,1,1,1,0,0,0,0,0,0],\n",
    "                                             2 : [0,0,0,0,0,0,1,1,1,0,0,0],\n",
    "                                             3 : [0,0,0,0,0,0,0,0,0,1,1,1],\n",
    "                                             4 : [1,0,0,0,0,0,1,0,0,0,0,0],\n",
    "                                             5 : [0,0,0,1,0,0,0,0,0,1,0,0],\n",
    "                                             6 : [0,1,1,0,0,0,0,1,1,0,0,0],\n",
    "                                             7 : [0,0,0,0,1,1,0,0,0,0,1,1]},\n",
    " \n",
    "         'link' : [],\n",
    "         'lane' : ['31-1', '31-2', '31-3', '32-1', '32-2', '32-3', '33-1', '33-2', '33-3', '34-1', '34-2', '34-3'],\n",
    "         \n",
    "         'controled_by_com' : True,\n",
    "         'agent_type' : agent_type,\n",
    "         'green_time' : 6,\n",
    "         'redamber_time' : 0,\n",
    "         'amber_time' : 3, \n",
    "         'red_time' : 0,\n",
    "         'state_size' : [13],\n",
    "         'state_type' : 'QueuesSig',\n",
    "         'reward_type' : 'Queues' ,\n",
    "         'queues_counter_ID' : [25,26,27,28,29,30,31,32,33,34,35,36]\n",
    "         },\n",
    "                  3 : {'default_actions' :  {    0 : [1,1,1,0,0,0,0,0,0,0,0,0],\n",
    "                                             1 : [0,0,0,1,1,1,0,0,0,0,0,0],\n",
    "                                             2 : [0,0,0,0,0,0,1,1,1,0,0,0],\n",
    "                                             3 : [0,0,0,0,0,0,0,0,0,1,1,1],\n",
    "                                             4 : [1,0,0,0,0,0,1,0,0,0,0,0],\n",
    "                                             5 : [0,0,0,1,0,0,0,0,0,1,0,0],\n",
    "                                             6 : [0,1,1,0,0,0,0,1,1,0,0,0],\n",
    "                                             7 : [0,0,0,0,1,1,0,0,0,0,1,1]},\n",
    "         \n",
    "         'all_actions' :        {            0 : [1,1,1,0,0,0,0,0,0,0,0,0],\n",
    "                                             1 : [0,0,0,1,1,1,0,0,0,0,0,0],\n",
    "                                             2 : [0,0,0,0,0,0,1,1,1,0,0,0],\n",
    "                                             3 : [0,0,0,0,0,0,0,0,0,1,1,1],\n",
    "                                             4 : [1,0,0,0,0,0,1,0,0,0,0,0],\n",
    "                                             5 : [0,0,0,1,0,0,0,0,0,1,0,0],\n",
    "                                             6 : [0,1,1,0,0,0,0,1,1,0,0,0],\n",
    "                                             7 : [0,0,0,0,1,1,0,0,0,0,1,1]},\n",
    " \n",
    "         'link' : [],\n",
    "         'lane' : ['41-1', '41-2', '41-3', '42-1', '42-2', '42-3', '43-1', '43-2', '43-3', '44-1', '44-2', '44-3'],\n",
    "         \n",
    "         'controled_by_com' : True,\n",
    "         'agent_type' : agent_type,\n",
    "         'green_time' : 6,\n",
    "         'redamber_time' : 0,\n",
    "         'amber_time' : 3, \n",
    "         'red_time' : 0,\n",
    "         'state_size' : [13],\n",
    "         'state_type' : 'QueuesSig',\n",
    "         'reward_type' : 'Queues' ,\n",
    "          'queues_counter_ID' : [37,38,39,40,41,42,43,44,45,46,47,48]\n",
    "         },\n",
    "                  4 : {'default_actions' :  {    0 : [1,1,1,0,0,0,0,0,0,0,0,0],\n",
    "                                             1 : [0,0,0,1,1,1,0,0,0,0,0,0],\n",
    "                                             2 : [0,0,0,0,0,0,1,1,1,0,0,0],\n",
    "                                             3 : [0,0,0,0,0,0,0,0,0,1,1,1],\n",
    "                                             4 : [1,0,0,0,0,0,1,0,0,0,0,0],\n",
    "                                             5 : [0,0,0,1,0,0,0,0,0,1,0,0],\n",
    "                                             6 : [0,1,1,0,0,0,0,1,1,0,0,0],\n",
    "                                             7 : [0,0,0,0,1,1,0,0,0,0,1,1]},\n",
    "         \n",
    "         'all_actions' :        {            0 : [1,1,1,0,0,0,0,0,0,0,0,0],\n",
    "                                             1 : [0,0,0,1,1,1,0,0,0,0,0,0],\n",
    "                                             2 : [0,0,0,0,0,0,1,1,1,0,0,0],\n",
    "                                             3 : [0,0,0,0,0,0,0,0,0,1,1,1],\n",
    "                                             4 : [1,0,0,0,0,0,1,0,0,0,0,0],\n",
    "                                             5 : [0,0,0,1,0,0,0,0,0,1,0,0],\n",
    "                                             6 : [0,1,1,0,0,0,0,1,1,0,0,0],\n",
    "                                             7 : [0,0,0,0,1,1,0,0,0,0,1,1]},\n",
    " \n",
    "         'link' : [],\n",
    "         'lane' : ['51-1', '51-2', '51-3', '52-1', '52-2', '52-3', '53-1', '53-2', '53-3', '54-1', '54-2', '54-3'],\n",
    "         \n",
    "         'controled_by_com' : True,\n",
    "         'agent_type' : agent_type,\n",
    "         'green_time' : 6,\n",
    "         'redamber_time' : 0,\n",
    "         'amber_time' : 3, \n",
    "         'red_time' : 0,\n",
    "         'state_size' : [13],\n",
    "         'state_type' : 'QueuesSig',\n",
    "         'reward_type' : 'Queues' ,\n",
    "         'queues_counter_ID' : [49,50,51,52,53,54,55,56,57,58,59,60]\n",
    "         }\n",
    "    },\n",
    "   'demand' : { 'default' : [400,400,400,400,400,400,400,400,400,400,400,400],\n",
    "             \n",
    "             0 : [200,200,200,200,200,200,200,200,200,200,200,200],\n",
    "             1 : [400,400,400,400,400,400,400,400,400,400,400,400],\n",
    "             2 : [500,900,500,500,900,500,500,900,500,500,900,500],\n",
    "             3 : [500,1000,500,500,1000,500,500,1000,500,500,1000,500],\n",
    "             4 : [500,700,500,500,700,500,500,700,500,500,700,500],\n",
    "             5 : [500,700,500,500,700,500,500,700,500,500,700,500],\n",
    "             6 : [500,1000,500,500,1000,500,500,1000,500,500,1000,500],\n",
    "             7 : [500,900,500,500,900,500,500,900,500,500,900,500],\n",
    "             8 : [400,400,400,400,400,400,400,400,400,400,400,400],\n",
    "             9 : [200,200,200,200,200,200,200,200,200,200,200,200]\n",
    "            }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## DQN Hyperaramenters\n",
    "episodes = 400\n",
    "copy_weights_frequency = 20 # On a successfull run I copied the weight every 50\n",
    "\n",
    "PER_activated = True\n",
    "memory_size = 1000\n",
    "batch_size = 128\n",
    "\n",
    "gamma = 0.95\n",
    "alpha = 0.005"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exploration Schedule (\"linear\" or \"geometric\")\n",
    "exploration_schedule = \"geometric\"\n",
    "epsilon_start = 1\n",
    "epsilon_end   = 0.001\n",
    "\n",
    "Random_Seed = 100\n",
    "\n",
    "def choose_schedule(exploration_schedule, espilon_start, epsilon_end, episodes):\n",
    "    if exploration_schedule == \"linear\":\n",
    "        epsilon_decay = 1.2*(epsilon_end - epsilon_start)/(episodes-1)\n",
    "        epsilon_sequence = [1 + epsilon_decay * entry for entry in range(episodes+1)]\n",
    "        epsilon_sequence = [0 if entry < 0 else entry for entry in epsilon_sequence]\n",
    "    elif exploration_schedule == \"geometric\":\n",
    "        epsilon_decay = np.power(epsilon_end/epsilon_start, 1./(episodes-1)) # Geometric decay\n",
    "        epsilon_sequence = [epsilon_start * epsilon_decay ** entry for entry in range(episodes+1)]\n",
    "    elif exploration_schedule == \"entropy\":\n",
    "        pass\n",
    "    else:\n",
    "        print(\"ERROR: Unrecognized choice of exploration schedule.\")\n",
    "        \n",
    "    # Plotting exploration schedule\n",
    "    plt.figure(figsize=(8,4.5))\n",
    "    x_series = np.array(range(1,episodes+1))\n",
    "    y_series = epsilon_sequence[0:episodes]\n",
    "    plt.plot(x_series, y_series, '-b')\n",
    "    plt.xlabel('Episodes')\n",
    "    plt.ylabel('Ratio of random exploration')\n",
    "    plt.title('Exploration schedule')\n",
    "    plt.show()\n",
    "    return(epsilon_sequence)\n",
    "\n",
    "epsilon_sequence = choose_schedule(exploration_schedule, epsilon_start, epsilon_end, episodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Five_intersection_MultiDQN_Agents = MasterDQN_Agent(model_name, vissim_working_directory, sim_length, Five_intersection_dictionary,\\\n",
    "                gamma, alpha, agent_type, memory_size, PER_activated, batch_size, copy_weights_frequency, epsilon_sequence,\\\n",
    "                Random_Seed = Random_Seed, timesteps_per_second = 1, Session_ID = Session_ID, verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Five_intersection_MultiDQN_Agents.prepopulate_memory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "Five_intersection_MultiDQN_Agents.train(episodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Five_intersection_MultiDQN_Agents.save(401)\n",
    "Five_intersection_MultiDQN_Agents.load(400,best = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Five_intersection_MultiDQN_Agents.Agents[0].load_agent(vissim_working_directory, 'Single_Cross_Triple', 'Single_Cross_Triple8_actions',400 , best = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Episode_Queues, Cumulative_Episode_Delays,Cumulative_Episode_stop_Delays, Cumulative_Totale_network_delay,Cumulative_Totale_network_stop_delay = Five_intersection_MultiDQN_Agents.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time = [t for t in range(len(Cumulative_Totale_network_stop_delay))]\n",
    "\n",
    "\n",
    "# Queues ovzer time for each junction\n",
    "for idx, queues in Episode_Queues.items():\n",
    "    queues = np.array(queues)\n",
    "    queues = queues.T\n",
    "    \n",
    "    plt.figure('1'+str(idx),figsize=(16, 9))\n",
    "    \n",
    "    Queuesdf = pd.DataFrame()\n",
    "    \n",
    "    Queuesdf['Time'] = time\n",
    "    \n",
    "    for i, queue in enumerate(queues):\n",
    "        plt.plot(queue)\n",
    "        Queuesdf[str(i)] = queue\n",
    "        \n",
    "    plt.xlabel('Time [s]')\n",
    "    plt.ylabel('Queue Length')\n",
    "    plt.title('Junction {} Queue length'.format(idx))\n",
    "    plt.gca().legend(('West Queue','South Queue', 'East Queue', 'North Queue'))\n",
    "    \n",
    "    Path = os.path.join(vissim_working_directory, model_name, \"Agents_Results\", Session_ID,\\\n",
    "                        \"Junction{}_Queues.png\".format(idx))               \n",
    "    plt.savefig(Path)\n",
    "    \n",
    "    csv_Path = os.path.join(vissim_working_directory, model_name, \"Agents_Results\", Session_ID,\\\n",
    "                        \"Junction{}_Queues.csv\".format(idx))        \n",
    "   \n",
    "    Queuesdf.to_csv(csv_Path,index=False)\n",
    "        \n",
    "        \n",
    "# Accumulated delay over time for each junction\n",
    "for idx, delay in Cumulative_Episode_Delays.items():\n",
    "    \n",
    "    plt.figure('2'+str(idx),figsize=(16, 9))\n",
    "    \n",
    "    delaydf = pd.DataFrame()   \n",
    "    delaydf['Time'] = time\n",
    "    delaydf['Junction {} delay'.format(idx)] = delay\n",
    "    \n",
    "    plt.plot(delay)\n",
    "    plt.xlabel('Time [s]')\n",
    "    plt.ylabel('Accumulated Delay')\n",
    "    plt.title('Junction {} Delay'.format(idx))\n",
    "    plt.gca().legend('Junction accumulated delay')\n",
    "    \n",
    "    Path = os.path.join(vissim_working_directory, model_name, \"Agents_Results\", Session_ID,\\\n",
    "                            \"Junction{}_Cumulative_Delay.png\".format(idx))\n",
    "    csv_Path = os.path.join(vissim_working_directory, model_name, \"Agents_Results\", Session_ID,\\\n",
    "                        \"Junction{}_Cumulative_Delay.csv\".format(idx))   \n",
    "    plt.savefig(Path)\n",
    "\n",
    "    delaydf.to_csv(csv_Path,index=False)\n",
    "    \n",
    "    \n",
    "# Accumulated stop delay over time for each junction\n",
    "for idx, stop_delay in Cumulative_Episode_stop_Delays.items():\n",
    "    \n",
    "    plt.figure('3'+str(idx),figsize=(16, 9))\n",
    "    \n",
    "    stop_delaydf = pd.DataFrame()   \n",
    "    stop_delaydf['Time'] = time\n",
    "    stop_delaydf['Junction {} stop delay'.format(idx)] = stop_delay\n",
    "\n",
    "    plt.plot(stop_delay)\n",
    "    plt.xlabel('Time [s]')\n",
    "    plt.ylabel('Accumulated Stop Delay')\n",
    "    plt.title('Junction {} Stop Delay'.format(idx))\n",
    "    plt.gca().legend('Junction accumulated Stop delay')\n",
    "    \n",
    "    Path = os.path.join(vissim_working_directory, model_name, \"Agents_Results\", Session_ID,\\\n",
    "                            \"Junction{}_Cumulative_stop_Delay.png\".format(idx))\n",
    "    csv_Path = os.path.join(vissim_working_directory, model_name, \"Agents_Results\", Session_ID,\\\n",
    "                        \"Junction{}_Cumulative_stop_Delay.csv\".format(idx))\n",
    "    plt.savefig(Path)\n",
    "    stop_delaydf.to_csv(csv_Path,index=False)\n",
    "    \n",
    "# Global Accumulated delay over time\n",
    "plt.figure('4',figsize=(16,9))\n",
    "\n",
    "\n",
    "Global_delaydf = pd.DataFrame()   \n",
    "Global_delaydf['Time'] = time\n",
    "Global_delaydf['Global accumulated Delay'] = Cumulative_Totale_network_delay\n",
    "\n",
    "plt.plot(Cumulative_Totale_network_delay)\n",
    "plt.xlabel('Time [s]')\n",
    "plt.ylabel('Global accumulated Delay')\n",
    "plt.title('Global accumulated Delay')\n",
    "plt.gca().legend('Global accumulated delay')\n",
    "\n",
    "Path = os.path.join(vissim_working_directory, model_name, \"Agents_Results\", Session_ID,\\\n",
    "                        \"Total_Cumulative_Delay.png\")\n",
    "csv_Path = os.path.join(vissim_working_directory, model_name, \"Agents_Results\", Session_ID,\\\n",
    "                        \"Total_Cumulative_Delay.csv\")\n",
    "plt.savefig(Path)\n",
    "Global_delaydf.to_csv(csv_Path,index=False)\n",
    "\n",
    "# Global Accumulated stop delay over time\n",
    "plt.figure('5'+str(idx),figsize=(16, 9))\n",
    "\n",
    "Global_stop_delaydf = pd.DataFrame()   \n",
    "Global_stop_delaydf['Time'] = time\n",
    "Global_stop_delaydf['Global accumulated stop Delay'] = Cumulative_Totale_network_stop_delay\n",
    "\n",
    "plt.plot(Cumulative_Totale_network_stop_delay)\n",
    "plt.xlabel('Time [s]')\n",
    "plt.ylabel('Global accumulated stop Delay')\n",
    "plt.title('Global accumulated stop Delay')\n",
    "plt.gca().legend('Global accumulated stop Delay')\n",
    "\n",
    "Path = os.path.join(vissim_working_directory, model_name, \"Agents_Results\", Session_ID,\\\n",
    "                        \"Total_Cumulative_stop_Delay.png\")\n",
    "csv_Path = os.path.join(vissim_working_directory, model_name, \"Agents_Results\", Session_ID,\\\n",
    "                        \"Total_Cumulative_stop_Delay.csv\")\n",
    "plt.savefig(Path)\n",
    "Global_stop_delaydf.to_csv(csv_Path,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Five_intersection_MultiDQN_Agents.Agents[2] = Five_intersection_MultiDQN_Agents.Agents[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Five_intersection_MultiDQN_Agents.demo()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
