{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Vissim_env_class import environment\n",
    "from MasterDQN_Agent import MasterDQN_Agent\n",
    "\n",
    "# Network Specific Libraries\n",
    "from Balance_Functions import balance_dictionary\n",
    "\n",
    "# General Libraries\n",
    "import numpy as np \n",
    "import pylab as plt\n",
    "import os\n",
    "import csv\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Single_Cross_Triple 8 actions DQN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "model_name  = 'Single_Cross_Triple'\n",
    "#vissim_working_directory =  'C:\\\\Users\\\\Rzhang\\\\Desktop\\\\MLforFlowOptimisationOrigine\\\\Vissim\\\\'\n",
    "vissim_working_directory = \"C:\\\\Users\\\\acabrejasegea\\\\Desktop\\\\15_Timescales_utc\\\\Timescales_and_Discount_Factor_in_UTC\"\n",
    "\n",
    "sim_length = 3601\n",
    "timesteps_per_second = 1\n",
    "learning_iterations = 10\n",
    "actions_set = \"all_actions\"\n",
    "\n",
    "agent_type = \"DuelingDDQN\"\n",
    "Session_ID = \"SCT_8act_DuelingDDQN_common_memory_generation_2\"\n",
    "\n",
    "# all controller actions\n",
    "Single_Cross_Triple_dictionary8 =\\\n",
    "{\\\n",
    "    # Controller Number 0 \n",
    "   'junctions' : {0 : {'default_actions' :  {    0 : [1,1,1,0,0,0,0,0,0,0,0,0],\n",
    "                                             1 : [0,0,0,1,1,1,0,0,0,0,0,0],\n",
    "                                             2 : [0,0,0,0,0,0,1,1,1,0,0,0],\n",
    "                                             3 : [0,0,0,0,0,0,0,0,0,1,1,1],\n",
    "                                             4 : [1,0,0,0,0,0,1,0,0,0,0,0],\n",
    "                                             5 : [0,0,0,1,0,0,0,0,0,1,0,0],\n",
    "                                             6 : [0,1,1,0,0,0,0,1,1,0,0,0],\n",
    "                                             7 : [0,0,0,0,1,1,0,0,0,0,1,1]},\n",
    "         \n",
    "         'all_actions' :        {            0 : [1,1,1,0,0,0,0,0,0,0,0,0],\n",
    "                                             1 : [0,0,0,1,1,1,0,0,0,0,0,0],\n",
    "                                             2 : [0,0,0,0,0,0,1,1,1,0,0,0],\n",
    "                                             3 : [0,0,0,0,0,0,0,0,0,1,1,1],\n",
    "                                             4 : [1,0,0,0,0,0,1,0,0,0,0,0],\n",
    "                                             5 : [0,0,0,1,0,0,0,0,0,1,0,0],\n",
    "                                             6 : [0,1,1,0,0,0,0,1,1,0,0,0],\n",
    "                                             7 : [0,0,0,0,1,1,0,0,0,0,1,1]},\n",
    " \n",
    "         'link' : [1, 3, 5, 7],\n",
    "         'lane' : ['1-1', '1-2', '1-3', '3-1', '3-2', '3-3', '5-1', '5-2', '5-3', '7-1', '7-2', '7-3'],\n",
    "         \n",
    "         'controled_by_com' : True,\n",
    "         'agent_type' : agent_type,\n",
    "         'green_time' : 6,\n",
    "         'redamber_time' : 0,\n",
    "         'amber_time' : 3, \n",
    "         'red_time' : 0,\n",
    "         'state_size' : [13],\n",
    "         'state_type' : 'QueuesSig',\n",
    "         'reward_type' : 'Queues' ,\n",
    "         'queues_counter_ID' : [1,2,3,4,5,6,7,8,9,10,11,12]             \n",
    "         }\n",
    "    },\n",
    "   'demand' : { 'default' : [400, 400, 400, 400],\n",
    "             \n",
    "             0 : [300,300,300,300],\n",
    "             1 : [600,600,600,600],\n",
    "             2 : [1350,750,1350,750],\n",
    "             3 : [1500,750,1500,750],\n",
    "             4 : [1050,750,1050,750],\n",
    "             5 : [750,1050,750,1050],\n",
    "             6 : [750,1500,750,1500],\n",
    "             7 : [750,1350,750,1350],\n",
    "             8 : [600,600,600,600],\n",
    "             9 : [300,300,300,300]\n",
    "            }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "## DQN Hyperaramenters\n",
    "episodes = 400 \n",
    "copy_weights_frequency = 20 # On a successfull run I copied the weight every 50\n",
    "\n",
    "PER_activated = True\n",
    "memory_size = 5000\n",
    "batch_size = 128\n",
    "\n",
    "gamma = 0.9\n",
    "alpha = 0.005"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Exploration Schedule (\"linear\" or \"geometric\")\n",
    "exploration_schedule = \"linear\"\n",
    "epsilon_start = 1\n",
    "epsilon_end   = 0.001\n",
    "\n",
    "Random_Seed = 100\n",
    "\n",
    "def choose_schedule(exploration_schedule, espilon_start, epsilon_end, episodes):\n",
    "    if exploration_schedule == \"linear\":\n",
    "        epsilon_decay = 1.2*(epsilon_end - epsilon_start)/(episodes-1)\n",
    "        epsilon_sequence = [1 + epsilon_decay * entry for entry in range(episodes+1)]\n",
    "        epsilon_sequence = [0 if entry < 0 else entry for entry in epsilon_sequence]\n",
    "    elif exploration_schedule == \"geometric\":\n",
    "        epsilon_decay = np.power(epsilon_end/epsilon_start, 1./(episodes-1)) # Geometric decay\n",
    "        epsilon_sequence = [epsilon_start * epsilon_decay ** entry for entry in range(episodes+1)]\n",
    "    elif exploration_schedule == \"entropy\":\n",
    "        pass\n",
    "    else:\n",
    "        print(\"ERROR: Unrecognized choice of exploration schedule.\")\n",
    "        \n",
    "    # Plotting exploration schedule\n",
    "    plt.figure(figsize=(8,4.5))\n",
    "    x_series = np.array(range(1,episodes+1))\n",
    "    y_series = epsilon_sequence[0:episodes]\n",
    "    plt.plot(x_series, y_series, '-b')\n",
    "    plt.xlabel('Episodes')\n",
    "    plt.ylabel('Ratio of random exploration')\n",
    "    plt.title('Exploration schedule')\n",
    "    plt.show()\n",
    "    return(epsilon_sequence)\n",
    "\n",
    "epsilon_sequence = choose_schedule(exploration_schedule, epsilon_start, epsilon_end, episodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "Single_Cross_Triple8_MultiDQN_Agents = MasterDQN_Agent(model_name, vissim_working_directory,\\\n",
    "                                                       sim_length, Single_Cross_Triple_dictionary8,\\\n",
    "                                                       actions_set, gamma, alpha, agent_type,\\\n",
    "                                                       memory_size, PER_activated, batch_size,\\\n",
    "                                                       learning_iterations, copy_weights_frequency,\\\n",
    "                                                       epsilon_sequence,Random_Seed,\\\n",
    "                                                       timesteps_per_second, Session_ID,\\\n",
    "                                                       verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "Single_Cross_Triple8_MultiDQN_Agents.prepopulate_memory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Single_Cross_Triple8_MultiDQN_Agents.train(episodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "Single_Cross_Triple8_MultiDQN_Agents.demo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "filename = os.path.join(vissim_working_directory, model_name, \"Agents_Results\", agent_type, Session_ID) + \"\\\\memoryD3QN.pkl\"\n",
    "memory = Single_Cross_Triple8_MultiDQN_Agents.Agents[0].memory2\n",
    "pickle.dump(memory, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## AGENT TRAINING RESULTS\n",
    "# Path to results folder\n",
    "results_path = os.path.join(vissim_working_directory, model_name, \"Agents_Results\", agent_type, Session_ID)\n",
    "\n",
    "# Loop over each agent\n",
    "for idx , agent in Single_Cross_Triple8_MultiDQN_Agents.Agents.items():\n",
    "    intersection_number_in_vissim = Single_Cross_Triple8_MultiDQN_Agents.Agents[0].signal_id + 1\n",
    "    print(\"Intersection \"+str(intersection_number_in_vissim))\n",
    "    \n",
    "    ## SAVE TRAINING DATA TO JSON.\n",
    "    json_filename = \"Agent{}_Loss_average_reward.json\".format(intersection_number_in_vissim)\n",
    "    Loss_reward = dict()   \n",
    "    # Loss dictionary\n",
    "    for epoch, loss in enumerate(agent.loss):\n",
    "        loss_dict = { epoch : loss }\n",
    "    Loss_reward['Agent{} loss'.format(intersection_number_in_vissim)] = loss_dict\n",
    "    # Reward dictionary            \n",
    "    episode = [i for i in range(len(agent.reward_storage))]\n",
    "    Loss_reward['Agent{} Average_Reward'.format(intersection_number_in_vissim)] = agent.reward_storage\n",
    "    # Store as JSON\n",
    "    with open(results_path + \"/\" + json_filename, 'w') as f:\n",
    "        json.dump(Loss_reward, f)\n",
    "    print(\"Agent {}: Training Loss and Average Reward during training successfuly saved to file:\".format(intersection_number_in_vissim))\n",
    "    print(results_path + \"/\" + json_filename)\n",
    "    \n",
    "    ## LOADING DATA FROM JSON\n",
    "    #results_path = os.path.join(vissim_working_directory, model_name, \"Agents_Results\", agent_type, Session_ID)\n",
    "    #dictionary_filename = \"Agent{}_Loss_average_reward.json\".format(intersection_number_in_vissim)\n",
    "    #with open(results_path + \"/\" + json_filename, 'r') as fp:\n",
    "    #    data = json.load(fp)\n",
    "    #print(data)\n",
    "    \n",
    "    ## TRAINING PLOTS\n",
    "    loss_plot_filename  = \"Agent{}_Loss.png\".format(intersection_number_in_vissim)\n",
    "    reward_plot_filename  = \"Agent{}_average_reward.png\".format(intersection_number_in_vissim) \n",
    "    \n",
    "    ## Loss Plot\n",
    "    plt.figure('LossAgent'+str(idx),figsize=(16,9))\n",
    "    plt.plot(agent.loss)\n",
    "    #plt.yscale('log')\n",
    "\n",
    "    plt.xlabel('Training Epoch',fontsize=18)\n",
    "    plt.ylabel('Loss',fontsize=18)\n",
    "    plt.title('Agent {} Loss over training'.format(intersection_number_in_vissim),fontsize=18)\n",
    "    plt.savefig(results_path + \"/\" + loss_plot_filename)\n",
    "\n",
    "    ## Average Reward Plot\n",
    "    plt.figure('RewardAgent'+str(idx),figsize=(16,9))\n",
    "    plt.plot(agent.reward_storage)\n",
    "    plt.xlabel('Training Episode',fontsize=18)\n",
    "    plt.ylabel('Average reward',fontsize=18)\n",
    "    plt.title('Agent {} average reward over training'.format(intersection_number_in_vissim),fontsize=18)\n",
    "    plt.savefig(results_path + \"/\" + reward_plot_filename)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "Single_Cross_Triple8_MultiDQN_Agents.save(episodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "Single_Cross_Triple8_MultiDQN_Agents.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "time = [t for t in range(len(Single_Cross_Triple8_MultiDQN_Agents.Cumulative_Totale_network_stop_delay))]\n",
    "\n",
    "# Queues ovzer time for each junction\n",
    "for idx, queues in Single_Cross_Triple8_MultiDQN_Agents.Episode_Queues.items():\n",
    "    queues = np.array(queues)\n",
    "    queues = queues.T\n",
    "    \n",
    "    plt.figure('1'+str(idx),figsize=(16, 9))\n",
    "    \n",
    "    Queuesdf = pd.DataFrame()\n",
    "    \n",
    "    Queuesdf['Time'] = time\n",
    "    Queues_legend = []\n",
    "    \n",
    "    for i, queue in enumerate(queues):\n",
    "        plt.plot(queue, label = \"Queue\"+str(i))\n",
    "        Queuesdf[str(i)] = queue\n",
    "        Queues_legend.append(\"Queue\"+str(i))\n",
    "        \n",
    "    plt.xlabel('Time [s]',fontsize=18)\n",
    "    plt.ylabel('Queue Length',fontsize=18)\n",
    "    plt.title('Junction {} Queue length'.format(idx),fontsize=18)\n",
    "    #plt.gca().legend(Queues_legend)\n",
    "    \n",
    "    Path = os.path.join(vissim_working_directory, model_name, \"Agents_Results\", Session_ID,\\\n",
    "                        \"Junction{}_Queues.png\".format(idx))               \n",
    "    plt.savefig(Path)\n",
    "    \n",
    "    csv_Path = os.path.join(vissim_working_directory, model_name, \"Agents_Results\", Session_ID,\\\n",
    "                        \"Junction{}_Queues.csv\".format(idx))        \n",
    "   \n",
    "    Queuesdf.to_csv(csv_Path,index=False)\n",
    "    plt.legend()\n",
    "        \n",
    "        \n",
    "# Accumulated delay over time for each junction\n",
    "for idx, delay in Single_Cross_Triple8_MultiDQN_Agents.Cumulative_Episode_Delays.items():\n",
    "    \n",
    "    plt.figure('2'+str(idx),figsize=(16, 9))\n",
    "    \n",
    "    delaydf = pd.DataFrame()   \n",
    "    delaydf['Time'] = time\n",
    "    delaydf['Junction {} delay'.format(idx)] = delay\n",
    "    \n",
    "    plt.plot(delay)\n",
    "    plt.xlabel('Time [s]',fontsize=18)\n",
    "    plt.ylabel('Accumulated Delay',fontsize=18)\n",
    "    plt.title('Junction {} Delay'.format(idx),fontsize=18)\n",
    "    plt.gca().legend('Junction accumulated delay')\n",
    "    \n",
    "    Path = os.path.join(vissim_working_directory, model_name, \"Agents_Results\", Session_ID,\\\n",
    "                            \"Junction{}_Cumulative_Delay.png\".format(idx))\n",
    "    csv_Path = os.path.join(vissim_working_directory, model_name, \"Agents_Results\", Session_ID,\\\n",
    "                        \"Junction{}_Cumulative_Delay.csv\".format(idx))   \n",
    "    plt.savefig(Path)\n",
    "\n",
    "    delaydf.to_csv(csv_Path,index=False)\n",
    "    \n",
    "    \n",
    "# Accumulated stop delay over time for each junction\n",
    "for idx, stop_delay in Single_Cross_Triple8_MultiDQN_Agents.Cumulative_Episode_stop_Delays.items():\n",
    "    \n",
    "    plt.figure('3'+str(idx),figsize=(16, 9))\n",
    "    \n",
    "    stop_delaydf = pd.DataFrame()   \n",
    "    stop_delaydf['Time'] = time\n",
    "    stop_delaydf['Junction {} stop delay'.format(idx)] = stop_delay\n",
    "\n",
    "    plt.plot(stop_delay)\n",
    "    plt.xlabel('Time [s]',fontsize=18)\n",
    "    plt.ylabel('Accumulated Stop Delay',fontsize=18)\n",
    "    plt.title('Junction {} Stop Delay'.format(idx),fontsize=18)\n",
    "    plt.gca().legend('Junction accumulated Stop delay')\n",
    "    \n",
    "    Path = os.path.join(vissim_working_directory, model_name, \"Agents_Results\", Session_ID,\\\n",
    "                            \"Junction{}_Cumulative_stop_Delay.png\".format(idx))\n",
    "    csv_Path = os.path.join(vissim_working_directory, model_name, \"Agents_Results\", Session_ID,\\\n",
    "                        \"Junction{}_Cumulative_stop_Delay.csv\".format(idx))\n",
    "    plt.savefig(Path)\n",
    "    stop_delaydf.to_csv(csv_Path,index=False)\n",
    "    \n",
    "# Global Accumulated delay over time\n",
    "plt.figure('4',figsize=(16,9))\n",
    "\n",
    "\n",
    "Global_delaydf = pd.DataFrame()   \n",
    "Global_delaydf['Time'] = time\n",
    "Global_delaydf['Global accumulated Delay'] = Single_Cross_Triple8_MultiDQN_Agents.Cumulative_Totale_network_delay\n",
    "\n",
    "plt.plot(Single_Cross_Triple8_MultiDQN_Agents.Cumulative_Totale_network_delay)\n",
    "plt.xlabel('Time [s]',fontsize=18)\n",
    "plt.ylabel('Global accumulated Delay',fontsize=18)\n",
    "plt.title('Global accumulated Delay',fontsize=18)\n",
    "plt.gca().legend('Global accumulated delay')\n",
    "\n",
    "Path = os.path.join(vissim_working_directory, model_name, \"Agents_Results\", Session_ID,\\\n",
    "                        \"Total_Cumulative_Delay.png\")\n",
    "csv_Path = os.path.join(vissim_working_directory, model_name, \"Agents_Results\", Session_ID,\\\n",
    "                        \"Total_Cumulative_Delay.csv\")\n",
    "plt.savefig(Path)\n",
    "Global_delaydf.to_csv(csv_Path,index=False)\n",
    "\n",
    "# Global Accumulated stop delay over time\n",
    "plt.figure('5'+str(idx),figsize=(16, 9))\n",
    "\n",
    "Global_stop_delaydf = pd.DataFrame()   \n",
    "Global_stop_delaydf['Time'] = time\n",
    "Global_stop_delaydf['Global accumulated stop Delay'] = Single_Cross_Triple8_MultiDQN_Agents.Cumulative_Totale_network_stop_delay\n",
    "\n",
    "plt.plot(Single_Cross_Triple8_MultiDQN_Agents.Cumulative_Totale_network_stop_delay)\n",
    "plt.xlabel('Time [s]',fontsize=18)\n",
    "plt.ylabel('Global accumulated stop Delay',fontsize=18)\n",
    "plt.title('Global accumulated stop Delay',fontsize=18)\n",
    "plt.gca().legend('Global accumulated stop Delay')\n",
    "\n",
    "Path = os.path.join(vissim_working_directory, model_name, \"Agents_Results\", Session_ID,\\\n",
    "                        \"Total_Cumulative_stop_Delay.png\")\n",
    "csv_Path = os.path.join(vissim_working_directory, model_name, \"Agents_Results\", Session_ID,\\\n",
    "                        \"Total_Cumulative_stop_Delay.csv\")\n",
    "plt.savefig(Path)\n",
    "Global_stop_delaydf.to_csv(csv_Path,index=False)\n",
    "\n",
    "\n",
    "# For the agent training\n",
    "\n",
    "for idx , agent in Single_Cross_Triple8_MultiDQN_Agents.Agents.items():  \n",
    "    plt.figure('6'+str(idx),figsize=(16, 9))\n",
    "    \n",
    "    Loss_rewarddf = pd.DataFrame()   \n",
    "    \n",
    "    plt.plot(agent.loss)\n",
    "    plt.xlabel('Episode',fontsize=18)\n",
    "    plt.ylabel('Loss',fontsize=18)\n",
    "    plt.title('Agent{} Loss over training'.format(idx),fontsize=18)\n",
    "    plt.gca().legend('Agent Loss over training')\n",
    "    \n",
    "    Path  = os.path.join(vissim_working_directory, model_name, \"Agents_Results\", Session_ID,\\\n",
    "                        \"Agent{}_Loss.png\".format(idx)) \n",
    "    plt.savefig(Path)\n",
    "    \n",
    "    csv_Path = os.path.join(vissim_working_directory, model_name, \"Agents_Results\", Session_ID,\\\n",
    "                           \"Agent{}_Loss_average_reward.csv\".format(idx)) \n",
    "    \n",
    "    \n",
    "    plt.figure('7'+str(idx),figsize=(16, 9))\n",
    "    plt.plot(agent.reward_storage)\n",
    "    plt.xlabel('Episode',fontsize=18)\n",
    "    plt.ylabel('Average reward',fontsize=18)\n",
    "    plt.title('Agent{} average reward over training'.format(idx),fontsize=18)\n",
    "    plt.gca().legend('Agent reward over training')\n",
    "    \n",
    "    Path  = os.path.join(vissim_working_directory, model_name, \"Agents_Results\", Session_ID,\\\n",
    "                        \"Agent{}_average_reward.png\".format(idx)) \n",
    "    plt.savefig(Path)\n",
    "    \n",
    "    \n",
    "    episode = [i for i in range(len(agent.reward_storage))]\n",
    "    \n",
    "    Loss_rewarddf['episode'] = episode \n",
    "    Loss_rewarddf['Agent{} loss'.format(idx)] = agent.loss\n",
    "    Loss_rewarddf['Agent{} Average_Reward'.format(idx)] = agent.reward_storage\n",
    "    \n",
    "    Loss_rewarddf.to_csv(csv_Path,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "Single_Cross_Triple8_MultiDQN_Agents.demo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "Single_Cross_Triple8_MultiDQN_Agents.Episode_Queues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Five intersection DQN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "model_name  = 'Five_intersection'\n",
    "#vissim_working_directory =  'C:\\\\Users\\\\Rzhang\\\\Desktop\\\\MLforFlowOptimisationOrigine\\\\Vissim\\\\'\n",
    "vissim_working_directory = 'C:\\\\Users\\\\acabrejasegea\\\\OneDrive - The Alan Turing Institute\\\\Desktop\\\\ATI\\\\0_TMF\\\\MLforFlowOptimisation\\\\Vissim\\\\'\n",
    "\n",
    "sim_length = 3601\n",
    "\n",
    "agent_type = \"DuelingDDQN\"\n",
    "Session_ID = \"Five5transfert\"\n",
    "\n",
    "# all controller actions\n",
    "Five_intersection_dictionary =\\\n",
    "{\\\n",
    "    # Controller Number 0 \n",
    "   'junctions' : {0 : {'default_actions' :  {    0 : [1,1,1,0,0,0,0,0,0,0,0,0],\n",
    "                                             1 : [0,0,0,1,1,1,0,0,0,0,0,0],\n",
    "                                             2 : [0,0,0,0,0,0,1,1,1,0,0,0],\n",
    "                                             3 : [0,0,0,0,0,0,0,0,0,1,1,1],\n",
    "                                             4 : [1,0,0,0,0,0,1,0,0,0,0,0],\n",
    "                                             5 : [0,0,0,1,0,0,0,0,0,1,0,0],\n",
    "                                             6 : [0,1,1,0,0,0,0,1,1,0,0,0],\n",
    "                                             7 : [0,0,0,0,1,1,0,0,0,0,1,1]},\n",
    "         \n",
    "         'all_actions' :        {            0 : [1,1,1,0,0,0,0,0,0,0,0,0],\n",
    "                                             1 : [0,0,0,1,1,1,0,0,0,0,0,0],\n",
    "                                             2 : [0,0,0,0,0,0,1,1,1,0,0,0],\n",
    "                                             3 : [0,0,0,0,0,0,0,0,0,1,1,1],\n",
    "                                             4 : [1,0,0,0,0,0,1,0,0,0,0,0],\n",
    "                                             5 : [0,0,0,1,0,0,0,0,0,1,0,0],\n",
    "                                             6 : [0,1,1,0,0,0,0,1,1,0,0,0],\n",
    "                                             7 : [0,0,0,0,1,1,0,0,0,0,1,1]},\n",
    " \n",
    "         'link' : [],\n",
    "         'lane' : ['11-1', '11-2', '11-3', '12-1', '12-2', '12-3', '13-1', '13-2', '13-3', '14-1', '14-2', '14-3'],\n",
    "         \n",
    "         'controled_by_com' : True,\n",
    "         'agent_type' : agent_type,\n",
    "         'green_time' : 6,\n",
    "         'redamber_time' : 0,\n",
    "         'amber_time' : 3, \n",
    "         'red_time' : 0,\n",
    "         'state_size' : [13],\n",
    "         'state_type' : 'QueuesSig',\n",
    "         'reward_type' : 'Queues',\n",
    "         'queues_counter_ID' : [1,2,3,4,5,6,7,8,9,10,11,12]\n",
    "         },\n",
    "                  1 : {'default_actions' :  {    0 : [1,1,1,0,0,0,0,0,0,0,0,0],\n",
    "                                             1 : [0,0,0,1,1,1,0,0,0,0,0,0],\n",
    "                                             2 : [0,0,0,0,0,0,1,1,1,0,0,0],\n",
    "                                             3 : [0,0,0,0,0,0,0,0,0,1,1,1],\n",
    "                                             4 : [1,0,0,0,0,0,1,0,0,0,0,0],\n",
    "                                             5 : [0,0,0,1,0,0,0,0,0,1,0,0],\n",
    "                                             6 : [0,1,1,0,0,0,0,1,1,0,0,0],\n",
    "                                             7 : [0,0,0,0,1,1,0,0,0,0,1,1]},\n",
    "         \n",
    "         'all_actions' :        {            0 : [1,1,1,0,0,0,0,0,0,0,0,0],\n",
    "                                             1 : [0,0,0,1,1,1,0,0,0,0,0,0],\n",
    "                                             2 : [0,0,0,0,0,0,1,1,1,0,0,0],\n",
    "                                             3 : [0,0,0,0,0,0,0,0,0,1,1,1],\n",
    "                                             4 : [1,0,0,0,0,0,1,0,0,0,0,0],\n",
    "                                             5 : [0,0,0,1,0,0,0,0,0,1,0,0],\n",
    "                                             6 : [0,1,1,0,0,0,0,1,1,0,0,0],\n",
    "                                             7 : [0,0,0,0,1,1,0,0,0,0,1,1]},\n",
    " \n",
    "         'link' : [],\n",
    "         'lane' : ['21-1', '21-2', '21-3', '22-1', '22-2', '22-3', '23-1', '23-2', '23-3', '24-1', '24-2', '24-3'],\n",
    "         \n",
    "         'controled_by_com' : True,\n",
    "         'agent_type' : agent_type,\n",
    "         'green_time' : 6,\n",
    "         'redamber_time' : 0,\n",
    "         'amber_time' : 3, \n",
    "         'red_time' : 0,\n",
    "         'state_size' : [13],\n",
    "         'state_type' : 'QueuesSig',\n",
    "         'reward_type' : 'Queues' ,\n",
    "        'queues_counter_ID' : [13,14,15,16,17,18,19,20,21,22,23,24]\n",
    "         },\n",
    "                  2 : {'default_actions' :  {    0 : [1,1,1,0,0,0,0,0,0,0,0,0],\n",
    "                                             1 : [0,0,0,1,1,1,0,0,0,0,0,0],\n",
    "                                             2 : [0,0,0,0,0,0,1,1,1,0,0,0],\n",
    "                                             3 : [0,0,0,0,0,0,0,0,0,1,1,1],\n",
    "                                             4 : [1,0,0,0,0,0,1,0,0,0,0,0],\n",
    "                                             5 : [0,0,0,1,0,0,0,0,0,1,0,0],\n",
    "                                             6 : [0,1,1,0,0,0,0,1,1,0,0,0],\n",
    "                                             7 : [0,0,0,0,1,1,0,0,0,0,1,1]},\n",
    "         \n",
    "         'all_actions' :        {            0 : [1,1,1,0,0,0,0,0,0,0,0,0],\n",
    "                                             1 : [0,0,0,1,1,1,0,0,0,0,0,0],\n",
    "                                             2 : [0,0,0,0,0,0,1,1,1,0,0,0],\n",
    "                                             3 : [0,0,0,0,0,0,0,0,0,1,1,1],\n",
    "                                             4 : [1,0,0,0,0,0,1,0,0,0,0,0],\n",
    "                                             5 : [0,0,0,1,0,0,0,0,0,1,0,0],\n",
    "                                             6 : [0,1,1,0,0,0,0,1,1,0,0,0],\n",
    "                                             7 : [0,0,0,0,1,1,0,0,0,0,1,1]},\n",
    " \n",
    "         'link' : [],\n",
    "         'lane' : ['31-1', '31-2', '31-3', '32-1', '32-2', '32-3', '33-1', '33-2', '33-3', '34-1', '34-2', '34-3'],\n",
    "         \n",
    "         'controled_by_com' : True,\n",
    "         'agent_type' : agent_type,\n",
    "         'green_time' : 6,\n",
    "         'redamber_time' : 0,\n",
    "         'amber_time' : 3, \n",
    "         'red_time' : 0,\n",
    "         'state_size' : [13],\n",
    "         'state_type' : 'QueuesSig',\n",
    "         'reward_type' : 'Queues' ,\n",
    "         'queues_counter_ID' : [25,26,27,28,29,30,31,32,33,34,35,36]\n",
    "         },\n",
    "                  3 : {'default_actions' :  {    0 : [1,1,1,0,0,0,0,0,0,0,0,0],\n",
    "                                             1 : [0,0,0,1,1,1,0,0,0,0,0,0],\n",
    "                                             2 : [0,0,0,0,0,0,1,1,1,0,0,0],\n",
    "                                             3 : [0,0,0,0,0,0,0,0,0,1,1,1],\n",
    "                                             4 : [1,0,0,0,0,0,1,0,0,0,0,0],\n",
    "                                             5 : [0,0,0,1,0,0,0,0,0,1,0,0],\n",
    "                                             6 : [0,1,1,0,0,0,0,1,1,0,0,0],\n",
    "                                             7 : [0,0,0,0,1,1,0,0,0,0,1,1]},\n",
    "         \n",
    "         'all_actions' :        {            0 : [1,1,1,0,0,0,0,0,0,0,0,0],\n",
    "                                             1 : [0,0,0,1,1,1,0,0,0,0,0,0],\n",
    "                                             2 : [0,0,0,0,0,0,1,1,1,0,0,0],\n",
    "                                             3 : [0,0,0,0,0,0,0,0,0,1,1,1],\n",
    "                                             4 : [1,0,0,0,0,0,1,0,0,0,0,0],\n",
    "                                             5 : [0,0,0,1,0,0,0,0,0,1,0,0],\n",
    "                                             6 : [0,1,1,0,0,0,0,1,1,0,0,0],\n",
    "                                             7 : [0,0,0,0,1,1,0,0,0,0,1,1]},\n",
    " \n",
    "         'link' : [],\n",
    "         'lane' : ['41-1', '41-2', '41-3', '42-1', '42-2', '42-3', '43-1', '43-2', '43-3', '44-1', '44-2', '44-3'],\n",
    "         \n",
    "         'controled_by_com' : True,\n",
    "         'agent_type' : agent_type,\n",
    "         'green_time' : 6,\n",
    "         'redamber_time' : 0,\n",
    "         'amber_time' : 3, \n",
    "         'red_time' : 0,\n",
    "         'state_size' : [13],\n",
    "         'state_type' : 'QueuesSig',\n",
    "         'reward_type' : 'Queues' ,\n",
    "          'queues_counter_ID' : [37,38,39,40,41,42,43,44,45,46,47,48]\n",
    "         },\n",
    "                  4 : {'default_actions' :  {    0 : [1,1,1,0,0,0,0,0,0,0,0,0],\n",
    "                                             1 : [0,0,0,1,1,1,0,0,0,0,0,0],\n",
    "                                             2 : [0,0,0,0,0,0,1,1,1,0,0,0],\n",
    "                                             3 : [0,0,0,0,0,0,0,0,0,1,1,1],\n",
    "                                             4 : [1,0,0,0,0,0,1,0,0,0,0,0],\n",
    "                                             5 : [0,0,0,1,0,0,0,0,0,1,0,0],\n",
    "                                             6 : [0,1,1,0,0,0,0,1,1,0,0,0],\n",
    "                                             7 : [0,0,0,0,1,1,0,0,0,0,1,1]},\n",
    "         \n",
    "         'all_actions' :        {            0 : [1,1,1,0,0,0,0,0,0,0,0,0],\n",
    "                                             1 : [0,0,0,1,1,1,0,0,0,0,0,0],\n",
    "                                             2 : [0,0,0,0,0,0,1,1,1,0,0,0],\n",
    "                                             3 : [0,0,0,0,0,0,0,0,0,1,1,1],\n",
    "                                             4 : [1,0,0,0,0,0,1,0,0,0,0,0],\n",
    "                                             5 : [0,0,0,1,0,0,0,0,0,1,0,0],\n",
    "                                             6 : [0,1,1,0,0,0,0,1,1,0,0,0],\n",
    "                                             7 : [0,0,0,0,1,1,0,0,0,0,1,1]},\n",
    " \n",
    "         'link' : [],\n",
    "         'lane' : ['51-1', '51-2', '51-3', '52-1', '52-2', '52-3', '53-1', '53-2', '53-3', '54-1', '54-2', '54-3'],\n",
    "         \n",
    "         'controled_by_com' : True,\n",
    "         'agent_type' : agent_type,\n",
    "         'green_time' : 6,\n",
    "         'redamber_time' : 0,\n",
    "         'amber_time' : 3, \n",
    "         'red_time' : 0,\n",
    "         'state_size' : [13],\n",
    "         'state_type' : 'QueuesSig',\n",
    "         'reward_type' : 'Queues' ,\n",
    "         'queues_counter_ID' : [49,50,51,52,53,54,55,56,57,58,59,60]\n",
    "         }\n",
    "    },\n",
    "   'demand' : { 'default' : [400,400,400,400,400,400,400,400,400,400,400,400],\n",
    "             \n",
    "             0 : [200,200,200,200,200,200,200,200,200,200,200,200],\n",
    "             1 : [400,400,400,400,400,400,400,400,400,400,400,400],\n",
    "             2 : [500,900,500,500,900,500,500,900,500,500,900,500],\n",
    "             3 : [500,1000,500,500,1000,500,500,1000,500,500,1000,500],\n",
    "             4 : [500,700,500,500,700,500,500,700,500,500,700,500],\n",
    "             5 : [500,700,500,500,700,500,500,700,500,500,700,500],\n",
    "             6 : [500,1000,500,500,1000,500,500,1000,500,500,1000,500],\n",
    "             7 : [500,900,500,500,900,500,500,900,500,500,900,500],\n",
    "             8 : [400,400,400,400,400,400,400,400,400,400,400,400],\n",
    "             9 : [200,200,200,200,200,200,200,200,200,200,200,200]\n",
    "            }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "## DQN Hyperaramenters\n",
    "episodes = 400\n",
    "copy_weights_frequency = 20 # On a successfull run I copied the weight every 50\n",
    "\n",
    "PER_activated = True\n",
    "memory_size = 1000\n",
    "batch_size = 128\n",
    "\n",
    "gamma = 0.95\n",
    "alpha = 0.005"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Exploration Schedule (\"linear\" or \"geometric\")\n",
    "exploration_schedule = \"geometric\"\n",
    "epsilon_start = 1\n",
    "epsilon_end   = 0.001\n",
    "\n",
    "Random_Seed = 100\n",
    "\n",
    "def choose_schedule(exploration_schedule, espilon_start, epsilon_end, episodes):\n",
    "    if exploration_schedule == \"linear\":\n",
    "        epsilon_decay = 1.2*(epsilon_end - epsilon_start)/(episodes-1)\n",
    "        epsilon_sequence = [1 + epsilon_decay * entry for entry in range(episodes+1)]\n",
    "        epsilon_sequence = [0 if entry < 0 else entry for entry in epsilon_sequence]\n",
    "    elif exploration_schedule == \"geometric\":\n",
    "        epsilon_decay = np.power(epsilon_end/epsilon_start, 1./(episodes-1)) # Geometric decay\n",
    "        epsilon_sequence = [epsilon_start * epsilon_decay ** entry for entry in range(episodes+1)]\n",
    "    elif exploration_schedule == \"entropy\":\n",
    "        pass\n",
    "    else:\n",
    "        print(\"ERROR: Unrecognized choice of exploration schedule.\")\n",
    "        \n",
    "    # Plotting exploration schedule\n",
    "    plt.figure(figsize=(8,4.5))\n",
    "    x_series = np.array(range(1,episodes+1))\n",
    "    y_series = epsilon_sequence[0:episodes]\n",
    "    plt.plot(x_series, y_series, '-b')\n",
    "    plt.xlabel('Episodes')\n",
    "    plt.ylabel('Ratio of random exploration')\n",
    "    plt.title('Exploration schedule')\n",
    "    plt.show()\n",
    "    return(epsilon_sequence)\n",
    "\n",
    "epsilon_sequence = choose_schedule(exploration_schedule, epsilon_start, epsilon_end, episodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "Five_intersection_MultiDQN_Agents = MasterDQN_Agent(model_name, vissim_working_directory, sim_length, Five_intersection_dictionary,\\\n",
    "                gamma, alpha, agent_type, memory_size, PER_activated, batch_size, copy_weights_frequency, epsilon_sequence,\\\n",
    "                Random_Seed = Random_Seed, timesteps_per_second = 1, Session_ID = Session_ID, verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "Five_intersection_MultiDQN_Agents.prepopulate_memory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "Five_intersection_MultiDQN_Agents.train(episodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "Five_intersection_MultiDQN_Agents.save(401)\n",
    "Five_intersection_MultiDQN_Agents.load(400,best = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "Five_intersection_MultiDQN_Agents.Agents[0].load_agent(vissim_working_directory, 'Single_Cross_Triple', 'Single_Cross_Triple8_actions',400 , best = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "Episode_Queues, Cumulative_Episode_Delays,Cumulative_Episode_stop_Delays, Cumulative_Totale_network_delay,Cumulative_Totale_network_stop_delay = Five_intersection_MultiDQN_Agents.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "time = [t for t in range(len(Cumulative_Totale_network_stop_delay))]\n",
    "\n",
    "\n",
    "# Queues ovzer time for each junction\n",
    "for idx, queues in Episode_Queues.items():\n",
    "    queues = np.array(queues)\n",
    "    queues = queues.T\n",
    "    \n",
    "    plt.figure('1'+str(idx),figsize=(16, 9))\n",
    "    \n",
    "    Queuesdf = pd.DataFrame()\n",
    "    \n",
    "    Queuesdf['Time'] = time\n",
    "    \n",
    "    for i, queue in enumerate(queues):\n",
    "        plt.plot(queue)\n",
    "        Queuesdf[str(i)] = queue\n",
    "        \n",
    "    plt.xlabel('Time [s]')\n",
    "    plt.ylabel('Queue Length')\n",
    "    plt.title('Junction {} Queue length'.format(idx))\n",
    "    plt.gca().legend(('West Queue','South Queue', 'East Queue', 'North Queue'))\n",
    "    \n",
    "    Path = os.path.join(vissim_working_directory, model_name, \"Agents_Results\", Session_ID,\\\n",
    "                        \"Junction{}_Queues.png\".format(idx))               \n",
    "    plt.savefig(Path)\n",
    "    \n",
    "    csv_Path = os.path.join(vissim_working_directory, model_name, \"Agents_Results\", Session_ID,\\\n",
    "                        \"Junction{}_Queues.csv\".format(idx))        \n",
    "   \n",
    "    Queuesdf.to_csv(csv_Path,index=False)\n",
    "        \n",
    "        \n",
    "# Accumulated delay over time for each junction\n",
    "for idx, delay in Cumulative_Episode_Delays.items():\n",
    "    \n",
    "    plt.figure('2'+str(idx),figsize=(16, 9))\n",
    "    \n",
    "    delaydf = pd.DataFrame()   \n",
    "    delaydf['Time'] = time\n",
    "    delaydf['Junction {} delay'.format(idx)] = delay\n",
    "    \n",
    "    plt.plot(delay)\n",
    "    plt.xlabel('Time [s]')\n",
    "    plt.ylabel('Accumulated Delay')\n",
    "    plt.title('Junction {} Delay'.format(idx))\n",
    "    plt.gca().legend('Junction accumulated delay')\n",
    "    \n",
    "    Path = os.path.join(vissim_working_directory, model_name, \"Agents_Results\", Session_ID,\\\n",
    "                            \"Junction{}_Cumulative_Delay.png\".format(idx))\n",
    "    csv_Path = os.path.join(vissim_working_directory, model_name, \"Agents_Results\", Session_ID,\\\n",
    "                        \"Junction{}_Cumulative_Delay.csv\".format(idx))   \n",
    "    plt.savefig(Path)\n",
    "\n",
    "    delaydf.to_csv(csv_Path,index=False)\n",
    "    \n",
    "    \n",
    "# Accumulated stop delay over time for each junction\n",
    "for idx, stop_delay in Cumulative_Episode_stop_Delays.items():\n",
    "    \n",
    "    plt.figure('3'+str(idx),figsize=(16, 9))\n",
    "    \n",
    "    stop_delaydf = pd.DataFrame()   \n",
    "    stop_delaydf['Time'] = time\n",
    "    stop_delaydf['Junction {} stop delay'.format(idx)] = stop_delay\n",
    "\n",
    "    plt.plot(stop_delay)\n",
    "    plt.xlabel('Time [s]')\n",
    "    plt.ylabel('Accumulated Stop Delay')\n",
    "    plt.title('Junction {} Stop Delay'.format(idx))\n",
    "    plt.gca().legend('Junction accumulated Stop delay')\n",
    "    \n",
    "    Path = os.path.join(vissim_working_directory, model_name, \"Agents_Results\", Session_ID,\\\n",
    "                            \"Junction{}_Cumulative_stop_Delay.png\".format(idx))\n",
    "    csv_Path = os.path.join(vissim_working_directory, model_name, \"Agents_Results\", Session_ID,\\\n",
    "                        \"Junction{}_Cumulative_stop_Delay.csv\".format(idx))\n",
    "    plt.savefig(Path)\n",
    "    stop_delaydf.to_csv(csv_Path,index=False)\n",
    "    \n",
    "# Global Accumulated delay over time\n",
    "plt.figure('4',figsize=(16,9))\n",
    "\n",
    "\n",
    "Global_delaydf = pd.DataFrame()   \n",
    "Global_delaydf['Time'] = time\n",
    "Global_delaydf['Global accumulated Delay'] = Cumulative_Totale_network_delay\n",
    "\n",
    "plt.plot(Cumulative_Totale_network_delay)\n",
    "plt.xlabel('Time [s]')\n",
    "plt.ylabel('Global accumulated Delay')\n",
    "plt.title('Global accumulated Delay')\n",
    "plt.gca().legend('Global accumulated delay')\n",
    "\n",
    "Path = os.path.join(vissim_working_directory, model_name, \"Agents_Results\", Session_ID,\\\n",
    "                        \"Total_Cumulative_Delay.png\")\n",
    "csv_Path = os.path.join(vissim_working_directory, model_name, \"Agents_Results\", Session_ID,\\\n",
    "                        \"Total_Cumulative_Delay.csv\")\n",
    "plt.savefig(Path)\n",
    "Global_delaydf.to_csv(csv_Path,index=False)\n",
    "\n",
    "# Global Accumulated stop delay over time\n",
    "plt.figure('5'+str(idx),figsize=(16, 9))\n",
    "\n",
    "Global_stop_delaydf = pd.DataFrame()   \n",
    "Global_stop_delaydf['Time'] = time\n",
    "Global_stop_delaydf['Global accumulated stop Delay'] = Cumulative_Totale_network_stop_delay\n",
    "\n",
    "plt.plot(Cumulative_Totale_network_stop_delay)\n",
    "plt.xlabel('Time [s]')\n",
    "plt.ylabel('Global accumulated stop Delay')\n",
    "plt.title('Global accumulated stop Delay')\n",
    "plt.gca().legend('Global accumulated stop Delay')\n",
    "\n",
    "Path = os.path.join(vissim_working_directory, model_name, \"Agents_Results\", Session_ID,\\\n",
    "                        \"Total_Cumulative_stop_Delay.png\")\n",
    "csv_Path = os.path.join(vissim_working_directory, model_name, \"Agents_Results\", Session_ID,\\\n",
    "                        \"Total_Cumulative_stop_Delay.csv\")\n",
    "plt.savefig(Path)\n",
    "Global_stop_delaydf.to_csv(csv_Path,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "Five_intersection_MultiDQN_Agents.Agents[2] = Five_intersection_MultiDQN_Agents.Agents[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "Five_intersection_MultiDQN_Agents.demo()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Balance RL DQN Partial Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current simulation: Balance_int3_all_actions_1000_10800_DuelingDDQN_memory_queuessq\n"
     ]
    }
   ],
   "source": [
    "intersection = 3\n",
    "map_name  = 'Balance_int'+str(intersection)\n",
    "model_name = map_name\n",
    "vissim_working_directory = \"C:\\\\Users\\\\acabrejasegea\\\\Desktop\\\\15_Timescales_utc\\\\Timescales_and_Discount_Factor_in_UTC\"\n",
    "#vissim_working_directory = \"E:\\\\OneDrive - University of Warwick\\\\Desktop\\\\ATI\\\\0_TMF\\\\MLforFlowOptimisation\\\\Vissim\"\n",
    "\n",
    "## Simulation Parameters\n",
    "Random_Seed = 10\n",
    "sim_length = 10801\n",
    "timesteps_per_second = 1\n",
    "agent_type = \"DuelingDDQN\"\n",
    "actions = 'all_actions'     # 'default_actions' or 'all_actions'\n",
    "\n",
    "## DQN Hyperaramenters\n",
    "episodes = 1000\n",
    "copy_weights_frequency = 10\n",
    "\n",
    "PER_activated = True\n",
    "memory_size = 10000\n",
    "batch_size = 128\n",
    "batches_per_episode = 20\n",
    "\n",
    "alpha = 0.0005\n",
    "gamma = 0.95\n",
    "\n",
    "# Load and partition balance dictionary\n",
    "Balance_dictionary = balance_dictionary(agent_type)\n",
    "if intersection == \"1_2_4\":\n",
    "    intersection = 1\n",
    "elif intersection == \"2_4\":\n",
    "    intersection = 2\n",
    "elif intersection == \"11_12\":\n",
    "    intersection = 11\n",
    "partial_dictionary = {\"junctions\": { (intersection-1) : Balance_dictionary[\"junctions\"][intersection-1]},\\\n",
    "                      \"demand\": Balance_dictionary[\"demand\"]}\n",
    "\n",
    "Session_ID = map_name + \"_\" + actions + \"_\" + str(episodes) + \"_\" + str(sim_length-1) + \"_\" + agent_type + \"_memory_queuessq\"\n",
    "print(\"Current simulation: {}\".format(Session_ID))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x324 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Exploration Schedule (\"linear\" or \"geometric\")\n",
    "exploration_schedule = \"linear\"\n",
    "epsilon_start = 1\n",
    "epsilon_end   = 0.01\n",
    "\n",
    "def choose_schedule(exploration_schedule, espilon_start, epsilon_end, episodes):\n",
    "    if exploration_schedule == \"linear\":\n",
    "        epsilon_decay = 1.2*(epsilon_end - epsilon_start)/(episodes-1)\n",
    "        epsilon_sequence = [1 + epsilon_decay * entry for entry in range(episodes+1)]\n",
    "        epsilon_sequence = [0.01 if entry < 0.01 else entry for entry in epsilon_sequence]\n",
    "    elif exploration_schedule == \"geometric\":\n",
    "        epsilon_decay = np.power(epsilon_end/epsilon_start, 1./(episodes-1)) # Geometric decay\n",
    "        epsilon_sequence = [epsilon_start * epsilon_decay ** entry for entry in range(episodes+1)]\n",
    "        epsilon_sequence = [0.01 if entry < 0.01 else entry for entry in epsilon_sequence]\n",
    "    elif exploration_schedule == \"entropy\":\n",
    "        pass\n",
    "    else:\n",
    "        print(\"ERROR: Unrecognized choice of exploration schedule.\")\n",
    "        \n",
    "    # Plotting exploration schedule\n",
    "    plt.figure(figsize=(8,4.5))\n",
    "    x_series = np.array(range(1,episodes+1))\n",
    "    y_series = epsilon_sequence[0:episodes]\n",
    "    plt.plot(x_series, y_series, '-b')\n",
    "    plt.xlabel('Episodes')\n",
    "    plt.ylabel('Ratio of random exploration')\n",
    "    plt.title('Exploration schedule')\n",
    "    plt.show()\n",
    "    return(epsilon_sequence)\n",
    "\n",
    "epsilon_sequence = choose_schedule(exploration_schedule, epsilon_start, epsilon_end, episodes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INTERSECTION 2: SETTING UP AGENT\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 14)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 24)           360         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 24)           600         dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 24)           600         dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 24)           600         dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 1)            25          dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 8)            200         dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "policy (Lambda)                 (None, 8)            0           dense_5[0][0]                    \n",
      "                                                                 dense_3[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 2,385\n",
      "Trainable params: 2,385\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Deployed instance of Dueling Double Deep Q Learning Agent(s) at Intersection 2\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Balance_int_MultiDQN_Agents = MasterDQN_Agent(model_name, vissim_working_directory, sim_length, partial_dictionary, actions,\\\n",
    "                gamma, alpha, agent_type, memory_size, PER_activated, batch_size, batches_per_episode, copy_weights_frequency, epsilon_sequence,\\\n",
    "                Random_Seed, timesteps_per_second, Session_ID, verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experience file not found. Generating now...\n",
      "Working Directory set to: C:\\Users\\acabrejasegea\\Desktop\\15_Timescales_utc\\Timescales_and_Discount_Factor_in_UTC\n",
      "Generating Cache...\n",
      "Cache generated.\n",
      "\n",
      "****************************\n",
      "*   COM Server dispatched  *\n",
      "****************************\n",
      "\n",
      "Attempting to load Model File: Balance_int3.inpx ...\n",
      "Model File load process successful.\n",
      "Simulation length set to 10801 seconds.\n",
      "Results from Previous Simulations: Deleted. Fresh Start Available.\n",
      "Fetched and containerized Network Object \n",
      "\n",
      "*******************************************************\n",
      "*                                                     *\n",
      "*                COM SETUP COMPLETE                   *\n",
      "*                                                     *\n",
      "*******************************************************\n",
      "\n",
      "Random seed set in simulator. Random Seed = 10\n",
      "Deploying Network Parser...\n",
      "Successful Network Crawl: Identified SignalControllers, Links, Lanes and Vehicle Inputs.\n",
      "\n",
      "Setting Simulation mode to: training\n",
      "Starting Deployments of Signal Control Units...\n",
      "SCUs successfully deployed. Elapsed time 0.25 seconds.\n",
      "\n",
      "After 0 actions taken by the Agents,  Agent 0 memory is 0.0 percent full\n",
      "After 1000 actions taken by the Agents,  Agent 0 memory is 10.0 percent full\n",
      "Random Seed Set to 11\n",
      "After 2000 actions taken by the Agents,  Agent 0 memory is 20.0 percent full\n",
      "Random Seed Set to 12\n",
      "After 3000 actions taken by the Agents,  Agent 0 memory is 30.0 percent full\n",
      "Random Seed Set to 13\n",
      "After 4000 actions taken by the Agents,  Agent 0 memory is 40.0 percent full\n",
      "Random Seed Set to 14\n",
      "After 5000 actions taken by the Agents,  Agent 0 memory is 50.0 percent full\n"
     ]
    }
   ],
   "source": [
    "Balance_int_MultiDQN_Agents.prepopulate_memory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Balance_int_MultiDQN_Agents.train(episodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Balance_int_MultiDQN_Agents.save(episodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Balance_int_MultiDQN_Agents.demo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## AGENT TRAINING RESULTS\n",
    "# Path to results folder\n",
    "results_path = os.path.join(vissim_working_directory, model_name, \"Agents_Results\", agent_type, Session_ID)\n",
    "\n",
    "# Loop over each agent\n",
    "for idx , agent in Balance_int_MultiDQN_Agents.Agents.items():\n",
    "    intersection_number_in_vissim = Balance_int_MultiDQN_Agents.Agents[0].signal_id + 1\n",
    "    print(\"Intersection \"+str(intersection_number_in_vissim))\n",
    "    \n",
    "    ## SAVE TRAINING DATA TO JSON.\n",
    "    json_filename = \"Agent{}_Loss_average_reward.json\".format(intersection_number_in_vissim)\n",
    "    Loss_reward = dict()   \n",
    "    # Loss dictionary\n",
    "    for epoch, loss in enumerate(agent.loss):\n",
    "        loss_dict = { epoch : loss }\n",
    "    Loss_reward['Agent{} loss'.format(intersection_number_in_vissim)] = loss_dict\n",
    "    # Reward dictionary            \n",
    "    episode = [i for i in range(len(agent.reward_storage))]\n",
    "    Loss_reward['Agent{} Average_Reward'.format(intersection_number_in_vissim)] = agent.reward_storage\n",
    "    # Store as JSON\n",
    "    with open(results_path + \"/\" + json_filename, 'w') as f:\n",
    "        json.dump(Loss_reward, f)\n",
    "    print(\"Agent {}: Training Loss and Average Reward during training successfuly saved to file:\".format(intersection_number_in_vissim))\n",
    "    print(results_path + \"/\" + json_filename)\n",
    "    \n",
    "    ## LOADING DATA FROM JSON\n",
    "    #results_path = os.path.join(vissim_working_directory, model_name, \"Agents_Results\", agent_type, Session_ID)\n",
    "    #dictionary_filename = \"Agent{}_Loss_average_reward.json\".format(intersection_number_in_vissim)\n",
    "    #with open(results_path + \"/\" + json_filename, 'r') as fp:\n",
    "    #    data = json.load(fp)\n",
    "    #print(data)\n",
    "    \n",
    "    ## TRAINING PLOTS\n",
    "    loss_plot_filename  = \"Agent{}_Loss.png\".format(intersection_number_in_vissim)\n",
    "    reward_plot_filename  = \"Agent{}_average_reward.png\".format(intersection_number_in_vissim) \n",
    "    \n",
    "    ## Loss Plot\n",
    "    plt.figure('LossAgent'+str(idx),figsize=(16,9))\n",
    "    plt.plot(agent.loss)\n",
    "    #plt.yscale('log')\n",
    "\n",
    "    plt.xlabel('Training Epoch',fontsize=18)\n",
    "    plt.ylabel('Loss',fontsize=18)\n",
    "    plt.title('Agent {} Loss over training'.format(intersection_number_in_vissim),fontsize=18)\n",
    "    plt.savefig(results_path + \"/\" + loss_plot_filename)\n",
    "\n",
    "    ## Average Reward Plot\n",
    "    plt.figure('RewardAgent'+str(idx),figsize=(16,9))\n",
    "    plt.plot(agent.reward_storage)\n",
    "    plt.xlabel('Training Episode',fontsize=18)\n",
    "    plt.ylabel('Average reward',fontsize=18)\n",
    "    plt.title('Agent {} average reward over training'.format(intersection_number_in_vissim),fontsize=18)\n",
    "    plt.savefig(results_path + \"/\" + reward_plot_filename)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "filename = os.path.join(vissim_working_directory, model_name, \"Agents_Results\", agent_type, Session_ID) + \"\\\\memoryD3QN.pkl\"\n",
    "memory = Balance_int_MultiDQN_Agents.Agents[0].memory2\n",
    "pickle.dump(memory, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Balance_int_MultiDQN_Agents.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "results_path = os.path.join(vissim_working_directory, model_name, \"Agents_Results\", agent_type, Session_ID)\n",
    "time = [t for t in range(len(Balance_int_MultiDQN_Agents.Cumulative_Totale_network_stop_delay))]\n",
    "\n",
    "########################################\n",
    "## Queues over time for each junction ##\n",
    "########################################\n",
    "for idx, queues in Balance_int_MultiDQN_Agents.Episode_Queues.items():\n",
    "    # Identify Junction ID in map\n",
    "    intersection_number_in_vissim = Balance_int_MultiDQN_Agents.Agents[0].signal_id + 1\n",
    "    \n",
    "    queues = np.array(queues)\n",
    "    queues = queues.T\n",
    "    number_queues = np.size(queues,0)\n",
    "    \n",
    "    plt.figure('1'+str(idx),figsize=(16, 9))\n",
    "    \n",
    "    Queues = dict()\n",
    "    Queues['Time'] = time\n",
    "    Queues_legend = []\n",
    "    \n",
    "    for i, queue in enumerate(queues):\n",
    "        plt.plot(queue, label = \"Queue\"+str(i))\n",
    "        Queues[str(i)] = queue.tolist()\n",
    "        Queues_legend.append(\"Queue\"+str(i))\n",
    "    \n",
    "    ## Plot the queues\n",
    "    plt.xlabel('Time [s]',fontsize=18)\n",
    "    plt.ylabel('Queue Length',fontsize=18)\n",
    "    plt.title('Junction {} Queue length'.format(intersection_number_in_vissim),fontsize=18)\n",
    "    plt.gca().legend(Queues_legend)\n",
    "    \n",
    "    filename = \"Junction{}_Queues.png\".format(intersection_number_in_vissim)           \n",
    "    plt.savefig(results_path + \"/\" + filename)\n",
    "    \n",
    "    # Store as JSON\n",
    "    json_filename = \"Junction{}_Queues.json\".format(intersection_number_in_vissim)        \n",
    "    with open(results_path + \"/\" + json_filename, 'w') as f:\n",
    "        json.dump(Queues, f)\n",
    "        \n",
    "    ### LOADING DATA FROM JSON\n",
    "    #results_path = os.path.join(vissim_working_directory, model_name, \"Agents_Results\", agent_type, Session_ID)\n",
    "    #json_filename = \"Junction{}_Queues.json\".format(intersection_number_in_vissim)\n",
    "    #with open(results_path + \"/\" + json_filename, 'r') as fp:\n",
    "    #    data = json.load(fp)\n",
    "    #print(data)\n",
    "        \n",
    "    # Success Message\n",
    "    print(\"Agent {}: Queues during Test successfuly saved to file:\".format(intersection_number_in_vissim))\n",
    "    print(results_path + \"/\" + json_filename)\n",
    "       \n",
    "        \n",
    "###################################################        \n",
    "## Accumulated delay over time for each junction ##\n",
    "###################################################\n",
    "for idx, delay in Balance_int_MultiDQN_Agents.Cumulative_Episode_Delays.items():\n",
    "    # Identify Junction ID in map\n",
    "    intersection_number_in_vissim = Balance_int_MultiDQN_Agents.Agents[idx].signal_id + 1\n",
    "\n",
    "    # Extract and process delay data\n",
    "    Delay = dict()   \n",
    "    Delay['Time'] = time\n",
    "    Delay['Junction {} delay'.format(intersection_number_in_vissim)] = delay\n",
    "    \n",
    "    # Store as JSON\n",
    "    json_filename = \"Junction{}_Cumulative_Delay.json\".format(intersection_number_in_vissim)        \n",
    "    with open(results_path + \"/\" + json_filename, 'w') as f:\n",
    "        json.dump(Delay, f)\n",
    "        \n",
    "    # Success Message\n",
    "    print(\"Agent {}: Test Cumulative Delay successfuly saved to file:\".format(intersection_number_in_vissim))\n",
    "    print(results_path + \"/\" + json_filename)\n",
    "    \n",
    "    ### Loading data from JSON\n",
    "    #results_path = os.path.join(vissim_working_directory, model_name, \"Agents_Results\", agent_type, Session_ID)\n",
    "    #dictionary_filename = \"Junction{}_Cumulative_Delay.json\".format(intersection_number_in_vissim)\n",
    "    #with open(results_path + \"/\" + json_filename, 'r') as fp:\n",
    "    #    data = json.load(fp)\n",
    "    #print(data)\n",
    "\n",
    "    # Plot the cumulative delay\n",
    "    plt.figure('2'+str(idx),figsize=(16, 9))\n",
    "    plt.plot(delay)\n",
    "    plt.xlabel('Time [s]',fontsize=18)\n",
    "    plt.ylabel('Accumulated Delay',fontsize=18)\n",
    "    plt.title('Junction {} Delay'.format(intersection_number_in_vissim),fontsize=18)\n",
    "    plt.gca().legend('Junction accumulated delay')\n",
    "    \n",
    "    filename = \"Junction{}_Cumulative_Delay.png\".format(intersection_number_in_vissim)\n",
    "    plt.savefig(results_path + \"/\" + filename)\n",
    "    \n",
    "    \n",
    "    \n",
    "########################################################    \n",
    "## Accumulated stop delay over time for each junction ##\n",
    "########################################################\n",
    "for idx, stop_delay in Balance_int_MultiDQN_Agents.Cumulative_Episode_stop_Delays.items():\n",
    "    # Identify Junction ID in map\n",
    "    intersection_number_in_vissim = Balance_int_MultiDQN_Agents.Agents[idx].signal_id + 1    \n",
    "    \n",
    "    # Extract and process stop delay data\n",
    "    Stop_delay = dict()   \n",
    "    Stop_delay['Time'] = time\n",
    "    Stop_delay['Junction {} stop delay'.format(intersection_number_in_vissim)] = stop_delay\n",
    "    \n",
    "    # Store as JSON\n",
    "    json_filename = \"Junction{}_Cumulative_Stop_Delay.json\".format(intersection_number_in_vissim)        \n",
    "    with open(results_path + \"/\" + json_filename, 'w') as f:\n",
    "        json.dump(Stop_delay, f)\n",
    "    \n",
    "    # Success Message\n",
    "    print(\"Agent {}: Test Cumulative Stop Delay successfuly saved to file:\".format(intersection_number_in_vissim))\n",
    "    print(results_path + \"/\" + json_filename)\n",
    "        \n",
    "    ### Loading data from JSON\n",
    "    #results_path = os.path.join(vissim_working_directory, model_name, \"Agents_Results\", agent_type, Session_ID)\n",
    "    #dictionary_filename = \"Junction{}_Cumulative_Stop_Delay.json\".format(intersection_number_in_vissim)\n",
    "    #with open(results_path + \"/\" + json_filename, 'r') as fp:\n",
    "    #    data = json.load(fp)\n",
    "    #print(data)\n",
    "    \n",
    "    # Plot the cumulative stop delay\n",
    "    plt.figure('3'+str(idx),figsize=(16, 9))\n",
    "    plt.plot(stop_delay)\n",
    "    plt.xlabel('Time [s]',fontsize=18)\n",
    "    plt.ylabel('Accumulated Stop Delay',fontsize=18)\n",
    "    plt.title('Junction {} Stop Delay'.format(intersection_number_in_vissim),fontsize=18)\n",
    "    plt.gca().legend('Junction accumulated Stop delay')\n",
    "    \n",
    "    filename = \"Junction{}_Cumulative_Stop_Delay.png\".format(intersection_number_in_vissim)\n",
    "    plt.savefig(results_path + \"/\" + filename)\n",
    "\n",
    "    \n",
    "    \n",
    "###############################################\n",
    "## ONLY IF THERE IS MORE THAN ONE CONTROLLER ##\n",
    "##    These are the global network plots     ##\n",
    "###############################################\n",
    "\n",
    "if len(Balance_int_MultiDQN_Agents.Agents) > 1:\n",
    "    ########################################    \n",
    "    ## Global Accumulated delay over time ##\n",
    "    ########################################\n",
    "    \n",
    "    # Process global delay data\n",
    "    Global_delay = dict()   \n",
    "    Global_delay['Time'] = time\n",
    "    Global_delay['Global accumulated Delay'] = Balance_int_MultiDQN_Agents.Cumulative_Totale_network_delay\n",
    "    \n",
    "    # Store as JSON\n",
    "    json_filename = \"Global_Cumulative_Delay.json\"\n",
    "    with open(results_path + \"/\" + json_filename, 'w') as f:\n",
    "        json.dump(Global_delay, f)\n",
    "    \n",
    "    # Success Message\n",
    "    print(\"Agent {}: Test Cumulative Global Delay successfuly saved to file:\")\n",
    "    print(results_path + \"/\" + json_filename)\n",
    "        \n",
    "    ### Loading data from JSON\n",
    "    #results_path = os.path.join(vissim_working_directory, model_name, \"Agents_Results\", agent_type, Session_ID)\n",
    "    #dictionary_filename = \"Global_Cumulative_Delay.json\"\n",
    "    #with open(results_path + \"/\" + json_filename, 'r') as fp:\n",
    "    #    data = json.load(fp)\n",
    "    #print(data)\n",
    "\n",
    "    \n",
    "    # Plot the global delay\n",
    "    plt.figure('4',figsize=(16,9))\n",
    "    plt.plot(Cumulative_Totale_network_delay)\n",
    "    plt.xlabel('Time [s]',fontsize=18)\n",
    "    plt.ylabel('Global accumulated Delay',fontsize=18)\n",
    "    plt.title('Global accumulated Delay',fontsize=18)\n",
    "    plt.gca().legend('Global accumulated delay')\n",
    "\n",
    "    filename = \"Global_Cumulative_Delay.png\".format(intersection_number_in_vissim)\n",
    "    plt.savefig(results_path + \"/\" + filename)\n",
    "\n",
    "\n",
    "    #############################################\n",
    "    ## Global Accumulated stop delay over time ##\n",
    "    #############################################\n",
    "    \n",
    "    # Process global stop delay data\n",
    "    Global_stop_delay = dict()   \n",
    "    Global_stop_delay['Time'] = time\n",
    "    Global_stop_delay['Global accumulated stop Delay'] = Balance_int_MultiDQN_Agents.Cumulative_Totale_network_stop_delay\n",
    "    \n",
    "    # Store as JSON\n",
    "    json_filename = \"Global_Cumulative_Stop_Delay.json\"\n",
    "    with open(results_path + \"/\" + json_filename, 'w') as f:\n",
    "        json.dump(Global_stop_delay, f)\n",
    "    \n",
    "    # Success Message\n",
    "    print(\"Agent {}: Test Cumulative Global Stop Delay successfuly saved to file:\")\n",
    "    print(results_path + \"/\" + json_filename)\n",
    "        \n",
    "    ### Loading data from JSON\n",
    "    #results_path = os.path.join(vissim_working_directory, model_name, \"Agents_Results\", agent_type, Session_ID)\n",
    "    #dictionary_filename = \"Global_Cumulative_Stop_Delay.json\"\n",
    "    #with open(results_path + \"/\" + json_filename, 'r') as fp:\n",
    "    #    data = json.load(fp)\n",
    "    #print(data)\n",
    "\n",
    "    # Plot the global stop delay\n",
    "    plt.figure('5'+str(idx),figsize=(16, 9))\n",
    "    plt.plot(Cumulative_Totale_network_stop_delay)\n",
    "    plt.xlabel('Time [s]',fontsize=18)\n",
    "    plt.ylabel('Global accumulated stop Delay',fontsize=18)\n",
    "    plt.title('Global accumulated stop Delay',fontsize=18)\n",
    "    plt.gca().legend('Global accumulated stop Delay')\n",
    "    \n",
    "    filename = \"Global_Cumulative_Delay.png\".format(intersection_number_in_vissim)\n",
    "    plt.savefig(results_path + \"/\" + filename)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Balance_int_MultiDQN_Agents.load(1000, best = True)\n",
    "Balance_int_MultiDQN_Agents.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "results_path = os.path.join(vissim_working_directory, model_name, \"Agents_Results\", agent_type, Session_ID)\n",
    "time = [t for t in range(len(Balance_int_MultiDQN_Agents.Cumulative_Totale_network_stop_delay))]\n",
    "\n",
    "########################################\n",
    "## Queues over time for each junction ##\n",
    "########################################\n",
    "for idx, queues in Balance_int_MultiDQN_Agents.Episode_Queues.items():\n",
    "    # Identify Junction ID in map\n",
    "    intersection_number_in_vissim = Balance_int_MultiDQN_Agents.Agents[0].signal_id + 1\n",
    "    \n",
    "    queues = np.array(queues)\n",
    "    queues = queues.T\n",
    "    number_queues = np.size(queues,0)\n",
    "    \n",
    "    plt.figure('1'+str(idx),figsize=(16, 9))\n",
    "    \n",
    "    Queues = dict()\n",
    "    Queues['Time'] = time\n",
    "    Queues_legend = []\n",
    "    \n",
    "    for i, queue in enumerate(queues):\n",
    "        plt.plot(queue, label = \"Queue\"+str(i))\n",
    "        Queues[str(i)] = queue.tolist()\n",
    "        Queues_legend.append(\"Queue\"+str(i))\n",
    "    \n",
    "    ## Plot the queues\n",
    "    plt.xlabel('Time [s]',fontsize=18)\n",
    "    plt.ylabel('Queue Length',fontsize=18)\n",
    "    plt.title('Junction {} Queue length'.format(intersection_number_in_vissim),fontsize=18)\n",
    "    plt.gca().legend(Queues_legend)\n",
    "    \n",
    "    filename = \"Junction{}_Queues.png\".format(intersection_number_in_vissim)           \n",
    "    plt.savefig(results_path + \"/\" + filename)\n",
    "    \n",
    "    # Store as JSON\n",
    "    json_filename = \"Junction{}_Queues.json\".format(intersection_number_in_vissim)        \n",
    "    with open(results_path + \"/\" + json_filename, 'w') as f:\n",
    "        json.dump(Queues, f)\n",
    "        \n",
    "    ### LOADING DATA FROM JSON\n",
    "    #results_path = os.path.join(vissim_working_directory, model_name, \"Agents_Results\", agent_type, Session_ID)\n",
    "    #json_filename = \"Junction{}_Queues.json\".format(intersection_number_in_vissim)\n",
    "    #with open(results_path + \"/\" + json_filename, 'r') as fp:\n",
    "    #    data = json.load(fp)\n",
    "    #print(data)\n",
    "        \n",
    "    # Success Message\n",
    "    print(\"Agent {}: Queues during Test successfuly saved to file:\".format(intersection_number_in_vissim))\n",
    "    print(results_path + \"/\" + json_filename)\n",
    "       \n",
    "        \n",
    "###################################################        \n",
    "## Accumulated delay over time for each junction ##\n",
    "###################################################\n",
    "for idx, delay in Balance_int_MultiDQN_Agents.Cumulative_Episode_Delays.items():\n",
    "    # Identify Junction ID in map\n",
    "    intersection_number_in_vissim = Balance_int_MultiDQN_Agents.Agents[idx].signal_id + 1\n",
    "\n",
    "    # Extract and process delay data\n",
    "    Delay = dict()   \n",
    "    Delay['Time'] = time\n",
    "    Delay['Junction {} delay'.format(intersection_number_in_vissim)] = delay\n",
    "    \n",
    "    # Store as JSON\n",
    "    json_filename = \"Junction{}_Cumulative_Delay.json\".format(intersection_number_in_vissim)        \n",
    "    with open(results_path + \"/\" + json_filename, 'w') as f:\n",
    "        json.dump(Delay, f)\n",
    "        \n",
    "    # Success Message\n",
    "    print(\"Agent {}: Test Cumulative Delay successfuly saved to file:\".format(intersection_number_in_vissim))\n",
    "    print(results_path + \"/\" + json_filename)\n",
    "    \n",
    "    ### Loading data from JSON\n",
    "    #results_path = os.path.join(vissim_working_directory, model_name, \"Agents_Results\", agent_type, Session_ID)\n",
    "    #dictionary_filename = \"Junction{}_Cumulative_Delay.json\".format(intersection_number_in_vissim)\n",
    "    #with open(results_path + \"/\" + json_filename, 'r') as fp:\n",
    "    #    data = json.load(fp)\n",
    "    #print(data)\n",
    "\n",
    "    # Plot the cumulative delay\n",
    "    plt.figure('2'+str(idx),figsize=(16, 9))\n",
    "    plt.plot(delay)\n",
    "    plt.xlabel('Time [s]',fontsize=18)\n",
    "    plt.ylabel('Accumulated Delay',fontsize=18)\n",
    "    plt.title('Junction {} Delay'.format(intersection_number_in_vissim),fontsize=18)\n",
    "    plt.gca().legend('Junction accumulated delay')\n",
    "    \n",
    "    filename = \"Junction{}_Cumulative_Delay.png\".format(intersection_number_in_vissim)\n",
    "    plt.savefig(results_path + \"/\" + filename)\n",
    "    \n",
    "    \n",
    "    \n",
    "########################################################    \n",
    "## Accumulated stop delay over time for each junction ##\n",
    "########################################################\n",
    "for idx, stop_delay in Balance_int_MultiDQN_Agents.Cumulative_Episode_stop_Delays.items():\n",
    "    # Identify Junction ID in map\n",
    "    intersection_number_in_vissim = Balance_int_MultiDQN_Agents.Agents[idx].signal_id + 1    \n",
    "    \n",
    "    # Extract and process stop delay data\n",
    "    Stop_delay = dict()   \n",
    "    Stop_delay['Time'] = time\n",
    "    Stop_delay['Junction {} stop delay'.format(intersection_number_in_vissim)] = stop_delay\n",
    "    \n",
    "    # Store as JSON\n",
    "    json_filename = \"Junction{}_Cumulative_Stop_Delay.json\".format(intersection_number_in_vissim)        \n",
    "    with open(results_path + \"/\" + json_filename, 'w') as f:\n",
    "        json.dump(Stop_delay, f)\n",
    "    \n",
    "    # Success Message\n",
    "    print(\"Agent {}: Test Cumulative Stop Delay successfuly saved to file:\".format(intersection_number_in_vissim))\n",
    "    print(results_path + \"/\" + json_filename)\n",
    "        \n",
    "    ### Loading data from JSON\n",
    "    #results_path = os.path.join(vissim_working_directory, model_name, \"Agents_Results\", agent_type, Session_ID)\n",
    "    #dictionary_filename = \"Junction{}_Cumulative_Stop_Delay.json\".format(intersection_number_in_vissim)\n",
    "    #with open(results_path + \"/\" + json_filename, 'r') as fp:\n",
    "    #    data = json.load(fp)\n",
    "    #print(data)\n",
    "    \n",
    "    # Plot the cumulative stop delay\n",
    "    plt.figure('3'+str(idx),figsize=(16, 9))\n",
    "    plt.plot(stop_delay)\n",
    "    plt.xlabel('Time [s]',fontsize=18)\n",
    "    plt.ylabel('Accumulated Stop Delay',fontsize=18)\n",
    "    plt.title('Junction {} Stop Delay'.format(intersection_number_in_vissim),fontsize=18)\n",
    "    plt.gca().legend('Junction accumulated Stop delay')\n",
    "    \n",
    "    filename = \"Junction{}_Cumulative_Stop_Delay.png\".format(intersection_number_in_vissim)\n",
    "    plt.savefig(results_path + \"/\" + filename)\n",
    "\n",
    "    \n",
    "    \n",
    "###############################################\n",
    "## ONLY IF THERE IS MORE THAN ONE CONTROLLER ##\n",
    "##    These are the global network plots     ##\n",
    "###############################################\n",
    "\n",
    "if len(Balance_int_MultiDQN_Agents.Agents) > 1:\n",
    "    ########################################    \n",
    "    ## Global Accumulated delay over time ##\n",
    "    ########################################\n",
    "    \n",
    "    # Process global delay data\n",
    "    Global_delay = dict()   \n",
    "    Global_delay['Time'] = time\n",
    "    Global_delay['Global accumulated Delay'] = Balance_int_MultiDQN_Agents.Cumulative_Totale_network_delay\n",
    "    \n",
    "    # Store as JSON\n",
    "    json_filename = \"Global_Cumulative_Delay.json\"\n",
    "    with open(results_path + \"/\" + json_filename, 'w') as f:\n",
    "        json.dump(Global_delay, f)\n",
    "    \n",
    "    # Success Message\n",
    "    print(\"Agent {}: Test Cumulative Global Delay successfuly saved to file:\")\n",
    "    print(results_path + \"/\" + json_filename)\n",
    "        \n",
    "    ### Loading data from JSON\n",
    "    #results_path = os.path.join(vissim_working_directory, model_name, \"Agents_Results\", agent_type, Session_ID)\n",
    "    #dictionary_filename = \"Global_Cumulative_Delay.json\"\n",
    "    #with open(results_path + \"/\" + json_filename, 'r') as fp:\n",
    "    #    data = json.load(fp)\n",
    "    #print(data)\n",
    "\n",
    "    \n",
    "    # Plot the global delay\n",
    "    plt.figure('4',figsize=(16,9))\n",
    "    plt.plot(Cumulative_Totale_network_delay)\n",
    "    plt.xlabel('Time [s]',fontsize=18)\n",
    "    plt.ylabel('Global accumulated Delay',fontsize=18)\n",
    "    plt.title('Global accumulated Delay',fontsize=18)\n",
    "    plt.gca().legend('Global accumulated delay')\n",
    "\n",
    "    filename = \"Global_Cumulative_Delay.png\".format(intersection_number_in_vissim)\n",
    "    plt.savefig(results_path + \"/\" + filename)\n",
    "\n",
    "\n",
    "    #############################################\n",
    "    ## Global Accumulated stop delay over time ##\n",
    "    #############################################\n",
    "    \n",
    "    # Process global stop delay data\n",
    "    Global_stop_delay = dict()   \n",
    "    Global_stop_delay['Time'] = time\n",
    "    Global_stop_delay['Global accumulated stop Delay'] = Balance_int_MultiDQN_Agents.Cumulative_Totale_network_stop_delay\n",
    "    \n",
    "    # Store as JSON\n",
    "    json_filename = \"Global_Cumulative_Stop_Delay.json\"\n",
    "    with open(results_path + \"/\" + json_filename, 'w') as f:\n",
    "        json.dump(Global_stop_delay, f)\n",
    "    \n",
    "    # Success Message\n",
    "    print(\"Agent {}: Test Cumulative Global Stop Delay successfuly saved to file:\")\n",
    "    print(results_path + \"/\" + json_filename)\n",
    "        \n",
    "    ### Loading data from JSON\n",
    "    #results_path = os.path.join(vissim_working_directory, model_name, \"Agents_Results\", agent_type, Session_ID)\n",
    "    #dictionary_filename = \"Global_Cumulative_Stop_Delay.json\"\n",
    "    #with open(results_path + \"/\" + json_filename, 'r') as fp:\n",
    "    #    data = json.load(fp)\n",
    "    #print(data)\n",
    "\n",
    "    # Plot the global stop delay\n",
    "    plt.figure('5'+str(idx),figsize=(16, 9))\n",
    "    plt.plot(Cumulative_Totale_network_stop_delay)\n",
    "    plt.xlabel('Time [s]',fontsize=18)\n",
    "    plt.ylabel('Global accumulated stop Delay',fontsize=18)\n",
    "    plt.title('Global accumulated stop Delay',fontsize=18)\n",
    "    plt.gca().legend('Global accumulated stop Delay')\n",
    "    \n",
    "    filename = \"Global_Cumulative_Delay.png\".format(intersection_number_in_vissim)\n",
    "    plt.savefig(results_path + \"/\" + filename)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
